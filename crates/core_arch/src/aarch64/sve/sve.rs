// This code is automatically generated. DO NOT MODIFY.
//
// Instead, modify `crates/stdarch-gen2/spec/` and run the following command to re-generate this file:
//
// ```
// cargo run --bin=stdarch-gen2 -- crates/stdarch-gen2/spec
// ```
#![allow(improper_ctypes)]

#[cfg(test)]
use stdarch_test::assert_instr;

use super::*;
use crate::core_arch::arch::aarch64::*;

#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabd))]
pub fn svabd_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fabd.nxv4f32")]
        fn _svabd_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svabd_f32_m(pg.into(), op1, op2) }
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabd))]
pub fn svabd_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svabd_f32_m(pg, op1, svdup_n_f32(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabd))]
pub fn svabd_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svabd_f32_m(pg, op1, op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabd))]
pub fn svabd_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svabd_f32_x(pg, op1, svdup_n_f32(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabd))]
pub fn svabd_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svabd_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabd))]
pub fn svabd_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svabd_f32_z(pg, op1, svdup_n_f32(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabd))]
pub fn svabd_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fabd.nxv2f64")]
        fn _svabd_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svabd_f64_m(pg.into(), op1, op2) }
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabd))]
pub fn svabd_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svabd_f64_m(pg, op1, svdup_n_f64(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabd))]
pub fn svabd_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svabd_f64_m(pg, op1, op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabd))]
pub fn svabd_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svabd_f64_x(pg, op1, svdup_n_f64(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabd))]
pub fn svabd_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svabd_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabd))]
pub fn svabd_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svabd_f64_z(pg, op1, svdup_n_f64(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sabd.nxv16i8")]
        fn _svabd_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svabd_s8_m(pg, op1, op2) }
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svabd_s8_m(pg, op1, svdup_n_s8(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svabd_s8_m(pg, op1, op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svabd_s8_x(pg, op1, svdup_n_s8(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svabd_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svabd_s8_z(pg, op1, svdup_n_s8(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sabd.nxv8i16")]
        fn _svabd_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svabd_s16_m(pg.into(), op1, op2) }
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svabd_s16_m(pg, op1, svdup_n_s16(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svabd_s16_m(pg, op1, op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svabd_s16_x(pg, op1, svdup_n_s16(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svabd_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svabd_s16_z(pg, op1, svdup_n_s16(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sabd.nxv4i32")]
        fn _svabd_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svabd_s32_m(pg.into(), op1, op2) }
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svabd_s32_m(pg, op1, svdup_n_s32(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svabd_s32_m(pg, op1, op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svabd_s32_x(pg, op1, svdup_n_s32(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svabd_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svabd_s32_z(pg, op1, svdup_n_s32(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sabd.nxv2i64")]
        fn _svabd_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svabd_s64_m(pg.into(), op1, op2) }
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svabd_s64_m(pg, op1, svdup_n_s64(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svabd_s64_m(pg, op1, op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svabd_s64_x(pg, op1, svdup_n_s64(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svabd_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sabd))]
pub fn svabd_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svabd_s64_z(pg, op1, svdup_n_s64(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uabd.nxv16i8")]
        fn _svabd_u8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svabd_u8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svabd_u8_m(pg, op1, svdup_n_u8(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svabd_u8_m(pg, op1, op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svabd_u8_x(pg, op1, svdup_n_u8(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svabd_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svabd_u8_z(pg, op1, svdup_n_u8(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uabd.nxv8i16")]
        fn _svabd_u16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svabd_u16_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svabd_u16_m(pg, op1, svdup_n_u16(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svabd_u16_m(pg, op1, op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svabd_u16_x(pg, op1, svdup_n_u16(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svabd_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svabd_u16_z(pg, op1, svdup_n_u16(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uabd.nxv4i32")]
        fn _svabd_u32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svabd_u32_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svabd_u32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svabd_u32_m(pg, op1, op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svabd_u32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svabd_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svabd_u32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uabd.nxv2i64")]
        fn _svabd_u64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svabd_u64_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svabd_u64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svabd_u64_m(pg, op1, op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svabd_u64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svabd_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[doc = "Absolute difference"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabd[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uabd))]
pub fn svabd_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svabd_u64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabs))]
pub fn svabs_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fabs.nxv4f32")]
        fn _svabs_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svabs_f32_m(inactive, pg.into(), op) }
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabs))]
pub fn svabs_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svabs_f32_m(op, pg, op)
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabs))]
pub fn svabs_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svabs_f32_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabs))]
pub fn svabs_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fabs.nxv2f64")]
        fn _svabs_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svabs_f64_m(inactive, pg.into(), op) }
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabs))]
pub fn svabs_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svabs_f64_m(op, pg, op)
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fabs))]
pub fn svabs_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svabs_f64_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(abs))]
pub fn svabs_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.abs.nxv16i8")]
        fn _svabs_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t;
    }
    unsafe { _svabs_s8_m(inactive, pg, op) }
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(abs))]
pub fn svabs_s8_x(pg: svbool_t, op: svint8_t) -> svint8_t {
    svabs_s8_m(op, pg, op)
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(abs))]
pub fn svabs_s8_z(pg: svbool_t, op: svint8_t) -> svint8_t {
    svabs_s8_m(svdup_n_s8(0), pg, op)
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(abs))]
pub fn svabs_s16_m(inactive: svint16_t, pg: svbool_t, op: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.abs.nxv8i16")]
        fn _svabs_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svabs_s16_m(inactive, pg.into(), op) }
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(abs))]
pub fn svabs_s16_x(pg: svbool_t, op: svint16_t) -> svint16_t {
    svabs_s16_m(op, pg, op)
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(abs))]
pub fn svabs_s16_z(pg: svbool_t, op: svint16_t) -> svint16_t {
    svabs_s16_m(svdup_n_s16(0), pg, op)
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(abs))]
pub fn svabs_s32_m(inactive: svint32_t, pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.abs.nxv4i32")]
        fn _svabs_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svabs_s32_m(inactive, pg.into(), op) }
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(abs))]
pub fn svabs_s32_x(pg: svbool_t, op: svint32_t) -> svint32_t {
    svabs_s32_m(op, pg, op)
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(abs))]
pub fn svabs_s32_z(pg: svbool_t, op: svint32_t) -> svint32_t {
    svabs_s32_m(svdup_n_s32(0), pg, op)
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(abs))]
pub fn svabs_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.abs.nxv2i64")]
        fn _svabs_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svabs_s64_m(inactive, pg.into(), op) }
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(abs))]
pub fn svabs_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svabs_s64_m(op, pg, op)
}
#[doc = "Absolute value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svabs[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(abs))]
pub fn svabs_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svabs_s64_m(svdup_n_s64(0), pg, op)
}
#[doc = "Absolute compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svacge[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(facge))]
pub fn svacge_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.facge.nxv4f32")]
        fn _svacge_f32(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool4_t;
    }
    unsafe { _svacge_f32(pg.into(), op1, op2).into() }
}
#[doc = "Absolute compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svacge[_n_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(facge))]
pub fn svacge_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svacge_f32(pg, op1, svdup_n_f32(op2))
}
#[doc = "Absolute compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svacge[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(facge))]
pub fn svacge_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.facge.nxv2f64")]
        fn _svacge_f64(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool2_t;
    }
    unsafe { _svacge_f64(pg.into(), op1, op2).into() }
}
#[doc = "Absolute compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svacge[_n_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(facge))]
pub fn svacge_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svacge_f64(pg, op1, svdup_n_f64(op2))
}
#[doc = "Absolute compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svacgt[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(facgt))]
pub fn svacgt_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.facgt.nxv4f32")]
        fn _svacgt_f32(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool4_t;
    }
    unsafe { _svacgt_f32(pg.into(), op1, op2).into() }
}
#[doc = "Absolute compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svacgt[_n_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(facgt))]
pub fn svacgt_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svacgt_f32(pg, op1, svdup_n_f32(op2))
}
#[doc = "Absolute compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svacgt[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(facgt))]
pub fn svacgt_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.facgt.nxv2f64")]
        fn _svacgt_f64(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool2_t;
    }
    unsafe { _svacgt_f64(pg.into(), op1, op2).into() }
}
#[doc = "Absolute compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svacgt[_n_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(facgt))]
pub fn svacgt_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svacgt_f64(pg, op1, svdup_n_f64(op2))
}
#[doc = "Absolute compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svacle[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(facge))]
pub fn svacle_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    svacge_f32(pg, op2, op1)
}
#[doc = "Absolute compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svacle[_n_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(facge))]
pub fn svacle_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svacle_f32(pg, op1, svdup_n_f32(op2))
}
#[doc = "Absolute compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svacle[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(facge))]
pub fn svacle_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    svacge_f64(pg, op2, op1)
}
#[doc = "Absolute compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svacle[_n_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(facge))]
pub fn svacle_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svacle_f64(pg, op1, svdup_n_f64(op2))
}
#[doc = "Absolute compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svaclt[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(facgt))]
pub fn svaclt_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    svacgt_f32(pg, op2, op1)
}
#[doc = "Absolute compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svaclt[_n_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(facgt))]
pub fn svaclt_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svaclt_f32(pg, op1, svdup_n_f32(op2))
}
#[doc = "Absolute compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svaclt[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(facgt))]
pub fn svaclt_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    svacgt_f64(pg, op2, op1)
}
#[doc = "Absolute compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svaclt[_n_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(facgt))]
pub fn svaclt_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svaclt_f64(pg, op1, svdup_n_f64(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fadd))]
pub fn svadd_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fadd.nxv4f32")]
        fn _svadd_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svadd_f32_m(pg.into(), op1, op2) }
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fadd))]
pub fn svadd_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svadd_f32_m(pg, op1, svdup_n_f32(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fadd))]
pub fn svadd_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svadd_f32_m(pg, op1, op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fadd))]
pub fn svadd_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svadd_f32_x(pg, op1, svdup_n_f32(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fadd))]
pub fn svadd_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svadd_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fadd))]
pub fn svadd_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svadd_f32_z(pg, op1, svdup_n_f32(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fadd))]
pub fn svadd_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fadd.nxv2f64")]
        fn _svadd_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svadd_f64_m(pg.into(), op1, op2) }
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fadd))]
pub fn svadd_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svadd_f64_m(pg, op1, svdup_n_f64(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fadd))]
pub fn svadd_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svadd_f64_m(pg, op1, op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fadd))]
pub fn svadd_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svadd_f64_x(pg, op1, svdup_n_f64(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fadd))]
pub fn svadd_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svadd_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fadd))]
pub fn svadd_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svadd_f64_z(pg, op1, svdup_n_f64(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.add.nxv16i8")]
        fn _svadd_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svadd_s8_m(pg, op1, op2) }
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svadd_s8_m(pg, op1, svdup_n_s8(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svadd_s8_m(pg, op1, op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svadd_s8_x(pg, op1, svdup_n_s8(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svadd_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svadd_s8_z(pg, op1, svdup_n_s8(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.add.nxv8i16")]
        fn _svadd_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svadd_s16_m(pg.into(), op1, op2) }
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svadd_s16_m(pg, op1, svdup_n_s16(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svadd_s16_m(pg, op1, op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svadd_s16_x(pg, op1, svdup_n_s16(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svadd_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svadd_s16_z(pg, op1, svdup_n_s16(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.add.nxv4i32")]
        fn _svadd_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svadd_s32_m(pg.into(), op1, op2) }
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svadd_s32_m(pg, op1, svdup_n_s32(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svadd_s32_m(pg, op1, op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svadd_s32_x(pg, op1, svdup_n_s32(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svadd_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svadd_s32_z(pg, op1, svdup_n_s32(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.add.nxv2i64")]
        fn _svadd_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svadd_s64_m(pg.into(), op1, op2) }
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svadd_s64_m(pg, op1, svdup_n_s64(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svadd_s64_m(pg, op1, op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svadd_s64_x(pg, op1, svdup_n_s64(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svadd_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svadd_s64_z(pg, op1, svdup_n_s64(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svadd_s8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svadd_u8_m(pg, op1, svdup_n_u8(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svadd_u8_m(pg, op1, op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svadd_u8_x(pg, op1, svdup_n_u8(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svadd_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svadd_u8_z(pg, op1, svdup_n_u8(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svadd_s16_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svadd_u16_m(pg, op1, svdup_n_u16(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svadd_u16_m(pg, op1, op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svadd_u16_x(pg, op1, svdup_n_u16(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svadd_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svadd_u16_z(pg, op1, svdup_n_u16(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svadd_s32_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svadd_u32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svadd_u32_m(pg, op1, op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svadd_u32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svadd_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svadd_u32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svadd_s64_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svadd_u64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svadd_u64_m(pg, op1, op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svadd_u64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svadd_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[doc = "Add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadd[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(add))]
pub fn svadd_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svadd_u64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Add reduction (strictly-ordered)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadda[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fadda))]
pub fn svadda_f32(pg: svbool_t, initial: f32, op: svfloat32_t) -> f32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fadda.nxv4f32")]
        fn _svadda_f32(pg: svbool4_t, initial: f32, op: svfloat32_t) -> f32;
    }
    unsafe { _svadda_f32(pg.into(), initial, op) }
}
#[doc = "Add reduction (strictly-ordered)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadda[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fadda))]
pub fn svadda_f64(pg: svbool_t, initial: f64, op: svfloat64_t) -> f64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fadda.nxv2f64")]
        fn _svadda_f64(pg: svbool2_t, initial: f64, op: svfloat64_t) -> f64;
    }
    unsafe { _svadda_f64(pg.into(), initial, op) }
}
#[doc = "Add reduction"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svaddv[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(faddv))]
pub fn svaddv_f32(pg: svbool_t, op: svfloat32_t) -> f32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.faddv.nxv4f32")]
        fn _svaddv_f32(pg: svbool4_t, op: svfloat32_t) -> f32;
    }
    unsafe { _svaddv_f32(pg.into(), op) }
}
#[doc = "Add reduction"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svaddv[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(faddv))]
pub fn svaddv_f64(pg: svbool_t, op: svfloat64_t) -> f64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.faddv.nxv2f64")]
        fn _svaddv_f64(pg: svbool2_t, op: svfloat64_t) -> f64;
    }
    unsafe { _svaddv_f64(pg.into(), op) }
}
#[doc = "Add reduction"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svaddv[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uaddv))]
pub fn svaddv_s64(pg: svbool_t, op: svint64_t) -> i64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.saddv.nxv2i64")]
        fn _svaddv_s64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _svaddv_s64(pg.into(), op) }
}
#[doc = "Add reduction"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svaddv[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uaddv))]
pub fn svaddv_u64(pg: svbool_t, op: svuint64_t) -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uaddv.nxv2i64")]
        fn _svaddv_u64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _svaddv_u64(pg.into(), op.as_signed()).as_unsigned() }
}
#[doc = "Add reduction"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svaddv[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(saddv))]
pub fn svaddv_s8(pg: svbool_t, op: svint8_t) -> i64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.saddv.nxv16i8")]
        fn _svaddv_s8(pg: svbool_t, op: svint8_t) -> i64;
    }
    unsafe { _svaddv_s8(pg, op) }
}
#[doc = "Add reduction"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svaddv[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(saddv))]
pub fn svaddv_s16(pg: svbool_t, op: svint16_t) -> i64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.saddv.nxv8i16")]
        fn _svaddv_s16(pg: svbool8_t, op: svint16_t) -> i64;
    }
    unsafe { _svaddv_s16(pg.into(), op) }
}
#[doc = "Add reduction"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svaddv[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(saddv))]
pub fn svaddv_s32(pg: svbool_t, op: svint32_t) -> i64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.saddv.nxv4i32")]
        fn _svaddv_s32(pg: svbool4_t, op: svint32_t) -> i64;
    }
    unsafe { _svaddv_s32(pg.into(), op) }
}
#[doc = "Add reduction"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svaddv[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uaddv))]
pub fn svaddv_u8(pg: svbool_t, op: svuint8_t) -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uaddv.nxv16i8")]
        fn _svaddv_u8(pg: svbool_t, op: svint8_t) -> i64;
    }
    unsafe { _svaddv_u8(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Add reduction"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svaddv[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uaddv))]
pub fn svaddv_u16(pg: svbool_t, op: svuint16_t) -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uaddv.nxv8i16")]
        fn _svaddv_u16(pg: svbool8_t, op: svint16_t) -> i64;
    }
    unsafe { _svaddv_u16(pg.into(), op.as_signed()).as_unsigned() }
}
#[doc = "Add reduction"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svaddv[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uaddv))]
pub fn svaddv_u32(pg: svbool_t, op: svuint32_t) -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uaddv.nxv4i32")]
        fn _svaddv_u32(pg: svbool4_t, op: svint32_t) -> i64;
    }
    unsafe { _svaddv_u32(pg.into(), op.as_signed()).as_unsigned() }
}
#[doc = "Compute vector addresses for 8-bit data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadrb[_u32base]_[s32]offset)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(adr))]
pub fn svadrb_u32base_s32offset(bases: svuint32_t, offsets: svint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.adrb.nxv4i32")]
        fn _svadrb_u32base_s32offset(bases: svint32_t, offsets: svint32_t) -> svint32_t;
    }
    unsafe { _svadrb_u32base_s32offset(bases.as_signed(), offsets).as_unsigned() }
}
#[doc = "Compute vector addresses for 16-bit data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadrh[_u32base]_[s32]index)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(adr))]
pub fn svadrh_u32base_s32index(bases: svuint32_t, indices: svint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.adrh.nxv4i32")]
        fn _svadrh_u32base_s32index(bases: svint32_t, indices: svint32_t) -> svint32_t;
    }
    unsafe { _svadrh_u32base_s32index(bases.as_signed(), indices).as_unsigned() }
}
#[doc = "Compute vector addresses for 32-bit data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadrw[_u32base]_[s32]index)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(adr))]
pub fn svadrw_u32base_s32index(bases: svuint32_t, indices: svint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.adrw.nxv4i32")]
        fn _svadrw_u32base_s32index(bases: svint32_t, indices: svint32_t) -> svint32_t;
    }
    unsafe { _svadrw_u32base_s32index(bases.as_signed(), indices).as_unsigned() }
}
#[doc = "Compute vector addresses for 64-bit data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadrd[_u32base]_[s32]index)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(adr))]
pub fn svadrd_u32base_s32index(bases: svuint32_t, indices: svint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.adrd.nxv4i32")]
        fn _svadrd_u32base_s32index(bases: svint32_t, indices: svint32_t) -> svint32_t;
    }
    unsafe { _svadrd_u32base_s32index(bases.as_signed(), indices).as_unsigned() }
}
#[doc = "Compute vector addresses for 8-bit data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadrb[_u32base]_[u32]offset)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(adr))]
pub fn svadrb_u32base_u32offset(bases: svuint32_t, offsets: svuint32_t) -> svuint32_t {
    unsafe { svadrb_u32base_s32offset(bases, offsets.as_signed()) }
}
#[doc = "Compute vector addresses for 16-bit data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadrh[_u32base]_[u32]index)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(adr))]
pub fn svadrh_u32base_u32index(bases: svuint32_t, indices: svuint32_t) -> svuint32_t {
    unsafe { svadrh_u32base_s32index(bases, indices.as_signed()) }
}
#[doc = "Compute vector addresses for 32-bit data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadrw[_u32base]_[u32]index)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(adr))]
pub fn svadrw_u32base_u32index(bases: svuint32_t, indices: svuint32_t) -> svuint32_t {
    unsafe { svadrw_u32base_s32index(bases, indices.as_signed()) }
}
#[doc = "Compute vector addresses for 64-bit data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadrd[_u32base]_[u32]index)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(adr))]
pub fn svadrd_u32base_u32index(bases: svuint32_t, indices: svuint32_t) -> svuint32_t {
    unsafe { svadrd_u32base_s32index(bases, indices.as_signed()) }
}
#[doc = "Compute vector addresses for 8-bit data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadrb[_u64base]_[s64]offset)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(adr))]
pub fn svadrb_u64base_s64offset(bases: svuint64_t, offsets: svint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.adrb.nxv2i64")]
        fn _svadrb_u64base_s64offset(bases: svint64_t, offsets: svint64_t) -> svint64_t;
    }
    unsafe { _svadrb_u64base_s64offset(bases.as_signed(), offsets).as_unsigned() }
}
#[doc = "Compute vector addresses for 16-bit data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadrh[_u64base]_[s64]index)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(adr))]
pub fn svadrh_u64base_s64index(bases: svuint64_t, indices: svint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.adrh.nxv2i64")]
        fn _svadrh_u64base_s64index(bases: svint64_t, indices: svint64_t) -> svint64_t;
    }
    unsafe { _svadrh_u64base_s64index(bases.as_signed(), indices).as_unsigned() }
}
#[doc = "Compute vector addresses for 32-bit data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadrw[_u64base]_[s64]index)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(adr))]
pub fn svadrw_u64base_s64index(bases: svuint64_t, indices: svint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.adrw.nxv2i64")]
        fn _svadrw_u64base_s64index(bases: svint64_t, indices: svint64_t) -> svint64_t;
    }
    unsafe { _svadrw_u64base_s64index(bases.as_signed(), indices).as_unsigned() }
}
#[doc = "Compute vector addresses for 64-bit data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadrd[_u64base]_[s64]index)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(adr))]
pub fn svadrd_u64base_s64index(bases: svuint64_t, indices: svint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.adrd.nxv2i64")]
        fn _svadrd_u64base_s64index(bases: svint64_t, indices: svint64_t) -> svint64_t;
    }
    unsafe { _svadrd_u64base_s64index(bases.as_signed(), indices).as_unsigned() }
}
#[doc = "Compute vector addresses for 8-bit data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadrb[_u64base]_[u64]offset)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(adr))]
pub fn svadrb_u64base_u64offset(bases: svuint64_t, offsets: svuint64_t) -> svuint64_t {
    unsafe { svadrb_u64base_s64offset(bases, offsets.as_signed()) }
}
#[doc = "Compute vector addresses for 16-bit data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadrh[_u64base]_[u64]index)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(adr))]
pub fn svadrh_u64base_u64index(bases: svuint64_t, indices: svuint64_t) -> svuint64_t {
    unsafe { svadrh_u64base_s64index(bases, indices.as_signed()) }
}
#[doc = "Compute vector addresses for 32-bit data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadrw[_u64base]_[u64]index)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(adr))]
pub fn svadrw_u64base_u64index(bases: svuint64_t, indices: svuint64_t) -> svuint64_t {
    unsafe { svadrw_u64base_s64index(bases, indices.as_signed()) }
}
#[doc = "Compute vector addresses for 64-bit data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svadrd[_u64base]_[u64]index)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(adr))]
pub fn svadrd_u64base_u64index(bases: svuint64_t, indices: svuint64_t) -> svuint64_t {
    unsafe { svadrd_u64base_s64index(bases, indices.as_signed()) }
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_b]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.and.z.nvx16i1")]
        fn _svand_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svand_b_z(pg, op1, op2) }
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.and.nxv16i8")]
        fn _svand_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svand_s8_m(pg, op1, op2) }
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svand_s8_m(pg, op1, svdup_n_s8(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svand_s8_m(pg, op1, op2)
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svand_s8_x(pg, op1, svdup_n_s8(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svand_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svand_s8_z(pg, op1, svdup_n_s8(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.and.nxv8i16")]
        fn _svand_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svand_s16_m(pg.into(), op1, op2) }
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svand_s16_m(pg, op1, svdup_n_s16(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svand_s16_m(pg, op1, op2)
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svand_s16_x(pg, op1, svdup_n_s16(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svand_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svand_s16_z(pg, op1, svdup_n_s16(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.and.nxv4i32")]
        fn _svand_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svand_s32_m(pg.into(), op1, op2) }
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svand_s32_m(pg, op1, svdup_n_s32(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svand_s32_m(pg, op1, op2)
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svand_s32_x(pg, op1, svdup_n_s32(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svand_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svand_s32_z(pg, op1, svdup_n_s32(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.and.nxv2i64")]
        fn _svand_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svand_s64_m(pg.into(), op1, op2) }
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svand_s64_m(pg, op1, svdup_n_s64(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svand_s64_m(pg, op1, op2)
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svand_s64_x(pg, op1, svdup_n_s64(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svand_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svand_s64_z(pg, op1, svdup_n_s64(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svand_s8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svand_u8_m(pg, op1, svdup_n_u8(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svand_u8_m(pg, op1, op2)
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svand_u8_x(pg, op1, svdup_n_u8(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svand_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svand_u8_z(pg, op1, svdup_n_u8(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svand_s16_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svand_u16_m(pg, op1, svdup_n_u16(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svand_u16_m(pg, op1, op2)
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svand_u16_x(pg, op1, svdup_n_u16(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svand_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svand_u16_z(pg, op1, svdup_n_u16(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svand_s32_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svand_u32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svand_u32_m(pg, op1, op2)
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svand_u32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svand_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svand_u32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svand_s64_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svand_u64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svand_u64_m(pg, op1, op2)
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svand_u64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svand_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[doc = "Bitwise AND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svand[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(and))]
pub fn svand_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svand_u64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Bitwise AND reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svandv[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(andv))]
pub fn svandv_s8(pg: svbool_t, op: svint8_t) -> i8 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.andv.nxv16i8")]
        fn _svandv_s8(pg: svbool_t, op: svint8_t) -> i8;
    }
    unsafe { _svandv_s8(pg, op) }
}
#[doc = "Bitwise AND reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svandv[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(andv))]
pub fn svandv_s16(pg: svbool_t, op: svint16_t) -> i16 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.andv.nxv8i16")]
        fn _svandv_s16(pg: svbool8_t, op: svint16_t) -> i16;
    }
    unsafe { _svandv_s16(pg.into(), op) }
}
#[doc = "Bitwise AND reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svandv[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(andv))]
pub fn svandv_s32(pg: svbool_t, op: svint32_t) -> i32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.andv.nxv4i32")]
        fn _svandv_s32(pg: svbool4_t, op: svint32_t) -> i32;
    }
    unsafe { _svandv_s32(pg.into(), op) }
}
#[doc = "Bitwise AND reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svandv[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(andv))]
pub fn svandv_s64(pg: svbool_t, op: svint64_t) -> i64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.andv.nxv2i64")]
        fn _svandv_s64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _svandv_s64(pg.into(), op) }
}
#[doc = "Bitwise AND reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svandv[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(andv))]
pub fn svandv_u8(pg: svbool_t, op: svuint8_t) -> u8 {
    unsafe { svandv_s8(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Bitwise AND reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svandv[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(andv))]
pub fn svandv_u16(pg: svbool_t, op: svuint16_t) -> u16 {
    unsafe { svandv_s16(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Bitwise AND reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svandv[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(andv))]
pub fn svandv_u32(pg: svbool_t, op: svuint32_t) -> u32 {
    unsafe { svandv_s32(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Bitwise AND reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svandv[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(andv))]
pub fn svandv_u64(pg: svbool_t, op: svuint64_t) -> u64 {
    unsafe { svandv_s64(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_s8_m(pg: svbool_t, op1: svint8_t, op2: svuint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.asr.nxv16i8")]
        fn _svasr_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svasr_s8_m(pg, op1, op2.as_signed()) }
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_n_s8_m(pg: svbool_t, op1: svint8_t, op2: u8) -> svint8_t {
    svasr_s8_m(pg, op1, svdup_n_u8(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_s8_x(pg: svbool_t, op1: svint8_t, op2: svuint8_t) -> svint8_t {
    svasr_s8_m(pg, op1, op2)
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_n_s8_x(pg: svbool_t, op1: svint8_t, op2: u8) -> svint8_t {
    svasr_s8_x(pg, op1, svdup_n_u8(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_s8_z(pg: svbool_t, op1: svint8_t, op2: svuint8_t) -> svint8_t {
    svasr_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_n_s8_z(pg: svbool_t, op1: svint8_t, op2: u8) -> svint8_t {
    svasr_s8_z(pg, op1, svdup_n_u8(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_s16_m(pg: svbool_t, op1: svint16_t, op2: svuint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.asr.nxv8i16")]
        fn _svasr_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svasr_s16_m(pg.into(), op1, op2.as_signed()) }
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_n_s16_m(pg: svbool_t, op1: svint16_t, op2: u16) -> svint16_t {
    svasr_s16_m(pg, op1, svdup_n_u16(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_s16_x(pg: svbool_t, op1: svint16_t, op2: svuint16_t) -> svint16_t {
    svasr_s16_m(pg, op1, op2)
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_n_s16_x(pg: svbool_t, op1: svint16_t, op2: u16) -> svint16_t {
    svasr_s16_x(pg, op1, svdup_n_u16(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_s16_z(pg: svbool_t, op1: svint16_t, op2: svuint16_t) -> svint16_t {
    svasr_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_n_s16_z(pg: svbool_t, op1: svint16_t, op2: u16) -> svint16_t {
    svasr_s16_z(pg, op1, svdup_n_u16(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_s32_m(pg: svbool_t, op1: svint32_t, op2: svuint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.asr.nxv4i32")]
        fn _svasr_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svasr_s32_m(pg.into(), op1, op2.as_signed()) }
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_n_s32_m(pg: svbool_t, op1: svint32_t, op2: u32) -> svint32_t {
    svasr_s32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_s32_x(pg: svbool_t, op1: svint32_t, op2: svuint32_t) -> svint32_t {
    svasr_s32_m(pg, op1, op2)
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_n_s32_x(pg: svbool_t, op1: svint32_t, op2: u32) -> svint32_t {
    svasr_s32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_s32_z(pg: svbool_t, op1: svint32_t, op2: svuint32_t) -> svint32_t {
    svasr_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_n_s32_z(pg: svbool_t, op1: svint32_t, op2: u32) -> svint32_t {
    svasr_s32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_s64_m(pg: svbool_t, op1: svint64_t, op2: svuint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.asr.nxv2i64")]
        fn _svasr_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svasr_s64_m(pg.into(), op1, op2.as_signed()) }
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_n_s64_m(pg: svbool_t, op1: svint64_t, op2: u64) -> svint64_t {
    svasr_s64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_s64_x(pg: svbool_t, op1: svint64_t, op2: svuint64_t) -> svint64_t {
    svasr_s64_m(pg, op1, op2)
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_n_s64_x(pg: svbool_t, op1: svint64_t, op2: u64) -> svint64_t {
    svasr_s64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_s64_z(pg: svbool_t, op1: svint64_t, op2: svuint64_t) -> svint64_t {
    svasr_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_n_s64_z(pg: svbool_t, op1: svint64_t, op2: u64) -> svint64_t {
    svasr_s64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_s8_m(pg: svbool_t, op1: svint8_t, op2: svuint64_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.asr.wide.nxv16i8"
        )]
        fn _svasr_wide_s8_m(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svint8_t;
    }
    unsafe { _svasr_wide_s8_m(pg, op1, op2.as_signed()) }
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_n_s8_m(pg: svbool_t, op1: svint8_t, op2: u64) -> svint8_t {
    svasr_wide_s8_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_s8_x(pg: svbool_t, op1: svint8_t, op2: svuint64_t) -> svint8_t {
    svasr_wide_s8_m(pg, op1, op2)
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_n_s8_x(pg: svbool_t, op1: svint8_t, op2: u64) -> svint8_t {
    svasr_wide_s8_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_s8_z(pg: svbool_t, op1: svint8_t, op2: svuint64_t) -> svint8_t {
    svasr_wide_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_n_s8_z(pg: svbool_t, op1: svint8_t, op2: u64) -> svint8_t {
    svasr_wide_s8_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_s16_m(pg: svbool_t, op1: svint16_t, op2: svuint64_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.asr.wide.nxv8i16"
        )]
        fn _svasr_wide_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svint16_t;
    }
    unsafe { _svasr_wide_s16_m(pg.into(), op1, op2.as_signed()) }
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_n_s16_m(pg: svbool_t, op1: svint16_t, op2: u64) -> svint16_t {
    svasr_wide_s16_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_s16_x(pg: svbool_t, op1: svint16_t, op2: svuint64_t) -> svint16_t {
    svasr_wide_s16_m(pg, op1, op2)
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_n_s16_x(pg: svbool_t, op1: svint16_t, op2: u64) -> svint16_t {
    svasr_wide_s16_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_s16_z(pg: svbool_t, op1: svint16_t, op2: svuint64_t) -> svint16_t {
    svasr_wide_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_n_s16_z(pg: svbool_t, op1: svint16_t, op2: u64) -> svint16_t {
    svasr_wide_s16_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_s32_m(pg: svbool_t, op1: svint32_t, op2: svuint64_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.asr.wide.nxv4i32"
        )]
        fn _svasr_wide_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svint32_t;
    }
    unsafe { _svasr_wide_s32_m(pg.into(), op1, op2.as_signed()) }
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_n_s32_m(pg: svbool_t, op1: svint32_t, op2: u64) -> svint32_t {
    svasr_wide_s32_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_s32_x(pg: svbool_t, op1: svint32_t, op2: svuint64_t) -> svint32_t {
    svasr_wide_s32_m(pg, op1, op2)
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_n_s32_x(pg: svbool_t, op1: svint32_t, op2: u64) -> svint32_t {
    svasr_wide_s32_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_s32_z(pg: svbool_t, op1: svint32_t, op2: svuint64_t) -> svint32_t {
    svasr_wide_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Arithmetic shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasr_wide[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asr))]
pub fn svasr_wide_n_s32_z(pg: svbool_t, op1: svint32_t, op2: u64) -> svint32_t {
    svasr_wide_s32_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Arithmetic shift right for divide by immediate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasrd[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asrd, IMM2 = 1))]
pub fn svasrd_n_s8_m<const IMM2: i32>(pg: svbool_t, op1: svint8_t) -> svint8_t {
    static_assert_range!(IMM2, 1, 8);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.asrd.nxv16i8")]
        fn _svasrd_n_s8_m(pg: svbool_t, op1: svint8_t, imm2: i32) -> svint8_t;
    }
    unsafe { _svasrd_n_s8_m(pg, op1, IMM2) }
}
#[doc = "Arithmetic shift right for divide by immediate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasrd[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asrd, IMM2 = 1))]
pub fn svasrd_n_s8_x<const IMM2: i32>(pg: svbool_t, op1: svint8_t) -> svint8_t {
    svasrd_n_s8_m::<IMM2>(pg, op1)
}
#[doc = "Arithmetic shift right for divide by immediate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasrd[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asrd, IMM2 = 1))]
pub fn svasrd_n_s8_z<const IMM2: i32>(pg: svbool_t, op1: svint8_t) -> svint8_t {
    svasrd_n_s8_m::<IMM2>(pg, svsel_s8(pg, op1, svdup_n_s8(0)))
}
#[doc = "Arithmetic shift right for divide by immediate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasrd[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asrd, IMM2 = 1))]
pub fn svasrd_n_s16_m<const IMM2: i32>(pg: svbool_t, op1: svint16_t) -> svint16_t {
    static_assert_range!(IMM2, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.asrd.nxv8i16")]
        fn _svasrd_n_s16_m(pg: svbool8_t, op1: svint16_t, imm2: i32) -> svint16_t;
    }
    unsafe { _svasrd_n_s16_m(pg.into(), op1, IMM2) }
}
#[doc = "Arithmetic shift right for divide by immediate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasrd[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asrd, IMM2 = 1))]
pub fn svasrd_n_s16_x<const IMM2: i32>(pg: svbool_t, op1: svint16_t) -> svint16_t {
    svasrd_n_s16_m::<IMM2>(pg, op1)
}
#[doc = "Arithmetic shift right for divide by immediate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasrd[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asrd, IMM2 = 1))]
pub fn svasrd_n_s16_z<const IMM2: i32>(pg: svbool_t, op1: svint16_t) -> svint16_t {
    svasrd_n_s16_m::<IMM2>(pg, svsel_s16(pg, op1, svdup_n_s16(0)))
}
#[doc = "Arithmetic shift right for divide by immediate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasrd[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asrd, IMM2 = 1))]
pub fn svasrd_n_s32_m<const IMM2: i32>(pg: svbool_t, op1: svint32_t) -> svint32_t {
    static_assert_range!(IMM2, 1, 32);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.asrd.nxv4i32")]
        fn _svasrd_n_s32_m(pg: svbool4_t, op1: svint32_t, imm2: i32) -> svint32_t;
    }
    unsafe { _svasrd_n_s32_m(pg.into(), op1, IMM2) }
}
#[doc = "Arithmetic shift right for divide by immediate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasrd[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asrd, IMM2 = 1))]
pub fn svasrd_n_s32_x<const IMM2: i32>(pg: svbool_t, op1: svint32_t) -> svint32_t {
    svasrd_n_s32_m::<IMM2>(pg, op1)
}
#[doc = "Arithmetic shift right for divide by immediate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasrd[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asrd, IMM2 = 1))]
pub fn svasrd_n_s32_z<const IMM2: i32>(pg: svbool_t, op1: svint32_t) -> svint32_t {
    svasrd_n_s32_m::<IMM2>(pg, svsel_s32(pg, op1, svdup_n_s32(0)))
}
#[doc = "Arithmetic shift right for divide by immediate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasrd[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asrd, IMM2 = 1))]
pub fn svasrd_n_s64_m<const IMM2: i32>(pg: svbool_t, op1: svint64_t) -> svint64_t {
    static_assert_range!(IMM2, 1, 64);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.asrd.nxv2i64")]
        fn _svasrd_n_s64_m(pg: svbool2_t, op1: svint64_t, imm2: i32) -> svint64_t;
    }
    unsafe { _svasrd_n_s64_m(pg.into(), op1, IMM2) }
}
#[doc = "Arithmetic shift right for divide by immediate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasrd[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asrd, IMM2 = 1))]
pub fn svasrd_n_s64_x<const IMM2: i32>(pg: svbool_t, op1: svint64_t) -> svint64_t {
    svasrd_n_s64_m::<IMM2>(pg, op1)
}
#[doc = "Arithmetic shift right for divide by immediate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svasrd[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(asrd, IMM2 = 1))]
pub fn svasrd_n_s64_z<const IMM2: i32>(pg: svbool_t, op1: svint64_t) -> svint64_t {
    svasrd_n_s64_m::<IMM2>(pg, svsel_s64(pg, op1, svdup_n_s64(0)))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_b]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.bic.z.nvx16i1")]
        fn _svbic_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svbic_b_z(pg, op1, op2) }
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.bic.nxv16i8")]
        fn _svbic_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svbic_s8_m(pg, op1, op2) }
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svbic_s8_m(pg, op1, svdup_n_s8(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svbic_s8_m(pg, op1, op2)
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svbic_s8_x(pg, op1, svdup_n_s8(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svbic_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svbic_s8_z(pg, op1, svdup_n_s8(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.bic.nxv8i16")]
        fn _svbic_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svbic_s16_m(pg.into(), op1, op2) }
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svbic_s16_m(pg, op1, svdup_n_s16(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svbic_s16_m(pg, op1, op2)
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svbic_s16_x(pg, op1, svdup_n_s16(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svbic_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svbic_s16_z(pg, op1, svdup_n_s16(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.bic.nxv4i32")]
        fn _svbic_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svbic_s32_m(pg.into(), op1, op2) }
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svbic_s32_m(pg, op1, svdup_n_s32(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svbic_s32_m(pg, op1, op2)
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svbic_s32_x(pg, op1, svdup_n_s32(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svbic_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svbic_s32_z(pg, op1, svdup_n_s32(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.bic.nxv2i64")]
        fn _svbic_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svbic_s64_m(pg.into(), op1, op2) }
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svbic_s64_m(pg, op1, svdup_n_s64(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svbic_s64_m(pg, op1, op2)
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svbic_s64_x(pg, op1, svdup_n_s64(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svbic_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svbic_s64_z(pg, op1, svdup_n_s64(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svbic_s8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svbic_u8_m(pg, op1, svdup_n_u8(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svbic_u8_m(pg, op1, op2)
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svbic_u8_x(pg, op1, svdup_n_u8(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svbic_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svbic_u8_z(pg, op1, svdup_n_u8(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svbic_s16_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svbic_u16_m(pg, op1, svdup_n_u16(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svbic_u16_m(pg, op1, op2)
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svbic_u16_x(pg, op1, svdup_n_u16(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svbic_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svbic_u16_z(pg, op1, svdup_n_u16(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svbic_s32_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svbic_u32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svbic_u32_m(pg, op1, op2)
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svbic_u32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svbic_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svbic_u32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svbic_s64_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svbic_u64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svbic_u64_m(pg, op1, op2)
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svbic_u64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svbic_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[doc = "Bitwise clear"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbic[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(bic))]
pub fn svbic_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svbic_u64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Break after first true condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbrka[_b]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(brka))]
pub fn svbrka_b_m(inactive: svbool_t, pg: svbool_t, op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.brka.nxv16i1")]
        fn _svbrka_b_m(inactive: svbool_t, pg: svbool_t, op: svbool_t) -> svbool_t;
    }
    unsafe { _svbrka_b_m(inactive, pg, op) }
}
#[doc = "Break after first true condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbrka[_b]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(brka))]
pub fn svbrka_b_z(pg: svbool_t, op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.brka.z.nxv16i1")]
        fn _svbrka_b_z(pg: svbool_t, op: svbool_t) -> svbool_t;
    }
    unsafe { _svbrka_b_z(pg, op) }
}
#[doc = "Break before first true condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbrkb[_b]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(brkb))]
pub fn svbrkb_b_m(inactive: svbool_t, pg: svbool_t, op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.brkb.nxv16i1")]
        fn _svbrkb_b_m(inactive: svbool_t, pg: svbool_t, op: svbool_t) -> svbool_t;
    }
    unsafe { _svbrkb_b_m(inactive, pg, op) }
}
#[doc = "Break before first true condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbrkb[_b]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(brkb))]
pub fn svbrkb_b_z(pg: svbool_t, op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.brkb.z.nxv16i1")]
        fn _svbrkb_b_z(pg: svbool_t, op: svbool_t) -> svbool_t;
    }
    unsafe { _svbrkb_b_z(pg, op) }
}
#[doc = "Propagate break to next partition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbrkn[_b]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(brkn))]
pub fn svbrkn_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.brkn.z.nxv16i1")]
        fn _svbrkn_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svbrkn_b_z(pg, op1, op2) }
}
#[doc = "Break after first true condition, propagating from previous partition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbrkpa[_b]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(brkpa))]
pub fn svbrkpa_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.brkpa.z.nxv16i1"
        )]
        fn _svbrkpa_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svbrkpa_b_z(pg, op1, op2) }
}
#[doc = "Break before first true condition, propagating from previous partition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svbrkpb[_b]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(brkpb))]
pub fn svbrkpb_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.brkpb.z.nxv16i1"
        )]
        fn _svbrkpb_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svbrkpb_b_z(pg, op1, op2) }
}
#[doc = "Complex add with rotate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcadd[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcadd, IMM_ROTATION = 90))]
pub fn svcadd_f32_m<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
) -> svfloat32_t {
    static_assert!(IMM_ROTATION == 90 || IMM_ROTATION == 270);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcadd.nxv4f32")]
        fn _svcadd_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            imm_rotation: i32,
        ) -> svfloat32_t;
    }
    unsafe { _svcadd_f32_m(pg.into(), op1, op2, IMM_ROTATION) }
}
#[doc = "Complex add with rotate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcadd[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcadd, IMM_ROTATION = 90))]
pub fn svcadd_f32_x<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
) -> svfloat32_t {
    svcadd_f32_m::<IMM_ROTATION>(pg, op1, op2)
}
#[doc = "Complex add with rotate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcadd[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcadd, IMM_ROTATION = 90))]
pub fn svcadd_f32_z<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
) -> svfloat32_t {
    svcadd_f32_m::<IMM_ROTATION>(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[doc = "Complex add with rotate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcadd[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcadd, IMM_ROTATION = 90))]
pub fn svcadd_f64_m<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
) -> svfloat64_t {
    static_assert!(IMM_ROTATION == 90 || IMM_ROTATION == 270);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcadd.nxv2f64")]
        fn _svcadd_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            imm_rotation: i32,
        ) -> svfloat64_t;
    }
    unsafe { _svcadd_f64_m(pg.into(), op1, op2, IMM_ROTATION) }
}
#[doc = "Complex add with rotate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcadd[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcadd, IMM_ROTATION = 90))]
pub fn svcadd_f64_x<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
) -> svfloat64_t {
    svcadd_f64_m::<IMM_ROTATION>(pg, op1, op2)
}
#[doc = "Complex add with rotate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcadd[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcadd, IMM_ROTATION = 90))]
pub fn svcadd_f64_z<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
) -> svfloat64_t {
    svcadd_f64_m::<IMM_ROTATION>(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_f32(pg: svbool_t, fallback: svfloat32_t, data: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clasta.nxv4f32")]
        fn _svclasta_f32(pg: svbool4_t, fallback: svfloat32_t, data: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svclasta_f32(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_f64(pg: svbool_t, fallback: svfloat64_t, data: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clasta.nxv2f64")]
        fn _svclasta_f64(pg: svbool2_t, fallback: svfloat64_t, data: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svclasta_f64(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_s8(pg: svbool_t, fallback: svint8_t, data: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clasta.nxv16i8")]
        fn _svclasta_s8(pg: svbool_t, fallback: svint8_t, data: svint8_t) -> svint8_t;
    }
    unsafe { _svclasta_s8(pg, fallback, data) }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_s16(pg: svbool_t, fallback: svint16_t, data: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clasta.nxv8i16")]
        fn _svclasta_s16(pg: svbool8_t, fallback: svint16_t, data: svint16_t) -> svint16_t;
    }
    unsafe { _svclasta_s16(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_s32(pg: svbool_t, fallback: svint32_t, data: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clasta.nxv4i32")]
        fn _svclasta_s32(pg: svbool4_t, fallback: svint32_t, data: svint32_t) -> svint32_t;
    }
    unsafe { _svclasta_s32(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_s64(pg: svbool_t, fallback: svint64_t, data: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clasta.nxv2i64")]
        fn _svclasta_s64(pg: svbool2_t, fallback: svint64_t, data: svint64_t) -> svint64_t;
    }
    unsafe { _svclasta_s64(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_u8(pg: svbool_t, fallback: svuint8_t, data: svuint8_t) -> svuint8_t {
    unsafe { svclasta_s8(pg, fallback.as_signed(), data.as_signed()).as_unsigned() }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_u16(pg: svbool_t, fallback: svuint16_t, data: svuint16_t) -> svuint16_t {
    unsafe { svclasta_s16(pg, fallback.as_signed(), data.as_signed()).as_unsigned() }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_u32(pg: svbool_t, fallback: svuint32_t, data: svuint32_t) -> svuint32_t {
    unsafe { svclasta_s32(pg, fallback.as_signed(), data.as_signed()).as_unsigned() }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_u64(pg: svbool_t, fallback: svuint64_t, data: svuint64_t) -> svuint64_t {
    unsafe { svclasta_s64(pg, fallback.as_signed(), data.as_signed()).as_unsigned() }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_n_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_n_f32(pg: svbool_t, fallback: f32, data: svfloat32_t) -> f32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.clasta.n.nxv4f32"
        )]
        fn _svclasta_n_f32(pg: svbool4_t, fallback: f32, data: svfloat32_t) -> f32;
    }
    unsafe { _svclasta_n_f32(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_n_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_n_f64(pg: svbool_t, fallback: f64, data: svfloat64_t) -> f64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.clasta.n.nxv2f64"
        )]
        fn _svclasta_n_f64(pg: svbool2_t, fallback: f64, data: svfloat64_t) -> f64;
    }
    unsafe { _svclasta_n_f64(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_n_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_n_s8(pg: svbool_t, fallback: i8, data: svint8_t) -> i8 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.clasta.n.nxv16i8"
        )]
        fn _svclasta_n_s8(pg: svbool_t, fallback: i8, data: svint8_t) -> i8;
    }
    unsafe { _svclasta_n_s8(pg, fallback, data) }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_n_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_n_s16(pg: svbool_t, fallback: i16, data: svint16_t) -> i16 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.clasta.n.nxv8i16"
        )]
        fn _svclasta_n_s16(pg: svbool8_t, fallback: i16, data: svint16_t) -> i16;
    }
    unsafe { _svclasta_n_s16(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_n_s32(pg: svbool_t, fallback: i32, data: svint32_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.clasta.n.nxv4i32"
        )]
        fn _svclasta_n_s32(pg: svbool4_t, fallback: i32, data: svint32_t) -> i32;
    }
    unsafe { _svclasta_n_s32(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_n_s64(pg: svbool_t, fallback: i64, data: svint64_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.clasta.n.nxv2i64"
        )]
        fn _svclasta_n_s64(pg: svbool2_t, fallback: i64, data: svint64_t) -> i64;
    }
    unsafe { _svclasta_n_s64(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_n_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_n_u8(pg: svbool_t, fallback: u8, data: svuint8_t) -> u8 {
    unsafe { svclasta_n_s8(pg, fallback.as_signed(), data.as_signed()).as_unsigned() }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_n_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_n_u16(pg: svbool_t, fallback: u16, data: svuint16_t) -> u16 {
    unsafe { svclasta_n_s16(pg, fallback.as_signed(), data.as_signed()).as_unsigned() }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_n_u32(pg: svbool_t, fallback: u32, data: svuint32_t) -> u32 {
    unsafe { svclasta_n_s32(pg, fallback.as_signed(), data.as_signed()).as_unsigned() }
}
#[doc = "Conditionally extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclasta[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clasta))]
pub fn svclasta_n_u64(pg: svbool_t, fallback: u64, data: svuint64_t) -> u64 {
    unsafe { svclasta_n_s64(pg, fallback.as_signed(), data.as_signed()).as_unsigned() }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_f32(pg: svbool_t, fallback: svfloat32_t, data: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clastb.nxv4f32")]
        fn _svclastb_f32(pg: svbool4_t, fallback: svfloat32_t, data: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svclastb_f32(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_f64(pg: svbool_t, fallback: svfloat64_t, data: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clastb.nxv2f64")]
        fn _svclastb_f64(pg: svbool2_t, fallback: svfloat64_t, data: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svclastb_f64(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_s8(pg: svbool_t, fallback: svint8_t, data: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clastb.nxv16i8")]
        fn _svclastb_s8(pg: svbool_t, fallback: svint8_t, data: svint8_t) -> svint8_t;
    }
    unsafe { _svclastb_s8(pg, fallback, data) }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_s16(pg: svbool_t, fallback: svint16_t, data: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clastb.nxv8i16")]
        fn _svclastb_s16(pg: svbool8_t, fallback: svint16_t, data: svint16_t) -> svint16_t;
    }
    unsafe { _svclastb_s16(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_s32(pg: svbool_t, fallback: svint32_t, data: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clastb.nxv4i32")]
        fn _svclastb_s32(pg: svbool4_t, fallback: svint32_t, data: svint32_t) -> svint32_t;
    }
    unsafe { _svclastb_s32(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_s64(pg: svbool_t, fallback: svint64_t, data: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clastb.nxv2i64")]
        fn _svclastb_s64(pg: svbool2_t, fallback: svint64_t, data: svint64_t) -> svint64_t;
    }
    unsafe { _svclastb_s64(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_u8(pg: svbool_t, fallback: svuint8_t, data: svuint8_t) -> svuint8_t {
    unsafe { svclastb_s8(pg, fallback.as_signed(), data.as_signed()).as_unsigned() }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_u16(pg: svbool_t, fallback: svuint16_t, data: svuint16_t) -> svuint16_t {
    unsafe { svclastb_s16(pg, fallback.as_signed(), data.as_signed()).as_unsigned() }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_u32(pg: svbool_t, fallback: svuint32_t, data: svuint32_t) -> svuint32_t {
    unsafe { svclastb_s32(pg, fallback.as_signed(), data.as_signed()).as_unsigned() }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_u64(pg: svbool_t, fallback: svuint64_t, data: svuint64_t) -> svuint64_t {
    unsafe { svclastb_s64(pg, fallback.as_signed(), data.as_signed()).as_unsigned() }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_n_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_n_f32(pg: svbool_t, fallback: f32, data: svfloat32_t) -> f32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.clastb.n.nxv4f32"
        )]
        fn _svclastb_n_f32(pg: svbool4_t, fallback: f32, data: svfloat32_t) -> f32;
    }
    unsafe { _svclastb_n_f32(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_n_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_n_f64(pg: svbool_t, fallback: f64, data: svfloat64_t) -> f64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.clastb.n.nxv2f64"
        )]
        fn _svclastb_n_f64(pg: svbool2_t, fallback: f64, data: svfloat64_t) -> f64;
    }
    unsafe { _svclastb_n_f64(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_n_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_n_s8(pg: svbool_t, fallback: i8, data: svint8_t) -> i8 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.clastb.n.nxv16i8"
        )]
        fn _svclastb_n_s8(pg: svbool_t, fallback: i8, data: svint8_t) -> i8;
    }
    unsafe { _svclastb_n_s8(pg, fallback, data) }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_n_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_n_s16(pg: svbool_t, fallback: i16, data: svint16_t) -> i16 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.clastb.n.nxv8i16"
        )]
        fn _svclastb_n_s16(pg: svbool8_t, fallback: i16, data: svint16_t) -> i16;
    }
    unsafe { _svclastb_n_s16(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_n_s32(pg: svbool_t, fallback: i32, data: svint32_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.clastb.n.nxv4i32"
        )]
        fn _svclastb_n_s32(pg: svbool4_t, fallback: i32, data: svint32_t) -> i32;
    }
    unsafe { _svclastb_n_s32(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_n_s64(pg: svbool_t, fallback: i64, data: svint64_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.clastb.n.nxv2i64"
        )]
        fn _svclastb_n_s64(pg: svbool2_t, fallback: i64, data: svint64_t) -> i64;
    }
    unsafe { _svclastb_n_s64(pg.into(), fallback, data) }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_n_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_n_u8(pg: svbool_t, fallback: u8, data: svuint8_t) -> u8 {
    unsafe { svclastb_n_s8(pg, fallback.as_signed(), data.as_signed()).as_unsigned() }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_n_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_n_u16(pg: svbool_t, fallback: u16, data: svuint16_t) -> u16 {
    unsafe { svclastb_n_s16(pg, fallback.as_signed(), data.as_signed()).as_unsigned() }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_n_u32(pg: svbool_t, fallback: u32, data: svuint32_t) -> u32 {
    unsafe { svclastb_n_s32(pg, fallback.as_signed(), data.as_signed()).as_unsigned() }
}
#[doc = "Conditionally extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclastb[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clastb))]
pub fn svclastb_n_u64(pg: svbool_t, fallback: u64, data: svuint64_t) -> u64 {
    unsafe { svclastb_n_s64(pg, fallback.as_signed(), data.as_signed()).as_unsigned() }
}
#[doc = "Count leading sign bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcls[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub fn svcls_s8_m(inactive: svuint8_t, pg: svbool_t, op: svint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cls.nxv16i8")]
        fn _svcls_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t;
    }
    unsafe { _svcls_s8_m(inactive.as_signed(), pg, op).as_unsigned() }
}
#[doc = "Count leading sign bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcls[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub fn svcls_s8_x(pg: svbool_t, op: svint8_t) -> svuint8_t {
    unsafe { svcls_s8_m(op.as_unsigned(), pg, op) }
}
#[doc = "Count leading sign bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcls[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub fn svcls_s8_z(pg: svbool_t, op: svint8_t) -> svuint8_t {
    svcls_s8_m(svdup_n_u8(0), pg, op)
}
#[doc = "Count leading sign bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcls[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub fn svcls_s16_m(inactive: svuint16_t, pg: svbool_t, op: svint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cls.nxv8i16")]
        fn _svcls_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svcls_s16_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[doc = "Count leading sign bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcls[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub fn svcls_s16_x(pg: svbool_t, op: svint16_t) -> svuint16_t {
    unsafe { svcls_s16_m(op.as_unsigned(), pg, op) }
}
#[doc = "Count leading sign bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcls[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub fn svcls_s16_z(pg: svbool_t, op: svint16_t) -> svuint16_t {
    svcls_s16_m(svdup_n_u16(0), pg, op)
}
#[doc = "Count leading sign bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcls[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub fn svcls_s32_m(inactive: svuint32_t, pg: svbool_t, op: svint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cls.nxv4i32")]
        fn _svcls_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svcls_s32_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[doc = "Count leading sign bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcls[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub fn svcls_s32_x(pg: svbool_t, op: svint32_t) -> svuint32_t {
    unsafe { svcls_s32_m(op.as_unsigned(), pg, op) }
}
#[doc = "Count leading sign bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcls[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub fn svcls_s32_z(pg: svbool_t, op: svint32_t) -> svuint32_t {
    svcls_s32_m(svdup_n_u32(0), pg, op)
}
#[doc = "Count leading sign bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcls[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub fn svcls_s64_m(inactive: svuint64_t, pg: svbool_t, op: svint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cls.nxv2i64")]
        fn _svcls_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svcls_s64_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[doc = "Count leading sign bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcls[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub fn svcls_s64_x(pg: svbool_t, op: svint64_t) -> svuint64_t {
    unsafe { svcls_s64_m(op.as_unsigned(), pg, op) }
}
#[doc = "Count leading sign bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcls[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cls))]
pub fn svcls_s64_z(pg: svbool_t, op: svint64_t) -> svuint64_t {
    svcls_s64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_s8_m(inactive: svuint8_t, pg: svbool_t, op: svint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clz.nxv16i8")]
        fn _svclz_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t;
    }
    unsafe { _svclz_s8_m(inactive.as_signed(), pg, op).as_unsigned() }
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_s8_x(pg: svbool_t, op: svint8_t) -> svuint8_t {
    unsafe { svclz_s8_m(op.as_unsigned(), pg, op) }
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_s8_z(pg: svbool_t, op: svint8_t) -> svuint8_t {
    svclz_s8_m(svdup_n_u8(0), pg, op)
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_s16_m(inactive: svuint16_t, pg: svbool_t, op: svint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clz.nxv8i16")]
        fn _svclz_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svclz_s16_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_s16_x(pg: svbool_t, op: svint16_t) -> svuint16_t {
    unsafe { svclz_s16_m(op.as_unsigned(), pg, op) }
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_s16_z(pg: svbool_t, op: svint16_t) -> svuint16_t {
    svclz_s16_m(svdup_n_u16(0), pg, op)
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_s32_m(inactive: svuint32_t, pg: svbool_t, op: svint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clz.nxv4i32")]
        fn _svclz_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svclz_s32_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_s32_x(pg: svbool_t, op: svint32_t) -> svuint32_t {
    unsafe { svclz_s32_m(op.as_unsigned(), pg, op) }
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_s32_z(pg: svbool_t, op: svint32_t) -> svuint32_t {
    svclz_s32_m(svdup_n_u32(0), pg, op)
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_s64_m(inactive: svuint64_t, pg: svbool_t, op: svint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.clz.nxv2i64")]
        fn _svclz_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svclz_s64_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_s64_x(pg: svbool_t, op: svint64_t) -> svuint64_t {
    unsafe { svclz_s64_m(op.as_unsigned(), pg, op) }
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_s64_z(pg: svbool_t, op: svint64_t) -> svuint64_t {
    svclz_s64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_u8_m(inactive: svuint8_t, pg: svbool_t, op: svuint8_t) -> svuint8_t {
    unsafe { svclz_s8_m(inactive, pg, op.as_signed()) }
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_u8_x(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svclz_u8_m(op, pg, op)
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_u8_z(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svclz_u8_m(svdup_n_u8(0), pg, op)
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_u16_m(inactive: svuint16_t, pg: svbool_t, op: svuint16_t) -> svuint16_t {
    unsafe { svclz_s16_m(inactive, pg, op.as_signed()) }
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_u16_x(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svclz_u16_m(op, pg, op)
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_u16_z(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svclz_u16_m(svdup_n_u16(0), pg, op)
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    unsafe { svclz_s32_m(inactive, pg, op.as_signed()) }
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svclz_u32_m(op, pg, op)
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svclz_u32_m(svdup_n_u32(0), pg, op)
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svclz_s64_m(inactive, pg, op.as_signed()) }
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svclz_u64_m(op, pg, op)
}
#[doc = "Count leading zero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svclz[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(clz))]
pub fn svclz_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svclz_u64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Complex multiply-add with rotate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmla[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmla, IMM_ROTATION = 90))]
pub fn svcmla_f32_m<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    static_assert!(
        IMM_ROTATION == 0 || IMM_ROTATION == 90 || IMM_ROTATION == 180 || IMM_ROTATION == 270
    );
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmla.nxv4f32")]
        fn _svcmla_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
            imm_rotation: i32,
        ) -> svfloat32_t;
    }
    unsafe { _svcmla_f32_m(pg.into(), op1, op2, op3, IMM_ROTATION) }
}
#[doc = "Complex multiply-add with rotate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmla[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmla, IMM_ROTATION = 90))]
pub fn svcmla_f32_x<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svcmla_f32_m::<IMM_ROTATION>(pg, op1, op2, op3)
}
#[doc = "Complex multiply-add with rotate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmla[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmla, IMM_ROTATION = 90))]
pub fn svcmla_f32_z<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svcmla_f32_m::<IMM_ROTATION>(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[doc = "Complex multiply-add with rotate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmla[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmla, IMM_ROTATION = 90))]
pub fn svcmla_f64_m<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    static_assert!(
        IMM_ROTATION == 0 || IMM_ROTATION == 90 || IMM_ROTATION == 180 || IMM_ROTATION == 270
    );
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmla.nxv2f64")]
        fn _svcmla_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
            imm_rotation: i32,
        ) -> svfloat64_t;
    }
    unsafe { _svcmla_f64_m(pg.into(), op1, op2, op3, IMM_ROTATION) }
}
#[doc = "Complex multiply-add with rotate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmla[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmla, IMM_ROTATION = 90))]
pub fn svcmla_f64_x<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svcmla_f64_m::<IMM_ROTATION>(pg, op1, op2, op3)
}
#[doc = "Complex multiply-add with rotate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmla[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmla, IMM_ROTATION = 90))]
pub fn svcmla_f64_z<const IMM_ROTATION: i32>(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svcmla_f64_m::<IMM_ROTATION>(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[doc = "Complex multiply-add with rotate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmla_lane[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmla, IMM_INDEX = 0, IMM_ROTATION = 90))]
pub fn svcmla_lane_f32<const IMM_INDEX: i32, const IMM_ROTATION: i32>(
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    static_assert!(
        IMM_ROTATION == 0 || IMM_ROTATION == 90 || IMM_ROTATION == 180 || IMM_ROTATION == 270
    );
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fcmla.lane.x.nxv4f32"
        )]
        fn _svcmla_lane_f32(
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
            imm_index: i32,
            imm_rotation: i32,
        ) -> svfloat32_t;
    }
    unsafe { _svcmla_lane_f32(op1, op2, op3, IMM_INDEX, IMM_ROTATION) }
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmeq))]
pub fn svcmpeq_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpeq.nxv4f32")]
        fn _svcmpeq_f32(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool4_t;
    }
    unsafe { _svcmpeq_f32(pg.into(), op1, op2).into() }
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_n_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmeq))]
pub fn svcmpeq_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svcmpeq_f32(pg, op1, svdup_n_f32(op2))
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmeq))]
pub fn svcmpeq_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpeq.nxv2f64")]
        fn _svcmpeq_f64(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool2_t;
    }
    unsafe { _svcmpeq_f64(pg.into(), op1, op2).into() }
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_n_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmeq))]
pub fn svcmpeq_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svcmpeq_f64(pg, op1, svdup_n_f64(op2))
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpeq.nxv16i8")]
        fn _svcmpeq_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t;
    }
    unsafe { _svcmpeq_s8(pg, op1, op2) }
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_n_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_n_s8(pg: svbool_t, op1: svint8_t, op2: i8) -> svbool_t {
    svcmpeq_s8(pg, op1, svdup_n_s8(op2))
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_s16(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpeq.nxv8i16")]
        fn _svcmpeq_s16(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svbool8_t;
    }
    unsafe { _svcmpeq_s16(pg.into(), op1, op2).into() }
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_n_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_n_s16(pg: svbool_t, op1: svint16_t, op2: i16) -> svbool_t {
    svcmpeq_s16(pg, op1, svdup_n_s16(op2))
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_s32(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpeq.nxv4i32")]
        fn _svcmpeq_s32(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svbool4_t;
    }
    unsafe { _svcmpeq_s32(pg.into(), op1, op2).into() }
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_n_s32(pg: svbool_t, op1: svint32_t, op2: i32) -> svbool_t {
    svcmpeq_s32(pg, op1, svdup_n_s32(op2))
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_s64(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpeq.nxv2i64")]
        fn _svcmpeq_s64(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svbool2_t;
    }
    unsafe { _svcmpeq_s64(pg.into(), op1, op2).into() }
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_n_s64(pg: svbool_t, op1: svint64_t, op2: i64) -> svbool_t {
    svcmpeq_s64(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_u8(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svbool_t {
    unsafe { svcmpeq_s8(pg, op1.as_signed(), op2.as_signed()) }
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_n_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_n_u8(pg: svbool_t, op1: svuint8_t, op2: u8) -> svbool_t {
    svcmpeq_u8(pg, op1, svdup_n_u8(op2))
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_u16(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svbool_t {
    unsafe { svcmpeq_s16(pg, op1.as_signed(), op2.as_signed()) }
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_n_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_n_u16(pg: svbool_t, op1: svuint16_t, op2: u16) -> svbool_t {
    svcmpeq_u16(pg, op1, svdup_n_u16(op2))
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_u32(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svbool_t {
    unsafe { svcmpeq_s32(pg, op1.as_signed(), op2.as_signed()) }
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_n_u32(pg: svbool_t, op1: svuint32_t, op2: u32) -> svbool_t {
    svcmpeq_u32(pg, op1, svdup_n_u32(op2))
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_u64(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svbool_t {
    unsafe { svcmpeq_s64(pg, op1.as_signed(), op2.as_signed()) }
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_n_u64(pg: svbool_t, op1: svuint64_t, op2: u64) -> svbool_t {
    svcmpeq_u64(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq_wide[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpeq.wide.nxv16i8"
        )]
        fn _svcmpeq_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmpeq_wide_s8(pg, op1, op2) }
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq_wide[_n_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_wide_n_s8(pg: svbool_t, op1: svint8_t, op2: i64) -> svbool_t {
    svcmpeq_wide_s8(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq_wide[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_wide_s16(pg: svbool_t, op1: svint16_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpeq.wide.nxv8i16"
        )]
        fn _svcmpeq_wide_s16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmpeq_wide_s16(pg.into(), op1, op2).into() }
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq_wide[_n_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_wide_n_s16(pg: svbool_t, op1: svint16_t, op2: i64) -> svbool_t {
    svcmpeq_wide_s16(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq_wide[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_wide_s32(pg: svbool_t, op1: svint32_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpeq.wide.nxv4i32"
        )]
        fn _svcmpeq_wide_s32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmpeq_wide_s32(pg.into(), op1, op2).into() }
}
#[doc = "Compare equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpeq_wide[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpeq))]
pub fn svcmpeq_wide_n_s32(pg: svbool_t, op1: svint32_t, op2: i64) -> svbool_t {
    svcmpeq_wide_s32(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmge))]
pub fn svcmpge_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpge.nxv4f32")]
        fn _svcmpge_f32(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool4_t;
    }
    unsafe { _svcmpge_f32(pg.into(), op1, op2).into() }
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_n_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmge))]
pub fn svcmpge_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svcmpge_f32(pg, op1, svdup_n_f32(op2))
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmge))]
pub fn svcmpge_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpge.nxv2f64")]
        fn _svcmpge_f64(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool2_t;
    }
    unsafe { _svcmpge_f64(pg.into(), op1, op2).into() }
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_n_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmge))]
pub fn svcmpge_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svcmpge_f64(pg, op1, svdup_n_f64(op2))
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmpge_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpge.nxv16i8")]
        fn _svcmpge_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t;
    }
    unsafe { _svcmpge_s8(pg, op1, op2) }
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_n_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmpge_n_s8(pg: svbool_t, op1: svint8_t, op2: i8) -> svbool_t {
    svcmpge_s8(pg, op1, svdup_n_s8(op2))
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmpge_s16(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpge.nxv8i16")]
        fn _svcmpge_s16(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svbool8_t;
    }
    unsafe { _svcmpge_s16(pg.into(), op1, op2).into() }
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_n_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmpge_n_s16(pg: svbool_t, op1: svint16_t, op2: i16) -> svbool_t {
    svcmpge_s16(pg, op1, svdup_n_s16(op2))
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmpge_s32(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpge.nxv4i32")]
        fn _svcmpge_s32(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svbool4_t;
    }
    unsafe { _svcmpge_s32(pg.into(), op1, op2).into() }
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmpge_n_s32(pg: svbool_t, op1: svint32_t, op2: i32) -> svbool_t {
    svcmpge_s32(pg, op1, svdup_n_s32(op2))
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmpge_s64(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpge.nxv2i64")]
        fn _svcmpge_s64(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svbool2_t;
    }
    unsafe { _svcmpge_s64(pg.into(), op1, op2).into() }
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmpge_n_s64(pg: svbool_t, op1: svint64_t, op2: i64) -> svbool_t {
    svcmpge_s64(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmpge_u8(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmphs.nxv16i8")]
        fn _svcmpge_u8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t;
    }
    unsafe { _svcmpge_u8(pg, op1.as_signed(), op2.as_signed()) }
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_n_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmpge_n_u8(pg: svbool_t, op1: svuint8_t, op2: u8) -> svbool_t {
    svcmpge_u8(pg, op1, svdup_n_u8(op2))
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmpge_u16(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmphs.nxv8i16")]
        fn _svcmpge_u16(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svbool8_t;
    }
    unsafe { _svcmpge_u16(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_n_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmpge_n_u16(pg: svbool_t, op1: svuint16_t, op2: u16) -> svbool_t {
    svcmpge_u16(pg, op1, svdup_n_u16(op2))
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmpge_u32(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmphs.nxv4i32")]
        fn _svcmpge_u32(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svbool4_t;
    }
    unsafe { _svcmpge_u32(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmpge_n_u32(pg: svbool_t, op1: svuint32_t, op2: u32) -> svbool_t {
    svcmpge_u32(pg, op1, svdup_n_u32(op2))
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmpge_u64(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmphs.nxv2i64")]
        fn _svcmpge_u64(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svbool2_t;
    }
    unsafe { _svcmpge_u64(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmpge_n_u64(pg: svbool_t, op1: svuint64_t, op2: u64) -> svbool_t {
    svcmpge_u64(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge_wide[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmpge_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpge.wide.nxv16i8"
        )]
        fn _svcmpge_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmpge_wide_s8(pg, op1, op2) }
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge_wide[_n_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmpge_wide_n_s8(pg: svbool_t, op1: svint8_t, op2: i64) -> svbool_t {
    svcmpge_wide_s8(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge_wide[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmpge_wide_s16(pg: svbool_t, op1: svint16_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpge.wide.nxv8i16"
        )]
        fn _svcmpge_wide_s16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmpge_wide_s16(pg.into(), op1, op2).into() }
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge_wide[_n_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmpge_wide_n_s16(pg: svbool_t, op1: svint16_t, op2: i64) -> svbool_t {
    svcmpge_wide_s16(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge_wide[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmpge_wide_s32(pg: svbool_t, op1: svint32_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpge.wide.nxv4i32"
        )]
        fn _svcmpge_wide_s32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmpge_wide_s32(pg.into(), op1, op2).into() }
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge_wide[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmpge_wide_n_s32(pg: svbool_t, op1: svint32_t, op2: i64) -> svbool_t {
    svcmpge_wide_s32(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge_wide[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmpge_wide_u8(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmphs.wide.nxv16i8"
        )]
        fn _svcmpge_wide_u8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmpge_wide_u8(pg, op1.as_signed(), op2.as_signed()) }
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge_wide[_n_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmpge_wide_n_u8(pg: svbool_t, op1: svuint8_t, op2: u64) -> svbool_t {
    svcmpge_wide_u8(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge_wide[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmpge_wide_u16(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmphs.wide.nxv8i16"
        )]
        fn _svcmpge_wide_u16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmpge_wide_u16(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge_wide[_n_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmpge_wide_n_u16(pg: svbool_t, op1: svuint16_t, op2: u64) -> svbool_t {
    svcmpge_wide_u16(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge_wide[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmpge_wide_u32(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmphs.wide.nxv4i32"
        )]
        fn _svcmpge_wide_u32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmpge_wide_u32(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "Compare greater than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpge_wide[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmpge_wide_n_u32(pg: svbool_t, op1: svuint32_t, op2: u64) -> svbool_t {
    svcmpge_wide_u32(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmgt))]
pub fn svcmpgt_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpgt.nxv4f32")]
        fn _svcmpgt_f32(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool4_t;
    }
    unsafe { _svcmpgt_f32(pg.into(), op1, op2).into() }
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_n_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmgt))]
pub fn svcmpgt_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svcmpgt_f32(pg, op1, svdup_n_f32(op2))
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmgt))]
pub fn svcmpgt_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpgt.nxv2f64")]
        fn _svcmpgt_f64(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool2_t;
    }
    unsafe { _svcmpgt_f64(pg.into(), op1, op2).into() }
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_n_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmgt))]
pub fn svcmpgt_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svcmpgt_f64(pg, op1, svdup_n_f64(op2))
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmpgt_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpgt.nxv16i8")]
        fn _svcmpgt_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t;
    }
    unsafe { _svcmpgt_s8(pg, op1, op2) }
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_n_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmpgt_n_s8(pg: svbool_t, op1: svint8_t, op2: i8) -> svbool_t {
    svcmpgt_s8(pg, op1, svdup_n_s8(op2))
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmpgt_s16(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpgt.nxv8i16")]
        fn _svcmpgt_s16(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svbool8_t;
    }
    unsafe { _svcmpgt_s16(pg.into(), op1, op2).into() }
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_n_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmpgt_n_s16(pg: svbool_t, op1: svint16_t, op2: i16) -> svbool_t {
    svcmpgt_s16(pg, op1, svdup_n_s16(op2))
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmpgt_s32(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpgt.nxv4i32")]
        fn _svcmpgt_s32(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svbool4_t;
    }
    unsafe { _svcmpgt_s32(pg.into(), op1, op2).into() }
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmpgt_n_s32(pg: svbool_t, op1: svint32_t, op2: i32) -> svbool_t {
    svcmpgt_s32(pg, op1, svdup_n_s32(op2))
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmpgt_s64(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpgt.nxv2i64")]
        fn _svcmpgt_s64(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svbool2_t;
    }
    unsafe { _svcmpgt_s64(pg.into(), op1, op2).into() }
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmpgt_n_s64(pg: svbool_t, op1: svint64_t, op2: i64) -> svbool_t {
    svcmpgt_s64(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmpgt_u8(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmphi.nxv16i8")]
        fn _svcmpgt_u8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t;
    }
    unsafe { _svcmpgt_u8(pg, op1.as_signed(), op2.as_signed()) }
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_n_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmpgt_n_u8(pg: svbool_t, op1: svuint8_t, op2: u8) -> svbool_t {
    svcmpgt_u8(pg, op1, svdup_n_u8(op2))
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmpgt_u16(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmphi.nxv8i16")]
        fn _svcmpgt_u16(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svbool8_t;
    }
    unsafe { _svcmpgt_u16(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_n_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmpgt_n_u16(pg: svbool_t, op1: svuint16_t, op2: u16) -> svbool_t {
    svcmpgt_u16(pg, op1, svdup_n_u16(op2))
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmpgt_u32(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmphi.nxv4i32")]
        fn _svcmpgt_u32(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svbool4_t;
    }
    unsafe { _svcmpgt_u32(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmpgt_n_u32(pg: svbool_t, op1: svuint32_t, op2: u32) -> svbool_t {
    svcmpgt_u32(pg, op1, svdup_n_u32(op2))
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmpgt_u64(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmphi.nxv2i64")]
        fn _svcmpgt_u64(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svbool2_t;
    }
    unsafe { _svcmpgt_u64(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmpgt_n_u64(pg: svbool_t, op1: svuint64_t, op2: u64) -> svbool_t {
    svcmpgt_u64(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt_wide[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmpgt_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpgt.wide.nxv16i8"
        )]
        fn _svcmpgt_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmpgt_wide_s8(pg, op1, op2) }
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt_wide[_n_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmpgt_wide_n_s8(pg: svbool_t, op1: svint8_t, op2: i64) -> svbool_t {
    svcmpgt_wide_s8(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt_wide[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmpgt_wide_s16(pg: svbool_t, op1: svint16_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpgt.wide.nxv8i16"
        )]
        fn _svcmpgt_wide_s16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmpgt_wide_s16(pg.into(), op1, op2).into() }
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt_wide[_n_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmpgt_wide_n_s16(pg: svbool_t, op1: svint16_t, op2: i64) -> svbool_t {
    svcmpgt_wide_s16(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt_wide[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmpgt_wide_s32(pg: svbool_t, op1: svint32_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpgt.wide.nxv4i32"
        )]
        fn _svcmpgt_wide_s32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmpgt_wide_s32(pg.into(), op1, op2).into() }
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt_wide[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmpgt_wide_n_s32(pg: svbool_t, op1: svint32_t, op2: i64) -> svbool_t {
    svcmpgt_wide_s32(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt_wide[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmpgt_wide_u8(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmphi.wide.nxv16i8"
        )]
        fn _svcmpgt_wide_u8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmpgt_wide_u8(pg, op1.as_signed(), op2.as_signed()) }
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt_wide[_n_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmpgt_wide_n_u8(pg: svbool_t, op1: svuint8_t, op2: u64) -> svbool_t {
    svcmpgt_wide_u8(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt_wide[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmpgt_wide_u16(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmphi.wide.nxv8i16"
        )]
        fn _svcmpgt_wide_u16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmpgt_wide_u16(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt_wide[_n_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmpgt_wide_n_u16(pg: svbool_t, op1: svuint16_t, op2: u64) -> svbool_t {
    svcmpgt_wide_u16(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt_wide[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmpgt_wide_u32(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmphi.wide.nxv4i32"
        )]
        fn _svcmpgt_wide_u32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmpgt_wide_u32(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "Compare greater than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpgt_wide[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmpgt_wide_n_u32(pg: svbool_t, op1: svuint32_t, op2: u64) -> svbool_t {
    svcmpgt_wide_u32(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmge))]
pub fn svcmple_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    svcmpge_f32(pg, op2, op1)
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_n_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmge))]
pub fn svcmple_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svcmple_f32(pg, op1, svdup_n_f32(op2))
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmge))]
pub fn svcmple_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    svcmpge_f64(pg, op2, op1)
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_n_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmge))]
pub fn svcmple_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svcmple_f64(pg, op1, svdup_n_f64(op2))
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmple_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t {
    svcmpge_s8(pg, op2, op1)
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_n_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmple_n_s8(pg: svbool_t, op1: svint8_t, op2: i8) -> svbool_t {
    svcmple_s8(pg, op1, svdup_n_s8(op2))
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmple_s16(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svbool_t {
    svcmpge_s16(pg, op2, op1)
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_n_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmple_n_s16(pg: svbool_t, op1: svint16_t, op2: i16) -> svbool_t {
    svcmple_s16(pg, op1, svdup_n_s16(op2))
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmple_s32(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svbool_t {
    svcmpge_s32(pg, op2, op1)
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmple_n_s32(pg: svbool_t, op1: svint32_t, op2: i32) -> svbool_t {
    svcmple_s32(pg, op1, svdup_n_s32(op2))
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmple_s64(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svbool_t {
    svcmpge_s64(pg, op2, op1)
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpge))]
pub fn svcmple_n_s64(pg: svbool_t, op1: svint64_t, op2: i64) -> svbool_t {
    svcmple_s64(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmple_u8(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svbool_t {
    svcmpge_u8(pg, op2, op1)
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_n_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmple_n_u8(pg: svbool_t, op1: svuint8_t, op2: u8) -> svbool_t {
    svcmple_u8(pg, op1, svdup_n_u8(op2))
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmple_u16(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svbool_t {
    svcmpge_u16(pg, op2, op1)
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_n_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmple_n_u16(pg: svbool_t, op1: svuint16_t, op2: u16) -> svbool_t {
    svcmple_u16(pg, op1, svdup_n_u16(op2))
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmple_u32(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svbool_t {
    svcmpge_u32(pg, op2, op1)
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmple_n_u32(pg: svbool_t, op1: svuint32_t, op2: u32) -> svbool_t {
    svcmple_u32(pg, op1, svdup_n_u32(op2))
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmple_u64(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svbool_t {
    svcmpge_u64(pg, op2, op1)
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphs))]
pub fn svcmple_n_u64(pg: svbool_t, op1: svuint64_t, op2: u64) -> svbool_t {
    svcmple_u64(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple_wide[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmple))]
pub fn svcmple_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmple.wide.nxv16i8"
        )]
        fn _svcmple_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmple_wide_s8(pg, op1, op2) }
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple_wide[_n_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmple))]
pub fn svcmple_wide_n_s8(pg: svbool_t, op1: svint8_t, op2: i64) -> svbool_t {
    svcmple_wide_s8(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple_wide[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmple))]
pub fn svcmple_wide_s16(pg: svbool_t, op1: svint16_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmple.wide.nxv8i16"
        )]
        fn _svcmple_wide_s16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmple_wide_s16(pg.into(), op1, op2).into() }
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple_wide[_n_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmple))]
pub fn svcmple_wide_n_s16(pg: svbool_t, op1: svint16_t, op2: i64) -> svbool_t {
    svcmple_wide_s16(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple_wide[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmple))]
pub fn svcmple_wide_s32(pg: svbool_t, op1: svint32_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmple.wide.nxv4i32"
        )]
        fn _svcmple_wide_s32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmple_wide_s32(pg.into(), op1, op2).into() }
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple_wide[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmple))]
pub fn svcmple_wide_n_s32(pg: svbool_t, op1: svint32_t, op2: i64) -> svbool_t {
    svcmple_wide_s32(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple_wide[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpls))]
pub fn svcmple_wide_u8(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpls.wide.nxv16i8"
        )]
        fn _svcmple_wide_u8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmple_wide_u8(pg, op1.as_signed(), op2.as_signed()) }
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple_wide[_n_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpls))]
pub fn svcmple_wide_n_u8(pg: svbool_t, op1: svuint8_t, op2: u64) -> svbool_t {
    svcmple_wide_u8(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple_wide[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpls))]
pub fn svcmple_wide_u16(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpls.wide.nxv8i16"
        )]
        fn _svcmple_wide_u16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmple_wide_u16(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple_wide[_n_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpls))]
pub fn svcmple_wide_n_u16(pg: svbool_t, op1: svuint16_t, op2: u64) -> svbool_t {
    svcmple_wide_u16(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple_wide[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpls))]
pub fn svcmple_wide_u32(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpls.wide.nxv4i32"
        )]
        fn _svcmple_wide_u32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmple_wide_u32(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "Compare less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmple_wide[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpls))]
pub fn svcmple_wide_n_u32(pg: svbool_t, op1: svuint32_t, op2: u64) -> svbool_t {
    svcmple_wide_u32(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmgt))]
pub fn svcmplt_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    svcmpgt_f32(pg, op2, op1)
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_n_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmgt))]
pub fn svcmplt_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svcmplt_f32(pg, op1, svdup_n_f32(op2))
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmgt))]
pub fn svcmplt_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    svcmpgt_f64(pg, op2, op1)
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_n_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmgt))]
pub fn svcmplt_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svcmplt_f64(pg, op1, svdup_n_f64(op2))
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmplt_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t {
    svcmpgt_s8(pg, op2, op1)
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_n_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmplt_n_s8(pg: svbool_t, op1: svint8_t, op2: i8) -> svbool_t {
    svcmplt_s8(pg, op1, svdup_n_s8(op2))
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmplt_s16(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svbool_t {
    svcmpgt_s16(pg, op2, op1)
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_n_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmplt_n_s16(pg: svbool_t, op1: svint16_t, op2: i16) -> svbool_t {
    svcmplt_s16(pg, op1, svdup_n_s16(op2))
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmplt_s32(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svbool_t {
    svcmpgt_s32(pg, op2, op1)
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmplt_n_s32(pg: svbool_t, op1: svint32_t, op2: i32) -> svbool_t {
    svcmplt_s32(pg, op1, svdup_n_s32(op2))
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmplt_s64(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svbool_t {
    svcmpgt_s64(pg, op2, op1)
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpgt))]
pub fn svcmplt_n_s64(pg: svbool_t, op1: svint64_t, op2: i64) -> svbool_t {
    svcmplt_s64(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmplt_u8(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svbool_t {
    svcmpgt_u8(pg, op2, op1)
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_n_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmplt_n_u8(pg: svbool_t, op1: svuint8_t, op2: u8) -> svbool_t {
    svcmplt_u8(pg, op1, svdup_n_u8(op2))
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmplt_u16(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svbool_t {
    svcmpgt_u16(pg, op2, op1)
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_n_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmplt_n_u16(pg: svbool_t, op1: svuint16_t, op2: u16) -> svbool_t {
    svcmplt_u16(pg, op1, svdup_n_u16(op2))
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmplt_u32(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svbool_t {
    svcmpgt_u32(pg, op2, op1)
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmplt_n_u32(pg: svbool_t, op1: svuint32_t, op2: u32) -> svbool_t {
    svcmplt_u32(pg, op1, svdup_n_u32(op2))
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmplt_u64(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svbool_t {
    svcmpgt_u64(pg, op2, op1)
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmphi))]
pub fn svcmplt_n_u64(pg: svbool_t, op1: svuint64_t, op2: u64) -> svbool_t {
    svcmplt_u64(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt_wide[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplt))]
pub fn svcmplt_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmplt.wide.nxv16i8"
        )]
        fn _svcmplt_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmplt_wide_s8(pg, op1, op2) }
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt_wide[_n_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplt))]
pub fn svcmplt_wide_n_s8(pg: svbool_t, op1: svint8_t, op2: i64) -> svbool_t {
    svcmplt_wide_s8(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt_wide[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplt))]
pub fn svcmplt_wide_s16(pg: svbool_t, op1: svint16_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmplt.wide.nxv8i16"
        )]
        fn _svcmplt_wide_s16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmplt_wide_s16(pg.into(), op1, op2).into() }
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt_wide[_n_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplt))]
pub fn svcmplt_wide_n_s16(pg: svbool_t, op1: svint16_t, op2: i64) -> svbool_t {
    svcmplt_wide_s16(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt_wide[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplt))]
pub fn svcmplt_wide_s32(pg: svbool_t, op1: svint32_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmplt.wide.nxv4i32"
        )]
        fn _svcmplt_wide_s32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmplt_wide_s32(pg.into(), op1, op2).into() }
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt_wide[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplt))]
pub fn svcmplt_wide_n_s32(pg: svbool_t, op1: svint32_t, op2: i64) -> svbool_t {
    svcmplt_wide_s32(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt_wide[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplo))]
pub fn svcmplt_wide_u8(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmplo.wide.nxv16i8"
        )]
        fn _svcmplt_wide_u8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmplt_wide_u8(pg, op1.as_signed(), op2.as_signed()) }
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt_wide[_n_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplo))]
pub fn svcmplt_wide_n_u8(pg: svbool_t, op1: svuint8_t, op2: u64) -> svbool_t {
    svcmplt_wide_u8(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt_wide[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplo))]
pub fn svcmplt_wide_u16(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmplo.wide.nxv8i16"
        )]
        fn _svcmplt_wide_u16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmplt_wide_u16(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt_wide[_n_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplo))]
pub fn svcmplt_wide_n_u16(pg: svbool_t, op1: svuint16_t, op2: u64) -> svbool_t {
    svcmplt_wide_u16(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt_wide[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplo))]
pub fn svcmplt_wide_u32(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmplo.wide.nxv4i32"
        )]
        fn _svcmplt_wide_u32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmplt_wide_u32(pg.into(), op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "Compare less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmplt_wide[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmplo))]
pub fn svcmplt_wide_n_u32(pg: svbool_t, op1: svuint32_t, op2: u64) -> svbool_t {
    svcmplt_wide_u32(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmne))]
pub fn svcmpne_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpne.nxv4f32")]
        fn _svcmpne_f32(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool4_t;
    }
    unsafe { _svcmpne_f32(pg.into(), op1, op2).into() }
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_n_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmne))]
pub fn svcmpne_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svcmpne_f32(pg, op1, svdup_n_f32(op2))
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmne))]
pub fn svcmpne_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpne.nxv2f64")]
        fn _svcmpne_f64(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool2_t;
    }
    unsafe { _svcmpne_f64(pg.into(), op1, op2).into() }
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_n_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmne))]
pub fn svcmpne_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svcmpne_f64(pg, op1, svdup_n_f64(op2))
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpne.nxv16i8")]
        fn _svcmpne_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svbool_t;
    }
    unsafe { _svcmpne_s8(pg, op1, op2) }
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_n_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_n_s8(pg: svbool_t, op1: svint8_t, op2: i8) -> svbool_t {
    svcmpne_s8(pg, op1, svdup_n_s8(op2))
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_s16(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpne.nxv8i16")]
        fn _svcmpne_s16(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svbool8_t;
    }
    unsafe { _svcmpne_s16(pg.into(), op1, op2).into() }
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_n_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_n_s16(pg: svbool_t, op1: svint16_t, op2: i16) -> svbool_t {
    svcmpne_s16(pg, op1, svdup_n_s16(op2))
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_s32(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpne.nxv4i32")]
        fn _svcmpne_s32(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svbool4_t;
    }
    unsafe { _svcmpne_s32(pg.into(), op1, op2).into() }
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_n_s32(pg: svbool_t, op1: svint32_t, op2: i32) -> svbool_t {
    svcmpne_s32(pg, op1, svdup_n_s32(op2))
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_s64(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cmpne.nxv2i64")]
        fn _svcmpne_s64(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svbool2_t;
    }
    unsafe { _svcmpne_s64(pg.into(), op1, op2).into() }
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_n_s64(pg: svbool_t, op1: svint64_t, op2: i64) -> svbool_t {
    svcmpne_s64(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_u8(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svbool_t {
    unsafe { svcmpne_s8(pg, op1.as_signed(), op2.as_signed()) }
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_n_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_n_u8(pg: svbool_t, op1: svuint8_t, op2: u8) -> svbool_t {
    svcmpne_u8(pg, op1, svdup_n_u8(op2))
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_u16(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svbool_t {
    unsafe { svcmpne_s16(pg, op1.as_signed(), op2.as_signed()) }
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_n_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_n_u16(pg: svbool_t, op1: svuint16_t, op2: u16) -> svbool_t {
    svcmpne_u16(pg, op1, svdup_n_u16(op2))
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_u32(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svbool_t {
    unsafe { svcmpne_s32(pg, op1.as_signed(), op2.as_signed()) }
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_n_u32(pg: svbool_t, op1: svuint32_t, op2: u32) -> svbool_t {
    svcmpne_u32(pg, op1, svdup_n_u32(op2))
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_u64(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svbool_t {
    unsafe { svcmpne_s64(pg, op1.as_signed(), op2.as_signed()) }
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_n_u64(pg: svbool_t, op1: svuint64_t, op2: u64) -> svbool_t {
    svcmpne_u64(pg, op1, svdup_n_u64(op2))
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne_wide[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpne.wide.nxv16i8"
        )]
        fn _svcmpne_wide_s8(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svbool_t;
    }
    unsafe { _svcmpne_wide_s8(pg, op1, op2) }
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne_wide[_n_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_wide_n_s8(pg: svbool_t, op1: svint8_t, op2: i64) -> svbool_t {
    svcmpne_wide_s8(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne_wide[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_wide_s16(pg: svbool_t, op1: svint16_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpne.wide.nxv8i16"
        )]
        fn _svcmpne_wide_s16(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svbool8_t;
    }
    unsafe { _svcmpne_wide_s16(pg.into(), op1, op2).into() }
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne_wide[_n_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_wide_n_s16(pg: svbool_t, op1: svint16_t, op2: i64) -> svbool_t {
    svcmpne_wide_s16(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne_wide[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_wide_s32(pg: svbool_t, op1: svint32_t, op2: svint64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.cmpne.wide.nxv4i32"
        )]
        fn _svcmpne_wide_s32(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svbool4_t;
    }
    unsafe { _svcmpne_wide_s32(pg.into(), op1, op2).into() }
}
#[doc = "Compare not equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpne_wide[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cmpne))]
pub fn svcmpne_wide_n_s32(pg: svbool_t, op1: svint32_t, op2: i64) -> svbool_t {
    svcmpne_wide_s32(pg, op1, svdup_n_s64(op2))
}
#[doc = "Compare unordered with"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpuo[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmuo))]
pub fn svcmpuo_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpuo.nxv4f32")]
        fn _svcmpuo_f32(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svbool4_t;
    }
    unsafe { _svcmpuo_f32(pg.into(), op1, op2).into() }
}
#[doc = "Compare unordered with"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpuo[_n_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmuo))]
pub fn svcmpuo_n_f32(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svbool_t {
    svcmpuo_f32(pg, op1, svdup_n_f32(op2))
}
#[doc = "Compare unordered with"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpuo[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmuo))]
pub fn svcmpuo_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcmpuo.nxv2f64")]
        fn _svcmpuo_f64(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svbool2_t;
    }
    unsafe { _svcmpuo_f64(pg.into(), op1, op2).into() }
}
#[doc = "Compare unordered with"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcmpuo[_n_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcmuo))]
pub fn svcmpuo_n_f64(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svbool_t {
    svcmpuo_f64(pg, op1, svdup_n_f64(op2))
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnot.nxv16i8")]
        fn _svcnot_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t;
    }
    unsafe { _svcnot_s8_m(inactive, pg, op) }
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_s8_x(pg: svbool_t, op: svint8_t) -> svint8_t {
    svcnot_s8_m(op, pg, op)
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_s8_z(pg: svbool_t, op: svint8_t) -> svint8_t {
    svcnot_s8_m(svdup_n_s8(0), pg, op)
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_s16_m(inactive: svint16_t, pg: svbool_t, op: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnot.nxv8i16")]
        fn _svcnot_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svcnot_s16_m(inactive, pg.into(), op) }
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_s16_x(pg: svbool_t, op: svint16_t) -> svint16_t {
    svcnot_s16_m(op, pg, op)
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_s16_z(pg: svbool_t, op: svint16_t) -> svint16_t {
    svcnot_s16_m(svdup_n_s16(0), pg, op)
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_s32_m(inactive: svint32_t, pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnot.nxv4i32")]
        fn _svcnot_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svcnot_s32_m(inactive, pg.into(), op) }
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_s32_x(pg: svbool_t, op: svint32_t) -> svint32_t {
    svcnot_s32_m(op, pg, op)
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_s32_z(pg: svbool_t, op: svint32_t) -> svint32_t {
    svcnot_s32_m(svdup_n_s32(0), pg, op)
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnot.nxv2i64")]
        fn _svcnot_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svcnot_s64_m(inactive, pg.into(), op) }
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svcnot_s64_m(op, pg, op)
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svcnot_s64_m(svdup_n_s64(0), pg, op)
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_u8_m(inactive: svuint8_t, pg: svbool_t, op: svuint8_t) -> svuint8_t {
    unsafe { svcnot_s8_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_u8_x(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svcnot_u8_m(op, pg, op)
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_u8_z(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svcnot_u8_m(svdup_n_u8(0), pg, op)
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_u16_m(inactive: svuint16_t, pg: svbool_t, op: svuint16_t) -> svuint16_t {
    unsafe { svcnot_s16_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_u16_x(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svcnot_u16_m(op, pg, op)
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_u16_z(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svcnot_u16_m(svdup_n_u16(0), pg, op)
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    unsafe { svcnot_s32_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svcnot_u32_m(op, pg, op)
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svcnot_u32_m(svdup_n_u32(0), pg, op)
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svcnot_s64_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svcnot_u64_m(op, pg, op)
}
#[doc = "Logically invert boolean condition"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnot[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnot))]
pub fn svcnot_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svcnot_u64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_f32_m(inactive: svuint32_t, pg: svbool_t, op: svfloat32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnt.nxv4f32")]
        fn _svcnt_f32_m(inactive: svint32_t, pg: svbool4_t, op: svfloat32_t) -> svint32_t;
    }
    unsafe { _svcnt_f32_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_f32_x(pg: svbool_t, op: svfloat32_t) -> svuint32_t {
    unsafe { svcnt_f32_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_f32_z(pg: svbool_t, op: svfloat32_t) -> svuint32_t {
    svcnt_f32_m(svdup_n_u32(0), pg, op)
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_f64_m(inactive: svuint64_t, pg: svbool_t, op: svfloat64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnt.nxv2f64")]
        fn _svcnt_f64_m(inactive: svint64_t, pg: svbool2_t, op: svfloat64_t) -> svint64_t;
    }
    unsafe { _svcnt_f64_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_f64_x(pg: svbool_t, op: svfloat64_t) -> svuint64_t {
    unsafe { svcnt_f64_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_f64_z(pg: svbool_t, op: svfloat64_t) -> svuint64_t {
    svcnt_f64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_s8_m(inactive: svuint8_t, pg: svbool_t, op: svint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnt.nxv16i8")]
        fn _svcnt_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t;
    }
    unsafe { _svcnt_s8_m(inactive.as_signed(), pg, op).as_unsigned() }
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_s8_x(pg: svbool_t, op: svint8_t) -> svuint8_t {
    unsafe { svcnt_s8_m(op.as_unsigned(), pg, op) }
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_s8_z(pg: svbool_t, op: svint8_t) -> svuint8_t {
    svcnt_s8_m(svdup_n_u8(0), pg, op)
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_s16_m(inactive: svuint16_t, pg: svbool_t, op: svint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnt.nxv8i16")]
        fn _svcnt_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svcnt_s16_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_s16_x(pg: svbool_t, op: svint16_t) -> svuint16_t {
    unsafe { svcnt_s16_m(op.as_unsigned(), pg, op) }
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_s16_z(pg: svbool_t, op: svint16_t) -> svuint16_t {
    svcnt_s16_m(svdup_n_u16(0), pg, op)
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_s32_m(inactive: svuint32_t, pg: svbool_t, op: svint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnt.nxv4i32")]
        fn _svcnt_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svcnt_s32_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_s32_x(pg: svbool_t, op: svint32_t) -> svuint32_t {
    unsafe { svcnt_s32_m(op.as_unsigned(), pg, op) }
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_s32_z(pg: svbool_t, op: svint32_t) -> svuint32_t {
    svcnt_s32_m(svdup_n_u32(0), pg, op)
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_s64_m(inactive: svuint64_t, pg: svbool_t, op: svint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnt.nxv2i64")]
        fn _svcnt_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svcnt_s64_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_s64_x(pg: svbool_t, op: svint64_t) -> svuint64_t {
    unsafe { svcnt_s64_m(op.as_unsigned(), pg, op) }
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_s64_z(pg: svbool_t, op: svint64_t) -> svuint64_t {
    svcnt_s64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_u8_m(inactive: svuint8_t, pg: svbool_t, op: svuint8_t) -> svuint8_t {
    unsafe { svcnt_s8_m(inactive, pg, op.as_signed()) }
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_u8_x(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svcnt_u8_m(op, pg, op)
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_u8_z(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svcnt_u8_m(svdup_n_u8(0), pg, op)
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_u16_m(inactive: svuint16_t, pg: svbool_t, op: svuint16_t) -> svuint16_t {
    unsafe { svcnt_s16_m(inactive, pg, op.as_signed()) }
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_u16_x(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svcnt_u16_m(op, pg, op)
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_u16_z(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svcnt_u16_m(svdup_n_u16(0), pg, op)
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    unsafe { svcnt_s32_m(inactive, pg, op.as_signed()) }
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svcnt_u32_m(op, pg, op)
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svcnt_u32_m(svdup_n_u32(0), pg, op)
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svcnt_s64_m(inactive, pg, op.as_signed()) }
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svcnt_u64_m(op, pg, op)
}
#[doc = "Count nonzero bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnt[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnt))]
pub fn svcnt_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svcnt_u64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Count the number of 8-bit elements in a vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcntb)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rdvl))]
pub fn svcntb() -> u64 {
    svcntb_pat::<{ svpattern::SV_ALL }>()
}
#[doc = "Count the number of 16-bit elements in a vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnth)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnth))]
pub fn svcnth() -> u64 {
    svcnth_pat::<{ svpattern::SV_ALL }>()
}
#[doc = "Count the number of 32-bit elements in a vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcntw)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntw))]
pub fn svcntw() -> u64 {
    svcntw_pat::<{ svpattern::SV_ALL }>()
}
#[doc = "Count the number of 64-bit elements in a vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcntd)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntd))]
pub fn svcntd() -> u64 {
    svcntd_pat::<{ svpattern::SV_ALL }>()
}
#[doc = "Count the number of 8-bit elements in a vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcntb_pat)"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (rdvl , PATTERN = { svpattern :: SV_ALL }))]
# [cfg_attr (test , assert_instr (cntb , PATTERN = { svpattern :: SV_MUL4 }))]
pub fn svcntb_pat<const PATTERN: svpattern>() -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cntb")]
        fn _svcntb_pat(pattern: svpattern) -> i64;
    }
    unsafe { _svcntb_pat(PATTERN).as_unsigned() }
}
#[doc = "Count the number of 16-bit elements in a vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcnth_pat)"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (cnth , PATTERN = { svpattern :: SV_ALL }))]
pub fn svcnth_pat<const PATTERN: svpattern>() -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cnth")]
        fn _svcnth_pat(pattern: svpattern) -> i64;
    }
    unsafe { _svcnth_pat(PATTERN).as_unsigned() }
}
#[doc = "Count the number of 32-bit elements in a vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcntw_pat)"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (cntw , PATTERN = { svpattern :: SV_ALL }))]
pub fn svcntw_pat<const PATTERN: svpattern>() -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cntw")]
        fn _svcntw_pat(pattern: svpattern) -> i64;
    }
    unsafe { _svcntw_pat(PATTERN).as_unsigned() }
}
#[doc = "Count the number of 64-bit elements in a vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcntd_pat)"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (cntd , PATTERN = { svpattern :: SV_ALL }))]
pub fn svcntd_pat<const PATTERN: svpattern>() -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cntd")]
        fn _svcntd_pat(pattern: svpattern) -> i64;
    }
    unsafe { _svcntd_pat(PATTERN).as_unsigned() }
}
#[doc = "Count set predicate bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcntp_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntp))]
pub fn svcntp_b8(pg: svbool_t, op: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cntp.nxv16i1")]
        fn _svcntp_b8(pg: svbool_t, op: svbool_t) -> i64;
    }
    unsafe { _svcntp_b8(pg, op).as_unsigned() }
}
#[doc = "Count set predicate bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcntp_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntp))]
pub fn svcntp_b16(pg: svbool_t, op: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cntp.nxv8i1")]
        fn _svcntp_b16(pg: svbool8_t, op: svbool8_t) -> i64;
    }
    unsafe { _svcntp_b16(pg.into(), op.into()).as_unsigned() }
}
#[doc = "Count set predicate bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcntp_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntp))]
pub fn svcntp_b32(pg: svbool_t, op: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cntp.nxv4i1")]
        fn _svcntp_b32(pg: svbool4_t, op: svbool4_t) -> i64;
    }
    unsafe { _svcntp_b32(pg.into(), op.into()).as_unsigned() }
}
#[doc = "Count set predicate bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcntp_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntp))]
pub fn svcntp_b64(pg: svbool_t, op: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.cntp.nxv2i1")]
        fn _svcntp_b64(pg: svbool2_t, op: svbool2_t) -> i64;
    }
    unsafe { _svcntp_b64(pg.into(), op.into()).as_unsigned() }
}
#[doc = "Shuffle active elements of vector to the right and fill with zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcompact[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(compact))]
pub fn svcompact_f32(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.compact.nxv4f32"
        )]
        fn _svcompact_f32(pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svcompact_f32(pg.into(), op) }
}
#[doc = "Shuffle active elements of vector to the right and fill with zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcompact[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(compact))]
pub fn svcompact_f64(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.compact.nxv2f64"
        )]
        fn _svcompact_f64(pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svcompact_f64(pg.into(), op) }
}
#[doc = "Shuffle active elements of vector to the right and fill with zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcompact[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(compact))]
pub fn svcompact_s32(pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.compact.nxv4i32"
        )]
        fn _svcompact_s32(pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svcompact_s32(pg.into(), op) }
}
#[doc = "Shuffle active elements of vector to the right and fill with zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcompact[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(compact))]
pub fn svcompact_s64(pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.compact.nxv2i64"
        )]
        fn _svcompact_s64(pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svcompact_s64(pg.into(), op) }
}
#[doc = "Shuffle active elements of vector to the right and fill with zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcompact[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(compact))]
pub fn svcompact_u32(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    unsafe { svcompact_s32(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Shuffle active elements of vector to the right and fill with zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcompact[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(compact))]
pub fn svcompact_u64(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svcompact_s64(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Create a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate2[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate2_f32(x0: svfloat32_t, x1: svfloat32_t) -> svfloat32x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create2.nxv8f32.nxv4f32"
        )]
        fn _svcreate2_f32(x0: svfloat32_t, x1: svfloat32_t) -> svfloat32x2_t;
    }
    unsafe { _svcreate2_f32(x0, x1) }
}
#[doc = "Create a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate2[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate2_f64(x0: svfloat64_t, x1: svfloat64_t) -> svfloat64x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create2.nxv4f64.nxv2f64"
        )]
        fn _svcreate2_f64(x0: svfloat64_t, x1: svfloat64_t) -> svfloat64x2_t;
    }
    unsafe { _svcreate2_f64(x0, x1) }
}
#[doc = "Create a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate2[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate2_s8(x0: svint8_t, x1: svint8_t) -> svint8x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create2.nxv32i8.nxv16i8"
        )]
        fn _svcreate2_s8(x0: svint8_t, x1: svint8_t) -> svint8x2_t;
    }
    unsafe { _svcreate2_s8(x0, x1) }
}
#[doc = "Create a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate2[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate2_s16(x0: svint16_t, x1: svint16_t) -> svint16x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create2.nxv16i16.nxv8i16"
        )]
        fn _svcreate2_s16(x0: svint16_t, x1: svint16_t) -> svint16x2_t;
    }
    unsafe { _svcreate2_s16(x0, x1) }
}
#[doc = "Create a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate2[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate2_s32(x0: svint32_t, x1: svint32_t) -> svint32x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create2.nxv8i32.nxv4i32"
        )]
        fn _svcreate2_s32(x0: svint32_t, x1: svint32_t) -> svint32x2_t;
    }
    unsafe { _svcreate2_s32(x0, x1) }
}
#[doc = "Create a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate2[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate2_s64(x0: svint64_t, x1: svint64_t) -> svint64x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create2.nxv4i64.nxv2i64"
        )]
        fn _svcreate2_s64(x0: svint64_t, x1: svint64_t) -> svint64x2_t;
    }
    unsafe { _svcreate2_s64(x0, x1) }
}
#[doc = "Create a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate2[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate2_u8(x0: svuint8_t, x1: svuint8_t) -> svuint8x2_t {
    unsafe { svcreate2_s8(x0.as_signed(), x1.as_signed()).as_unsigned() }
}
#[doc = "Create a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate2[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate2_u16(x0: svuint16_t, x1: svuint16_t) -> svuint16x2_t {
    unsafe { svcreate2_s16(x0.as_signed(), x1.as_signed()).as_unsigned() }
}
#[doc = "Create a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate2[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate2_u32(x0: svuint32_t, x1: svuint32_t) -> svuint32x2_t {
    unsafe { svcreate2_s32(x0.as_signed(), x1.as_signed()).as_unsigned() }
}
#[doc = "Create a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate2[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate2_u64(x0: svuint64_t, x1: svuint64_t) -> svuint64x2_t {
    unsafe { svcreate2_s64(x0.as_signed(), x1.as_signed()).as_unsigned() }
}
#[doc = "Create a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate3[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate3_f32(x0: svfloat32_t, x1: svfloat32_t, x2: svfloat32_t) -> svfloat32x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create3.nxv12f32.nxv4f32"
        )]
        fn _svcreate3_f32(x0: svfloat32_t, x1: svfloat32_t, x2: svfloat32_t) -> svfloat32x3_t;
    }
    unsafe { _svcreate3_f32(x0, x1, x2) }
}
#[doc = "Create a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate3[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate3_f64(x0: svfloat64_t, x1: svfloat64_t, x2: svfloat64_t) -> svfloat64x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create3.nxv6f64.nxv2f64"
        )]
        fn _svcreate3_f64(x0: svfloat64_t, x1: svfloat64_t, x2: svfloat64_t) -> svfloat64x3_t;
    }
    unsafe { _svcreate3_f64(x0, x1, x2) }
}
#[doc = "Create a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate3[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate3_s8(x0: svint8_t, x1: svint8_t, x2: svint8_t) -> svint8x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create3.nxv48i8.nxv16i8"
        )]
        fn _svcreate3_s8(x0: svint8_t, x1: svint8_t, x2: svint8_t) -> svint8x3_t;
    }
    unsafe { _svcreate3_s8(x0, x1, x2) }
}
#[doc = "Create a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate3[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate3_s16(x0: svint16_t, x1: svint16_t, x2: svint16_t) -> svint16x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create3.nxv24i16.nxv8i16"
        )]
        fn _svcreate3_s16(x0: svint16_t, x1: svint16_t, x2: svint16_t) -> svint16x3_t;
    }
    unsafe { _svcreate3_s16(x0, x1, x2) }
}
#[doc = "Create a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate3[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate3_s32(x0: svint32_t, x1: svint32_t, x2: svint32_t) -> svint32x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create3.nxv12i32.nxv4i32"
        )]
        fn _svcreate3_s32(x0: svint32_t, x1: svint32_t, x2: svint32_t) -> svint32x3_t;
    }
    unsafe { _svcreate3_s32(x0, x1, x2) }
}
#[doc = "Create a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate3[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate3_s64(x0: svint64_t, x1: svint64_t, x2: svint64_t) -> svint64x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create3.nxv6i64.nxv2i64"
        )]
        fn _svcreate3_s64(x0: svint64_t, x1: svint64_t, x2: svint64_t) -> svint64x3_t;
    }
    unsafe { _svcreate3_s64(x0, x1, x2) }
}
#[doc = "Create a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate3[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate3_u8(x0: svuint8_t, x1: svuint8_t, x2: svuint8_t) -> svuint8x3_t {
    unsafe { svcreate3_s8(x0.as_signed(), x1.as_signed(), x2.as_signed()).as_unsigned() }
}
#[doc = "Create a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate3[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate3_u16(x0: svuint16_t, x1: svuint16_t, x2: svuint16_t) -> svuint16x3_t {
    unsafe { svcreate3_s16(x0.as_signed(), x1.as_signed(), x2.as_signed()).as_unsigned() }
}
#[doc = "Create a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate3[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate3_u32(x0: svuint32_t, x1: svuint32_t, x2: svuint32_t) -> svuint32x3_t {
    unsafe { svcreate3_s32(x0.as_signed(), x1.as_signed(), x2.as_signed()).as_unsigned() }
}
#[doc = "Create a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate3[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate3_u64(x0: svuint64_t, x1: svuint64_t, x2: svuint64_t) -> svuint64x3_t {
    unsafe { svcreate3_s64(x0.as_signed(), x1.as_signed(), x2.as_signed()).as_unsigned() }
}
#[doc = "Create a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate4[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate4_f32(
    x0: svfloat32_t,
    x1: svfloat32_t,
    x2: svfloat32_t,
    x3: svfloat32_t,
) -> svfloat32x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create4.nxv16f32.nxv4f32"
        )]
        fn _svcreate4_f32(
            x0: svfloat32_t,
            x1: svfloat32_t,
            x2: svfloat32_t,
            x3: svfloat32_t,
        ) -> svfloat32x4_t;
    }
    unsafe { _svcreate4_f32(x0, x1, x2, x3) }
}
#[doc = "Create a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate4[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate4_f64(
    x0: svfloat64_t,
    x1: svfloat64_t,
    x2: svfloat64_t,
    x3: svfloat64_t,
) -> svfloat64x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create4.nxv8f64.nxv2f64"
        )]
        fn _svcreate4_f64(
            x0: svfloat64_t,
            x1: svfloat64_t,
            x2: svfloat64_t,
            x3: svfloat64_t,
        ) -> svfloat64x4_t;
    }
    unsafe { _svcreate4_f64(x0, x1, x2, x3) }
}
#[doc = "Create a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate4[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate4_s8(x0: svint8_t, x1: svint8_t, x2: svint8_t, x3: svint8_t) -> svint8x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create4.nxv64i8.nxv16i8"
        )]
        fn _svcreate4_s8(x0: svint8_t, x1: svint8_t, x2: svint8_t, x3: svint8_t) -> svint8x4_t;
    }
    unsafe { _svcreate4_s8(x0, x1, x2, x3) }
}
#[doc = "Create a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate4[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate4_s16(x0: svint16_t, x1: svint16_t, x2: svint16_t, x3: svint16_t) -> svint16x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create4.nxv32i16.nxv8i16"
        )]
        fn _svcreate4_s16(
            x0: svint16_t,
            x1: svint16_t,
            x2: svint16_t,
            x3: svint16_t,
        ) -> svint16x4_t;
    }
    unsafe { _svcreate4_s16(x0, x1, x2, x3) }
}
#[doc = "Create a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate4[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate4_s32(x0: svint32_t, x1: svint32_t, x2: svint32_t, x3: svint32_t) -> svint32x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create4.nxv16i32.nxv4i32"
        )]
        fn _svcreate4_s32(
            x0: svint32_t,
            x1: svint32_t,
            x2: svint32_t,
            x3: svint32_t,
        ) -> svint32x4_t;
    }
    unsafe { _svcreate4_s32(x0, x1, x2, x3) }
}
#[doc = "Create a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate4[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate4_s64(x0: svint64_t, x1: svint64_t, x2: svint64_t, x3: svint64_t) -> svint64x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.create4.nxv8i64.nxv2i64"
        )]
        fn _svcreate4_s64(
            x0: svint64_t,
            x1: svint64_t,
            x2: svint64_t,
            x3: svint64_t,
        ) -> svint64x4_t;
    }
    unsafe { _svcreate4_s64(x0, x1, x2, x3) }
}
#[doc = "Create a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate4[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate4_u8(x0: svuint8_t, x1: svuint8_t, x2: svuint8_t, x3: svuint8_t) -> svuint8x4_t {
    unsafe {
        svcreate4_s8(
            x0.as_signed(),
            x1.as_signed(),
            x2.as_signed(),
            x3.as_signed(),
        )
        .as_unsigned()
    }
}
#[doc = "Create a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate4[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate4_u16(
    x0: svuint16_t,
    x1: svuint16_t,
    x2: svuint16_t,
    x3: svuint16_t,
) -> svuint16x4_t {
    unsafe {
        svcreate4_s16(
            x0.as_signed(),
            x1.as_signed(),
            x2.as_signed(),
            x3.as_signed(),
        )
        .as_unsigned()
    }
}
#[doc = "Create a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate4[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate4_u32(
    x0: svuint32_t,
    x1: svuint32_t,
    x2: svuint32_t,
    x3: svuint32_t,
) -> svuint32x4_t {
    unsafe {
        svcreate4_s32(
            x0.as_signed(),
            x1.as_signed(),
            x2.as_signed(),
            x3.as_signed(),
        )
        .as_unsigned()
    }
}
#[doc = "Create a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcreate4[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svcreate4_u64(
    x0: svuint64_t,
    x1: svuint64_t,
    x2: svuint64_t,
    x3: svuint64_t,
) -> svuint64x4_t {
    unsafe {
        svcreate4_s64(
            x0.as_signed(),
            x1.as_signed(),
            x2.as_signed(),
            x3.as_signed(),
        )
        .as_unsigned()
    }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f32[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvt))]
pub fn svcvt_f32_f64_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat64_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvt.f32f64")]
        fn _svcvt_f32_f64_m(inactive: svfloat32_t, pg: svbool2_t, op: svfloat64_t) -> svfloat32_t;
    }
    unsafe { _svcvt_f32_f64_m(inactive, pg.into(), op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f32[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvt))]
pub fn svcvt_f32_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat32_t {
    unsafe { svcvt_f32_f64_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f32[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvt))]
pub fn svcvt_f32_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat32_t {
    svcvt_f32_f64_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f64[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvt))]
pub fn svcvt_f64_f32_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat32_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvt.f64f32")]
        fn _svcvt_f64_f32_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat32_t) -> svfloat64_t;
    }
    unsafe { _svcvt_f64_f32_m(inactive, pg.into(), op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f64[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvt))]
pub fn svcvt_f64_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat64_t {
    unsafe { svcvt_f64_f32_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f64[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvt))]
pub fn svcvt_f64_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat64_t {
    svcvt_f64_f32_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f32[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub fn svcvt_f32_s32_m(inactive: svfloat32_t, pg: svbool_t, op: svint32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.scvtf.nxv4f32.nxv4i32"
        )]
        fn _svcvt_f32_s32_m(inactive: svfloat32_t, pg: svbool4_t, op: svint32_t) -> svfloat32_t;
    }
    unsafe { _svcvt_f32_s32_m(inactive, pg.into(), op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f32[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub fn svcvt_f32_s32_x(pg: svbool_t, op: svint32_t) -> svfloat32_t {
    unsafe { svcvt_f32_s32_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f32[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub fn svcvt_f32_s32_z(pg: svbool_t, op: svint32_t) -> svfloat32_t {
    svcvt_f32_s32_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f32[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub fn svcvt_f32_s64_m(inactive: svfloat32_t, pg: svbool_t, op: svint64_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.scvtf.f32i64")]
        fn _svcvt_f32_s64_m(inactive: svfloat32_t, pg: svbool2_t, op: svint64_t) -> svfloat32_t;
    }
    unsafe { _svcvt_f32_s64_m(inactive, pg.into(), op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f32[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub fn svcvt_f32_s64_x(pg: svbool_t, op: svint64_t) -> svfloat32_t {
    unsafe { svcvt_f32_s64_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f32[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub fn svcvt_f32_s64_z(pg: svbool_t, op: svint64_t) -> svfloat32_t {
    svcvt_f32_s64_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f32[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub fn svcvt_f32_u32_m(inactive: svfloat32_t, pg: svbool_t, op: svuint32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ucvtf.nxv4f32.nxv4i32"
        )]
        fn _svcvt_f32_u32_m(inactive: svfloat32_t, pg: svbool4_t, op: svint32_t) -> svfloat32_t;
    }
    unsafe { _svcvt_f32_u32_m(inactive, pg.into(), op.as_signed()) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f32[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub fn svcvt_f32_u32_x(pg: svbool_t, op: svuint32_t) -> svfloat32_t {
    unsafe { svcvt_f32_u32_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f32[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub fn svcvt_f32_u32_z(pg: svbool_t, op: svuint32_t) -> svfloat32_t {
    svcvt_f32_u32_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f32[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub fn svcvt_f32_u64_m(inactive: svfloat32_t, pg: svbool_t, op: svuint64_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ucvtf.f32i64")]
        fn _svcvt_f32_u64_m(inactive: svfloat32_t, pg: svbool2_t, op: svint64_t) -> svfloat32_t;
    }
    unsafe { _svcvt_f32_u64_m(inactive, pg.into(), op.as_signed()) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f32[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub fn svcvt_f32_u64_x(pg: svbool_t, op: svuint64_t) -> svfloat32_t {
    unsafe { svcvt_f32_u64_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f32[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub fn svcvt_f32_u64_z(pg: svbool_t, op: svuint64_t) -> svfloat32_t {
    svcvt_f32_u64_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f64[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub fn svcvt_f64_s32_m(inactive: svfloat64_t, pg: svbool_t, op: svint32_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.scvtf.nxv2f64.nxv4i32"
        )]
        fn _svcvt_f64_s32_m(inactive: svfloat64_t, pg: svbool2_t, op: svint32_t) -> svfloat64_t;
    }
    unsafe { _svcvt_f64_s32_m(inactive, pg.into(), op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f64[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub fn svcvt_f64_s32_x(pg: svbool_t, op: svint32_t) -> svfloat64_t {
    unsafe { svcvt_f64_s32_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f64[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub fn svcvt_f64_s32_z(pg: svbool_t, op: svint32_t) -> svfloat64_t {
    svcvt_f64_s32_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f64[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub fn svcvt_f64_s64_m(inactive: svfloat64_t, pg: svbool_t, op: svint64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.scvtf.nxv2f64.nxv2i64"
        )]
        fn _svcvt_f64_s64_m(inactive: svfloat64_t, pg: svbool2_t, op: svint64_t) -> svfloat64_t;
    }
    unsafe { _svcvt_f64_s64_m(inactive, pg.into(), op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f64[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub fn svcvt_f64_s64_x(pg: svbool_t, op: svint64_t) -> svfloat64_t {
    unsafe { svcvt_f64_s64_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f64[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(scvtf))]
pub fn svcvt_f64_s64_z(pg: svbool_t, op: svint64_t) -> svfloat64_t {
    svcvt_f64_s64_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f64[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub fn svcvt_f64_u32_m(inactive: svfloat64_t, pg: svbool_t, op: svuint32_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ucvtf.nxv2f64.nxv4i32"
        )]
        fn _svcvt_f64_u32_m(inactive: svfloat64_t, pg: svbool2_t, op: svint32_t) -> svfloat64_t;
    }
    unsafe { _svcvt_f64_u32_m(inactive, pg.into(), op.as_signed()) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f64[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub fn svcvt_f64_u32_x(pg: svbool_t, op: svuint32_t) -> svfloat64_t {
    unsafe { svcvt_f64_u32_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f64[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub fn svcvt_f64_u32_z(pg: svbool_t, op: svuint32_t) -> svfloat64_t {
    svcvt_f64_u32_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f64[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub fn svcvt_f64_u64_m(inactive: svfloat64_t, pg: svbool_t, op: svuint64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ucvtf.nxv2f64.nxv2i64"
        )]
        fn _svcvt_f64_u64_m(inactive: svfloat64_t, pg: svbool2_t, op: svint64_t) -> svfloat64_t;
    }
    unsafe { _svcvt_f64_u64_m(inactive, pg.into(), op.as_signed()) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f64[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub fn svcvt_f64_u64_x(pg: svbool_t, op: svuint64_t) -> svfloat64_t {
    unsafe { svcvt_f64_u64_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_f64[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ucvtf))]
pub fn svcvt_f64_u64_z(pg: svbool_t, op: svuint64_t) -> svfloat64_t {
    svcvt_f64_u64_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_s32[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub fn svcvt_s32_f32_m(inactive: svint32_t, pg: svbool_t, op: svfloat32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvtzs.i32f32")]
        fn _svcvt_s32_f32_m(inactive: svint32_t, pg: svbool4_t, op: svfloat32_t) -> svint32_t;
    }
    unsafe { _svcvt_s32_f32_m(inactive, pg.into(), op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_s32[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub fn svcvt_s32_f32_x(pg: svbool_t, op: svfloat32_t) -> svint32_t {
    unsafe { svcvt_s32_f32_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_s32[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub fn svcvt_s32_f32_z(pg: svbool_t, op: svfloat32_t) -> svint32_t {
    svcvt_s32_f32_m(svdup_n_s32(0), pg, op)
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_s32[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub fn svcvt_s32_f64_m(inactive: svint32_t, pg: svbool_t, op: svfloat64_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvtzs.i32f64")]
        fn _svcvt_s32_f64_m(inactive: svint32_t, pg: svbool2_t, op: svfloat64_t) -> svint32_t;
    }
    unsafe { _svcvt_s32_f64_m(inactive, pg.into(), op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_s32[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub fn svcvt_s32_f64_x(pg: svbool_t, op: svfloat64_t) -> svint32_t {
    unsafe { svcvt_s32_f64_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_s32[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub fn svcvt_s32_f64_z(pg: svbool_t, op: svfloat64_t) -> svint32_t {
    svcvt_s32_f64_m(svdup_n_s32(0), pg, op)
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_s64[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub fn svcvt_s64_f32_m(inactive: svint64_t, pg: svbool_t, op: svfloat32_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvtzs.i64f32")]
        fn _svcvt_s64_f32_m(inactive: svint64_t, pg: svbool2_t, op: svfloat32_t) -> svint64_t;
    }
    unsafe { _svcvt_s64_f32_m(inactive, pg.into(), op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_s64[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub fn svcvt_s64_f32_x(pg: svbool_t, op: svfloat32_t) -> svint64_t {
    unsafe { svcvt_s64_f32_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_s64[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub fn svcvt_s64_f32_z(pg: svbool_t, op: svfloat32_t) -> svint64_t {
    svcvt_s64_f32_m(svdup_n_s64(0), pg, op)
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_s64[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub fn svcvt_s64_f64_m(inactive: svint64_t, pg: svbool_t, op: svfloat64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvtzs.i64f64")]
        fn _svcvt_s64_f64_m(inactive: svint64_t, pg: svbool2_t, op: svfloat64_t) -> svint64_t;
    }
    unsafe { _svcvt_s64_f64_m(inactive, pg.into(), op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_s64[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub fn svcvt_s64_f64_x(pg: svbool_t, op: svfloat64_t) -> svint64_t {
    unsafe { svcvt_s64_f64_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_s64[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzs))]
pub fn svcvt_s64_f64_z(pg: svbool_t, op: svfloat64_t) -> svint64_t {
    svcvt_s64_f64_m(svdup_n_s64(0), pg, op)
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_u32[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub fn svcvt_u32_f32_m(inactive: svuint32_t, pg: svbool_t, op: svfloat32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvtzu.i32f32")]
        fn _svcvt_u32_f32_m(inactive: svint32_t, pg: svbool4_t, op: svfloat32_t) -> svint32_t;
    }
    unsafe { _svcvt_u32_f32_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_u32[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub fn svcvt_u32_f32_x(pg: svbool_t, op: svfloat32_t) -> svuint32_t {
    unsafe { svcvt_u32_f32_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_u32[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub fn svcvt_u32_f32_z(pg: svbool_t, op: svfloat32_t) -> svuint32_t {
    svcvt_u32_f32_m(svdup_n_u32(0), pg, op)
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_u32[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub fn svcvt_u32_f64_m(inactive: svuint32_t, pg: svbool_t, op: svfloat64_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvtzu.i32f64")]
        fn _svcvt_u32_f64_m(inactive: svint32_t, pg: svbool2_t, op: svfloat64_t) -> svint32_t;
    }
    unsafe { _svcvt_u32_f64_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_u32[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub fn svcvt_u32_f64_x(pg: svbool_t, op: svfloat64_t) -> svuint32_t {
    unsafe { svcvt_u32_f64_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_u32[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub fn svcvt_u32_f64_z(pg: svbool_t, op: svfloat64_t) -> svuint32_t {
    svcvt_u32_f64_m(svdup_n_u32(0), pg, op)
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_u64[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub fn svcvt_u64_f32_m(inactive: svuint64_t, pg: svbool_t, op: svfloat32_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvtzu.i64f32")]
        fn _svcvt_u64_f32_m(inactive: svint64_t, pg: svbool2_t, op: svfloat32_t) -> svint64_t;
    }
    unsafe { _svcvt_u64_f32_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_u64[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub fn svcvt_u64_f32_x(pg: svbool_t, op: svfloat32_t) -> svuint64_t {
    unsafe { svcvt_u64_f32_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_u64[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub fn svcvt_u64_f32_z(pg: svbool_t, op: svfloat32_t) -> svuint64_t {
    svcvt_u64_f32_m(svdup_n_u64(0), pg, op)
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_u64[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub fn svcvt_u64_f64_m(inactive: svuint64_t, pg: svbool_t, op: svfloat64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fcvtzu.i64f64")]
        fn _svcvt_u64_f64_m(inactive: svint64_t, pg: svbool2_t, op: svfloat64_t) -> svint64_t;
    }
    unsafe { _svcvt_u64_f64_m(inactive.as_signed(), pg.into(), op).as_unsigned() }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_u64[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub fn svcvt_u64_f64_x(pg: svbool_t, op: svfloat64_t) -> svuint64_t {
    unsafe { svcvt_u64_f64_m(simd_reinterpret(op), pg, op) }
}
#[doc = "Floating-point convert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svcvt_u64[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fcvtzu))]
pub fn svcvt_u64_f64_z(pg: svbool_t, op: svfloat64_t) -> svuint64_t {
    svcvt_u64_f64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub fn svdiv_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fdiv.nxv4f32")]
        fn _svdiv_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svdiv_f32_m(pg.into(), op1, op2) }
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub fn svdiv_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svdiv_f32_m(pg, op1, svdup_n_f32(op2))
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub fn svdiv_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svdiv_f32_m(pg, op1, op2)
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub fn svdiv_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svdiv_f32_x(pg, op1, svdup_n_f32(op2))
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub fn svdiv_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svdiv_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub fn svdiv_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svdiv_f32_z(pg, op1, svdup_n_f32(op2))
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub fn svdiv_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fdiv.nxv2f64")]
        fn _svdiv_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svdiv_f64_m(pg.into(), op1, op2) }
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub fn svdiv_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svdiv_f64_m(pg, op1, svdup_n_f64(op2))
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub fn svdiv_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svdiv_f64_m(pg, op1, op2)
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub fn svdiv_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svdiv_f64_x(pg, op1, svdup_n_f64(op2))
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub fn svdiv_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svdiv_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdiv))]
pub fn svdiv_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svdiv_f64_z(pg, op1, svdup_n_f64(op2))
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub fn svdiv_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sdiv.nxv4i32")]
        fn _svdiv_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svdiv_s32_m(pg.into(), op1, op2) }
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub fn svdiv_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svdiv_s32_m(pg, op1, svdup_n_s32(op2))
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub fn svdiv_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svdiv_s32_m(pg, op1, op2)
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub fn svdiv_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svdiv_s32_x(pg, op1, svdup_n_s32(op2))
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub fn svdiv_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svdiv_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub fn svdiv_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svdiv_s32_z(pg, op1, svdup_n_s32(op2))
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub fn svdiv_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sdiv.nxv2i64")]
        fn _svdiv_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svdiv_s64_m(pg.into(), op1, op2) }
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub fn svdiv_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svdiv_s64_m(pg, op1, svdup_n_s64(op2))
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub fn svdiv_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svdiv_s64_m(pg, op1, op2)
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub fn svdiv_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svdiv_s64_x(pg, op1, svdup_n_s64(op2))
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub fn svdiv_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svdiv_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdiv))]
pub fn svdiv_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svdiv_s64_z(pg, op1, svdup_n_s64(op2))
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub fn svdiv_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.udiv.nxv4i32")]
        fn _svdiv_u32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svdiv_u32_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub fn svdiv_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svdiv_u32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub fn svdiv_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svdiv_u32_m(pg, op1, op2)
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub fn svdiv_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svdiv_u32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub fn svdiv_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svdiv_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub fn svdiv_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svdiv_u32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub fn svdiv_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.udiv.nxv2i64")]
        fn _svdiv_u64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svdiv_u64_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub fn svdiv_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svdiv_u64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub fn svdiv_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svdiv_u64_m(pg, op1, op2)
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub fn svdiv_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svdiv_u64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub fn svdiv_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svdiv_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[doc = "Divide"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdiv[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udiv))]
pub fn svdiv_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svdiv_u64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub fn svdivr_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fdivr.nxv4f32")]
        fn _svdivr_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svdivr_f32_m(pg.into(), op1, op2) }
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub fn svdivr_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svdivr_f32_m(pg, op1, svdup_n_f32(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub fn svdivr_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svdivr_f32_m(pg, op1, op2)
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub fn svdivr_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svdivr_f32_x(pg, op1, svdup_n_f32(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub fn svdivr_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svdivr_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub fn svdivr_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svdivr_f32_z(pg, op1, svdup_n_f32(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub fn svdivr_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fdivr.nxv2f64")]
        fn _svdivr_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svdivr_f64_m(pg.into(), op1, op2) }
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub fn svdivr_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svdivr_f64_m(pg, op1, svdup_n_f64(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub fn svdivr_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svdivr_f64_m(pg, op1, op2)
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub fn svdivr_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svdivr_f64_x(pg, op1, svdup_n_f64(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub fn svdivr_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svdivr_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fdivr))]
pub fn svdivr_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svdivr_f64_z(pg, op1, svdup_n_f64(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub fn svdivr_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sdivr.nxv4i32")]
        fn _svdivr_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svdivr_s32_m(pg.into(), op1, op2) }
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub fn svdivr_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svdivr_s32_m(pg, op1, svdup_n_s32(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub fn svdivr_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svdivr_s32_m(pg, op1, op2)
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub fn svdivr_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svdivr_s32_x(pg, op1, svdup_n_s32(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub fn svdivr_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svdivr_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub fn svdivr_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svdivr_s32_z(pg, op1, svdup_n_s32(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub fn svdivr_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sdivr.nxv2i64")]
        fn _svdivr_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svdivr_s64_m(pg.into(), op1, op2) }
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub fn svdivr_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svdivr_s64_m(pg, op1, svdup_n_s64(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub fn svdivr_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svdivr_s64_m(pg, op1, op2)
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub fn svdivr_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svdivr_s64_x(pg, op1, svdup_n_s64(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub fn svdivr_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svdivr_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdivr))]
pub fn svdivr_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svdivr_s64_z(pg, op1, svdup_n_s64(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub fn svdivr_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.udivr.nxv4i32")]
        fn _svdivr_u32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svdivr_u32_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub fn svdivr_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svdivr_u32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub fn svdivr_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svdivr_u32_m(pg, op1, op2)
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub fn svdivr_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svdivr_u32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub fn svdivr_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svdivr_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub fn svdivr_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svdivr_u32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub fn svdivr_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.udivr.nxv2i64")]
        fn _svdivr_u64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svdivr_u64_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub fn svdivr_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svdivr_u64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub fn svdivr_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svdivr_u64_m(pg, op1, op2)
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub fn svdivr_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svdivr_u64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub fn svdivr_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svdivr_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[doc = "Divide reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdivr[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udivr))]
pub fn svdivr_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svdivr_u64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Dot product"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdot_lane[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdot, IMM_INDEX = 0))]
pub fn svdot_lane_s32<const IMM_INDEX: i32>(
    op1: svint32_t,
    op2: svint8_t,
    op3: svint8_t,
) -> svint32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sdot.lane.nxv4i32"
        )]
        fn _svdot_lane_s32(
            op1: svint32_t,
            op2: svint8_t,
            op3: svint8_t,
            imm_index: i32,
        ) -> svint32_t;
    }
    unsafe { _svdot_lane_s32(op1, op2, op3, IMM_INDEX) }
}
#[doc = "Dot product"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdot_lane[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdot, IMM_INDEX = 0))]
pub fn svdot_lane_s64<const IMM_INDEX: i32>(
    op1: svint64_t,
    op2: svint16_t,
    op3: svint16_t,
) -> svint64_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sdot.lane.nxv2i64"
        )]
        fn _svdot_lane_s64(
            op1: svint64_t,
            op2: svint16_t,
            op3: svint16_t,
            imm_index: i32,
        ) -> svint64_t;
    }
    unsafe { _svdot_lane_s64(op1, op2, op3, IMM_INDEX) }
}
#[doc = "Dot product"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdot_lane[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udot, IMM_INDEX = 0))]
pub fn svdot_lane_u32<const IMM_INDEX: i32>(
    op1: svuint32_t,
    op2: svuint8_t,
    op3: svuint8_t,
) -> svuint32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.udot.lane.nxv4i32"
        )]
        fn _svdot_lane_u32(
            op1: svint32_t,
            op2: svint8_t,
            op3: svint8_t,
            imm_index: i32,
        ) -> svint32_t;
    }
    unsafe {
        _svdot_lane_u32(op1.as_signed(), op2.as_signed(), op3.as_signed(), IMM_INDEX).as_unsigned()
    }
}
#[doc = "Dot product"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdot_lane[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udot, IMM_INDEX = 0))]
pub fn svdot_lane_u64<const IMM_INDEX: i32>(
    op1: svuint64_t,
    op2: svuint16_t,
    op3: svuint16_t,
) -> svuint64_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.udot.lane.nxv2i64"
        )]
        fn _svdot_lane_u64(
            op1: svint64_t,
            op2: svint16_t,
            op3: svint16_t,
            imm_index: i32,
        ) -> svint64_t;
    }
    unsafe {
        _svdot_lane_u64(op1.as_signed(), op2.as_signed(), op3.as_signed(), IMM_INDEX).as_unsigned()
    }
}
#[doc = "Dot product"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdot[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdot))]
pub fn svdot_s32(op1: svint32_t, op2: svint8_t, op3: svint8_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sdot.nxv4i32")]
        fn _svdot_s32(op1: svint32_t, op2: svint8_t, op3: svint8_t) -> svint32_t;
    }
    unsafe { _svdot_s32(op1, op2, op3) }
}
#[doc = "Dot product"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdot[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdot))]
pub fn svdot_n_s32(op1: svint32_t, op2: svint8_t, op3: i8) -> svint32_t {
    svdot_s32(op1, op2, svdup_n_s8(op3))
}
#[doc = "Dot product"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdot[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdot))]
pub fn svdot_s64(op1: svint64_t, op2: svint16_t, op3: svint16_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sdot.nxv2i64")]
        fn _svdot_s64(op1: svint64_t, op2: svint16_t, op3: svint16_t) -> svint64_t;
    }
    unsafe { _svdot_s64(op1, op2, op3) }
}
#[doc = "Dot product"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdot[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sdot))]
pub fn svdot_n_s64(op1: svint64_t, op2: svint16_t, op3: i16) -> svint64_t {
    svdot_s64(op1, op2, svdup_n_s16(op3))
}
#[doc = "Dot product"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdot[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udot))]
pub fn svdot_u32(op1: svuint32_t, op2: svuint8_t, op3: svuint8_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.udot.nxv4i32")]
        fn _svdot_u32(op1: svint32_t, op2: svint8_t, op3: svint8_t) -> svint32_t;
    }
    unsafe { _svdot_u32(op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Dot product"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdot[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udot))]
pub fn svdot_n_u32(op1: svuint32_t, op2: svuint8_t, op3: u8) -> svuint32_t {
    svdot_u32(op1, op2, svdup_n_u8(op3))
}
#[doc = "Dot product"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdot[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udot))]
pub fn svdot_u64(op1: svuint64_t, op2: svuint16_t, op3: svuint16_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.udot.nxv2i64")]
        fn _svdot_u64(op1: svint64_t, op2: svint16_t, op3: svint16_t) -> svint64_t;
    }
    unsafe { _svdot_u64(op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Dot product"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdot[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(udot))]
pub fn svdot_n_u64(op1: svuint64_t, op2: svuint16_t, op3: u16) -> svuint64_t {
    svdot_u64(op1, op2, svdup_n_u16(op3))
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup_lane[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdup_lane_f32(data: svfloat32_t, index: u32) -> svfloat32_t {
    svtbl_f32(data, svdup_n_u32(index))
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup_lane[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdup_lane_f64(data: svfloat64_t, index: u64) -> svfloat64_t {
    svtbl_f64(data, svdup_n_u64(index))
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup_lane[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdup_lane_s8(data: svint8_t, index: u8) -> svint8_t {
    svtbl_s8(data, svdup_n_u8(index))
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup_lane[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdup_lane_s16(data: svint16_t, index: u16) -> svint16_t {
    svtbl_s16(data, svdup_n_u16(index))
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup_lane[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdup_lane_s32(data: svint32_t, index: u32) -> svint32_t {
    svtbl_s32(data, svdup_n_u32(index))
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup_lane[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdup_lane_s64(data: svint64_t, index: u64) -> svint64_t {
    svtbl_s64(data, svdup_n_u64(index))
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup_lane[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdup_lane_u8(data: svuint8_t, index: u8) -> svuint8_t {
    svtbl_u8(data, svdup_n_u8(index))
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup_lane[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdup_lane_u16(data: svuint16_t, index: u16) -> svuint16_t {
    svtbl_u16(data, svdup_n_u16(index))
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup_lane[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdup_lane_u32(data: svuint32_t, index: u32) -> svuint32_t {
    svtbl_u32(data, svdup_n_u32(index))
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup_lane[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdup_lane_u64(data: svuint64_t, index: u64) -> svuint64_t {
    svtbl_u64(data, svdup_n_u64(index))
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sbfx))]
#[cfg_attr(test, assert_instr(whilelo))]
pub fn svdup_n_b8(op: bool) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv16i1")]
        fn _svdup_n_b8(op: bool) -> svbool_t;
    }
    unsafe { _svdup_n_b8(op) }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sbfx))]
#[cfg_attr(test, assert_instr(whilelo))]
pub fn svdup_n_b16(op: bool) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv8i1")]
        fn _svdup_n_b16(op: bool) -> svbool8_t;
    }
    unsafe { _svdup_n_b16(op).into() }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sbfx))]
#[cfg_attr(test, assert_instr(whilelo))]
pub fn svdup_n_b32(op: bool) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv4i1")]
        fn _svdup_n_b32(op: bool) -> svbool4_t;
    }
    unsafe { _svdup_n_b32(op).into() }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sbfx))]
#[cfg_attr(test, assert_instr(whilelo))]
pub fn svdup_n_b64(op: bool) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv2i1")]
        fn _svdup_n_b64(op: bool) -> svbool2_t;
    }
    unsafe { _svdup_n_b64(op).into() }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_f32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_f32(op: f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv4f32")]
        fn _svdup_n_f32(op: f32) -> svfloat32_t;
    }
    unsafe { _svdup_n_f32(op) }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_f64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_f64(op: f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv2f64")]
        fn _svdup_n_f64(op: f64) -> svfloat64_t;
    }
    unsafe { _svdup_n_f64(op) }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_s8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_s8(op: i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv16i8")]
        fn _svdup_n_s8(op: i8) -> svint8_t;
    }
    unsafe { _svdup_n_s8(op) }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_s16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_s16(op: i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv8i16")]
        fn _svdup_n_s16(op: i16) -> svint16_t;
    }
    unsafe { _svdup_n_s16(op) }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_s32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_s32(op: i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv4i32")]
        fn _svdup_n_s32(op: i32) -> svint32_t;
    }
    unsafe { _svdup_n_s32(op) }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_s64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_s64(op: i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.x.nxv2i64")]
        fn _svdup_n_s64(op: i64) -> svint64_t;
    }
    unsafe { _svdup_n_s64(op) }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_u8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_u8(op: u8) -> svuint8_t {
    unsafe { svdup_n_s8(op.as_signed()).as_unsigned() }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_u16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_u16(op: u16) -> svuint16_t {
    unsafe { svdup_n_s16(op.as_signed()).as_unsigned() }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_u32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_u32(op: u32) -> svuint32_t {
    unsafe { svdup_n_s32(op.as_signed()).as_unsigned() }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_u64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_u64(op: u64) -> svuint64_t {
    unsafe { svdup_n_s64(op.as_signed()).as_unsigned() }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_f32_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_f32_m(inactive: svfloat32_t, pg: svbool_t, op: f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.nxv4f32")]
        fn _svdup_n_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: f32) -> svfloat32_t;
    }
    unsafe { _svdup_n_f32_m(inactive, pg.into(), op) }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_f32_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_f32_x(pg: svbool_t, op: f32) -> svfloat32_t {
    svdup_n_f32_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_f32_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_f32_z(pg: svbool_t, op: f32) -> svfloat32_t {
    svdup_n_f32_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_f64_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_f64_m(inactive: svfloat64_t, pg: svbool_t, op: f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.nxv2f64")]
        fn _svdup_n_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: f64) -> svfloat64_t;
    }
    unsafe { _svdup_n_f64_m(inactive, pg.into(), op) }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_f64_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_f64_x(pg: svbool_t, op: f64) -> svfloat64_t {
    svdup_n_f64_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_f64_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_f64_z(pg: svbool_t, op: f64) -> svfloat64_t {
    svdup_n_f64_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_s8_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_s8_m(inactive: svint8_t, pg: svbool_t, op: i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.nxv16i8")]
        fn _svdup_n_s8_m(inactive: svint8_t, pg: svbool_t, op: i8) -> svint8_t;
    }
    unsafe { _svdup_n_s8_m(inactive, pg, op) }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_s8_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_s8_x(pg: svbool_t, op: i8) -> svint8_t {
    svdup_n_s8_m(svdup_n_s8(0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_s8_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_s8_z(pg: svbool_t, op: i8) -> svint8_t {
    svdup_n_s8_m(svdup_n_s8(0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_s16_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_s16_m(inactive: svint16_t, pg: svbool_t, op: i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.nxv8i16")]
        fn _svdup_n_s16_m(inactive: svint16_t, pg: svbool8_t, op: i16) -> svint16_t;
    }
    unsafe { _svdup_n_s16_m(inactive, pg.into(), op) }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_s16_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_s16_x(pg: svbool_t, op: i16) -> svint16_t {
    svdup_n_s16_m(svdup_n_s16(0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_s16_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_s16_z(pg: svbool_t, op: i16) -> svint16_t {
    svdup_n_s16_m(svdup_n_s16(0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_s32_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_s32_m(inactive: svint32_t, pg: svbool_t, op: i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.nxv4i32")]
        fn _svdup_n_s32_m(inactive: svint32_t, pg: svbool4_t, op: i32) -> svint32_t;
    }
    unsafe { _svdup_n_s32_m(inactive, pg.into(), op) }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_s32_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_s32_x(pg: svbool_t, op: i32) -> svint32_t {
    svdup_n_s32_m(svdup_n_s32(0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_s32_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_s32_z(pg: svbool_t, op: i32) -> svint32_t {
    svdup_n_s32_m(svdup_n_s32(0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_s64_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_s64_m(inactive: svint64_t, pg: svbool_t, op: i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.dup.nxv2i64")]
        fn _svdup_n_s64_m(inactive: svint64_t, pg: svbool2_t, op: i64) -> svint64_t;
    }
    unsafe { _svdup_n_s64_m(inactive, pg.into(), op) }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_s64_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_s64_x(pg: svbool_t, op: i64) -> svint64_t {
    svdup_n_s64_m(svdup_n_s64(0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_s64_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_s64_z(pg: svbool_t, op: i64) -> svint64_t {
    svdup_n_s64_m(svdup_n_s64(0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_u8_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_u8_m(inactive: svuint8_t, pg: svbool_t, op: u8) -> svuint8_t {
    unsafe { svdup_n_s8_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_u8_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_u8_x(pg: svbool_t, op: u8) -> svuint8_t {
    svdup_n_u8_m(svdup_n_u8(0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_u8_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_u8_z(pg: svbool_t, op: u8) -> svuint8_t {
    svdup_n_u8_m(svdup_n_u8(0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_u16_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_u16_m(inactive: svuint16_t, pg: svbool_t, op: u16) -> svuint16_t {
    unsafe { svdup_n_s16_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_u16_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_u16_x(pg: svbool_t, op: u16) -> svuint16_t {
    svdup_n_u16_m(svdup_n_u16(0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_u16_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_u16_z(pg: svbool_t, op: u16) -> svuint16_t {
    svdup_n_u16_m(svdup_n_u16(0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_u32_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_u32_m(inactive: svuint32_t, pg: svbool_t, op: u32) -> svuint32_t {
    unsafe { svdup_n_s32_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_u32_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_u32_x(pg: svbool_t, op: u32) -> svuint32_t {
    svdup_n_u32_m(svdup_n_u32(0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_u32_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_u32_z(pg: svbool_t, op: u32) -> svuint32_t {
    svdup_n_u32_m(svdup_n_u32(0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_u64_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_u64_m(inactive: svuint64_t, pg: svbool_t, op: u64) -> svuint64_t {
    unsafe { svdup_n_s64_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_u64_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_u64_x(pg: svbool_t, op: u64) -> svuint64_t {
    svdup_n_u64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Broadcast a scalar value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdup[_n]_u64_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svdup_n_u64_z(pg: svbool_t, op: u64) -> svuint64_t {
    svdup_n_u64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq_lane[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdupq_lane_f32(data: svfloat32_t, index: u64) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.dupq.lane.nxv4f32"
        )]
        fn _svdupq_lane_f32(data: svfloat32_t, index: i64) -> svfloat32_t;
    }
    unsafe { _svdupq_lane_f32(data, index.as_signed()) }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq_lane[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdupq_lane_f64(data: svfloat64_t, index: u64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.dupq.lane.nxv2f64"
        )]
        fn _svdupq_lane_f64(data: svfloat64_t, index: i64) -> svfloat64_t;
    }
    unsafe { _svdupq_lane_f64(data, index.as_signed()) }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq_lane[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdupq_lane_s8(data: svint8_t, index: u64) -> svint8_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.dupq.lane.nxv16i8"
        )]
        fn _svdupq_lane_s8(data: svint8_t, index: i64) -> svint8_t;
    }
    unsafe { _svdupq_lane_s8(data, index.as_signed()) }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq_lane[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdupq_lane_s16(data: svint16_t, index: u64) -> svint16_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.dupq.lane.nxv8i16"
        )]
        fn _svdupq_lane_s16(data: svint16_t, index: i64) -> svint16_t;
    }
    unsafe { _svdupq_lane_s16(data, index.as_signed()) }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq_lane[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdupq_lane_s32(data: svint32_t, index: u64) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.dupq.lane.nxv4i32"
        )]
        fn _svdupq_lane_s32(data: svint32_t, index: i64) -> svint32_t;
    }
    unsafe { _svdupq_lane_s32(data, index.as_signed()) }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq_lane[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdupq_lane_s64(data: svint64_t, index: u64) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.dupq.lane.nxv2i64"
        )]
        fn _svdupq_lane_s64(data: svint64_t, index: i64) -> svint64_t;
    }
    unsafe { _svdupq_lane_s64(data, index.as_signed()) }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq_lane[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdupq_lane_u8(data: svuint8_t, index: u64) -> svuint8_t {
    unsafe { svdupq_lane_s8(data.as_signed(), index).as_unsigned() }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq_lane[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdupq_lane_u16(data: svuint16_t, index: u64) -> svuint16_t {
    unsafe { svdupq_lane_s16(data.as_signed(), index).as_unsigned() }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq_lane[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdupq_lane_u32(data: svuint32_t, index: u64) -> svuint32_t {
    unsafe { svdupq_lane_s32(data.as_signed(), index).as_unsigned() }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq_lane[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svdupq_lane_u64(data: svuint64_t, index: u64) -> svuint64_t {
    unsafe { svdupq_lane_s64(data.as_signed(), index).as_unsigned() }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq[_n]_b16)"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svdupq_n_b16(
    x0: bool,
    x1: bool,
    x2: bool,
    x3: bool,
    x4: bool,
    x5: bool,
    x6: bool,
    x7: bool,
) -> svbool_t {
    let op1 = svdupq_n_s16(
        x0 as i16, x1 as i16, x2 as i16, x3 as i16, x4 as i16, x5 as i16, x6 as i16, x7 as i16,
    );
    svcmpne_wide_s16(svptrue_b16(), op1, svdup_n_s64(0))
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq[_n]_b32)"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svdupq_n_b32(x0: bool, x1: bool, x2: bool, x3: bool) -> svbool_t {
    let op1 = svdupq_n_s32(x0 as i32, x1 as i32, x2 as i32, x3 as i32);
    svcmpne_wide_s32(svptrue_b32(), op1, svdup_n_s64(0))
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq[_n]_b64)"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svdupq_n_b64(x0: bool, x1: bool) -> svbool_t {
    let op1 = svdupq_n_s64(x0 as i64, x1 as i64);
    svcmpne_s64(svptrue_b64(), op1, svdup_n_s64(0))
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq[_n]_b8)"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svdupq_n_b8(
    x0: bool,
    x1: bool,
    x2: bool,
    x3: bool,
    x4: bool,
    x5: bool,
    x6: bool,
    x7: bool,
    x8: bool,
    x9: bool,
    x10: bool,
    x11: bool,
    x12: bool,
    x13: bool,
    x14: bool,
    x15: bool,
) -> svbool_t {
    let op1 = svdupq_n_s8(
        x0 as i8, x1 as i8, x2 as i8, x3 as i8, x4 as i8, x5 as i8, x6 as i8, x7 as i8, x8 as i8,
        x9 as i8, x10 as i8, x11 as i8, x12 as i8, x13 as i8, x14 as i8, x15 as i8,
    );
    svcmpne_wide_s8(svptrue_b8(), op1, svdup_n_s64(0))
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq[_n]_f32)"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svdupq_n_f32(x0: f32, x1: f32, x2: f32, x3: f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.experimental.vector.insert.nxv4f32.v4f32"
        )]
        fn _svdupq_n_f32(op0: svfloat32_t, op1: float32x4_t, idx: i64) -> svfloat32_t;
    }
    unsafe {
        let op = _svdupq_n_f32(
            simd_reinterpret(()),
            crate::mem::transmute([x0, x1, x2, x3]),
            0,
        );
        svdupq_lane_f32(op, 0)
    }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq[_n]_s32)"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svdupq_n_s32(x0: i32, x1: i32, x2: i32, x3: i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.experimental.vector.insert.nxv4i32.v4i32"
        )]
        fn _svdupq_n_s32(op0: svint32_t, op1: int32x4_t, idx: i64) -> svint32_t;
    }
    unsafe {
        let op = _svdupq_n_s32(
            simd_reinterpret(()),
            crate::mem::transmute([x0, x1, x2, x3]),
            0,
        );
        svdupq_lane_s32(op, 0)
    }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq[_n]_u32)"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svdupq_n_u32(x0: u32, x1: u32, x2: u32, x3: u32) -> svuint32_t {
    unsafe {
        svdupq_n_s32(
            x0.as_signed(),
            x1.as_signed(),
            x2.as_signed(),
            x3.as_signed(),
        )
        .as_unsigned()
    }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq[_n]_f64)"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svdupq_n_f64(x0: f64, x1: f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.experimental.vector.insert.nxv2f64.v2f64"
        )]
        fn _svdupq_n_f64(op0: svfloat64_t, op1: float64x2_t, idx: i64) -> svfloat64_t;
    }
    unsafe {
        let op = _svdupq_n_f64(simd_reinterpret(()), crate::mem::transmute([x0, x1]), 0);
        svdupq_lane_f64(op, 0)
    }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq[_n]_s64)"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svdupq_n_s64(x0: i64, x1: i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.experimental.vector.insert.nxv2i64.v2i64"
        )]
        fn _svdupq_n_s64(op0: svint64_t, op1: int64x2_t, idx: i64) -> svint64_t;
    }
    unsafe {
        let op = _svdupq_n_s64(simd_reinterpret(()), crate::mem::transmute([x0, x1]), 0);
        svdupq_lane_s64(op, 0)
    }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq[_n]_u64)"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svdupq_n_u64(x0: u64, x1: u64) -> svuint64_t {
    unsafe { svdupq_n_s64(x0.as_signed(), x1.as_signed()).as_unsigned() }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq[_n]_s16)"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svdupq_n_s16(
    x0: i16,
    x1: i16,
    x2: i16,
    x3: i16,
    x4: i16,
    x5: i16,
    x6: i16,
    x7: i16,
) -> svint16_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.experimental.vector.insert.nxv8i16.v8i16"
        )]
        fn _svdupq_n_s16(op0: svint16_t, op1: int16x8_t, idx: i64) -> svint16_t;
    }
    unsafe {
        let op = _svdupq_n_s16(
            simd_reinterpret(()),
            crate::mem::transmute([x0, x1, x2, x3, x4, x5, x6, x7]),
            0,
        );
        svdupq_lane_s16(op, 0)
    }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq[_n]_u16)"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svdupq_n_u16(
    x0: u16,
    x1: u16,
    x2: u16,
    x3: u16,
    x4: u16,
    x5: u16,
    x6: u16,
    x7: u16,
) -> svuint16_t {
    unsafe {
        svdupq_n_s16(
            x0.as_signed(),
            x1.as_signed(),
            x2.as_signed(),
            x3.as_signed(),
            x4.as_signed(),
            x5.as_signed(),
            x6.as_signed(),
            x7.as_signed(),
        )
        .as_unsigned()
    }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq[_n]_s8)"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svdupq_n_s8(
    x0: i8,
    x1: i8,
    x2: i8,
    x3: i8,
    x4: i8,
    x5: i8,
    x6: i8,
    x7: i8,
    x8: i8,
    x9: i8,
    x10: i8,
    x11: i8,
    x12: i8,
    x13: i8,
    x14: i8,
    x15: i8,
) -> svint8_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.experimental.vector.insert.nxv16i8.v16i8"
        )]
        fn _svdupq_n_s8(op0: svint8_t, op1: int8x16_t, idx: i64) -> svint8_t;
    }
    unsafe {
        let op = _svdupq_n_s8(
            simd_reinterpret(()),
            crate::mem::transmute([
                x0, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15,
            ]),
            0,
        );
        svdupq_lane_s8(op, 0)
    }
}
#[doc = "Broadcast a quadword of scalars"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svdupq[_n]_u8)"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svdupq_n_u8(
    x0: u8,
    x1: u8,
    x2: u8,
    x3: u8,
    x4: u8,
    x5: u8,
    x6: u8,
    x7: u8,
    x8: u8,
    x9: u8,
    x10: u8,
    x11: u8,
    x12: u8,
    x13: u8,
    x14: u8,
    x15: u8,
) -> svuint8_t {
    unsafe {
        svdupq_n_s8(
            x0.as_signed(),
            x1.as_signed(),
            x2.as_signed(),
            x3.as_signed(),
            x4.as_signed(),
            x5.as_signed(),
            x6.as_signed(),
            x7.as_signed(),
            x8.as_signed(),
            x9.as_signed(),
            x10.as_signed(),
            x11.as_signed(),
            x12.as_signed(),
            x13.as_signed(),
            x14.as_signed(),
            x15.as_signed(),
        )
        .as_unsigned()
    }
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_b]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eor.z.nvx16i1")]
        fn _sveor_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _sveor_b_z(pg, op1, op2) }
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eor.nxv16i8")]
        fn _sveor_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _sveor_s8_m(pg, op1, op2) }
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    sveor_s8_m(pg, op1, svdup_n_s8(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    sveor_s8_m(pg, op1, op2)
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    sveor_s8_x(pg, op1, svdup_n_s8(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    sveor_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    sveor_s8_z(pg, op1, svdup_n_s8(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eor.nxv8i16")]
        fn _sveor_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _sveor_s16_m(pg.into(), op1, op2) }
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    sveor_s16_m(pg, op1, svdup_n_s16(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    sveor_s16_m(pg, op1, op2)
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    sveor_s16_x(pg, op1, svdup_n_s16(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    sveor_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    sveor_s16_z(pg, op1, svdup_n_s16(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eor.nxv4i32")]
        fn _sveor_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _sveor_s32_m(pg.into(), op1, op2) }
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    sveor_s32_m(pg, op1, svdup_n_s32(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    sveor_s32_m(pg, op1, op2)
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    sveor_s32_x(pg, op1, svdup_n_s32(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    sveor_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    sveor_s32_z(pg, op1, svdup_n_s32(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eor.nxv2i64")]
        fn _sveor_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _sveor_s64_m(pg.into(), op1, op2) }
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    sveor_s64_m(pg, op1, svdup_n_s64(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    sveor_s64_m(pg, op1, op2)
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    sveor_s64_x(pg, op1, svdup_n_s64(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    sveor_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    sveor_s64_z(pg, op1, svdup_n_s64(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { sveor_s8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    sveor_u8_m(pg, op1, svdup_n_u8(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    sveor_u8_m(pg, op1, op2)
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    sveor_u8_x(pg, op1, svdup_n_u8(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    sveor_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    sveor_u8_z(pg, op1, svdup_n_u8(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { sveor_s16_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    sveor_u16_m(pg, op1, svdup_n_u16(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    sveor_u16_m(pg, op1, op2)
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    sveor_u16_x(pg, op1, svdup_n_u16(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    sveor_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    sveor_u16_z(pg, op1, svdup_n_u16(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { sveor_s32_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    sveor_u32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    sveor_u32_m(pg, op1, op2)
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    sveor_u32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    sveor_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    sveor_u32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { sveor_s64_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    sveor_u64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    sveor_u64_m(pg, op1, op2)
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    sveor_u64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    sveor_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[doc = "Bitwise exclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveor[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eor))]
pub fn sveor_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    sveor_u64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Bitwise exclusive OR reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveorv[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eorv))]
pub fn sveorv_s8(pg: svbool_t, op: svint8_t) -> i8 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eorv.nxv16i8")]
        fn _sveorv_s8(pg: svbool_t, op: svint8_t) -> i8;
    }
    unsafe { _sveorv_s8(pg, op) }
}
#[doc = "Bitwise exclusive OR reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveorv[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eorv))]
pub fn sveorv_s16(pg: svbool_t, op: svint16_t) -> i16 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eorv.nxv8i16")]
        fn _sveorv_s16(pg: svbool8_t, op: svint16_t) -> i16;
    }
    unsafe { _sveorv_s16(pg.into(), op) }
}
#[doc = "Bitwise exclusive OR reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveorv[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eorv))]
pub fn sveorv_s32(pg: svbool_t, op: svint32_t) -> i32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eorv.nxv4i32")]
        fn _sveorv_s32(pg: svbool4_t, op: svint32_t) -> i32;
    }
    unsafe { _sveorv_s32(pg.into(), op) }
}
#[doc = "Bitwise exclusive OR reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveorv[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eorv))]
pub fn sveorv_s64(pg: svbool_t, op: svint64_t) -> i64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.eorv.nxv2i64")]
        fn _sveorv_s64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _sveorv_s64(pg.into(), op) }
}
#[doc = "Bitwise exclusive OR reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveorv[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eorv))]
pub fn sveorv_u8(pg: svbool_t, op: svuint8_t) -> u8 {
    unsafe { sveorv_s8(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Bitwise exclusive OR reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveorv[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eorv))]
pub fn sveorv_u16(pg: svbool_t, op: svuint16_t) -> u16 {
    unsafe { sveorv_s16(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Bitwise exclusive OR reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveorv[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eorv))]
pub fn sveorv_u32(pg: svbool_t, op: svuint32_t) -> u32 {
    unsafe { sveorv_s32(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Bitwise exclusive OR reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/sveorv[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(eorv))]
pub fn sveorv_u64(pg: svbool_t, op: svuint64_t) -> u64 {
    unsafe { sveorv_s64(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Floating-point exponential accelerator"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svexpa[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fexpa))]
pub fn svexpa_f32(op: svuint32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fexpa.x.nxv4f32 "
        )]
        fn _svexpa_f32(op: svint32_t) -> svfloat32_t;
    }
    unsafe { _svexpa_f32(op.as_signed()) }
}
#[doc = "Floating-point exponential accelerator"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svexpa[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fexpa))]
pub fn svexpa_f64(op: svuint64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fexpa.x.nxv2f64 "
        )]
        fn _svexpa_f64(op: svint64_t) -> svfloat64_t;
    }
    unsafe { _svexpa_f64(op.as_signed()) }
}
#[doc = "Extract vector from pair of vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svext[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub fn svext_f32<const IMM3: i32>(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    static_assert_range!(IMM3, 0, 63);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ext.nxv4f32")]
        fn _svext_f32(op1: svfloat32_t, op2: svfloat32_t, imm3: i32) -> svfloat32_t;
    }
    unsafe { _svext_f32(op1, op2, IMM3) }
}
#[doc = "Extract vector from pair of vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svext[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub fn svext_f64<const IMM3: i32>(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    static_assert_range!(IMM3, 0, 31);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ext.nxv2f64")]
        fn _svext_f64(op1: svfloat64_t, op2: svfloat64_t, imm3: i32) -> svfloat64_t;
    }
    unsafe { _svext_f64(op1, op2, IMM3) }
}
#[doc = "Extract vector from pair of vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svext[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub fn svext_s8<const IMM3: i32>(op1: svint8_t, op2: svint8_t) -> svint8_t {
    static_assert_range!(IMM3, 0, 255);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ext.nxv16i8")]
        fn _svext_s8(op1: svint8_t, op2: svint8_t, imm3: i32) -> svint8_t;
    }
    unsafe { _svext_s8(op1, op2, IMM3) }
}
#[doc = "Extract vector from pair of vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svext[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub fn svext_s16<const IMM3: i32>(op1: svint16_t, op2: svint16_t) -> svint16_t {
    static_assert_range!(IMM3, 0, 127);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ext.nxv8i16")]
        fn _svext_s16(op1: svint16_t, op2: svint16_t, imm3: i32) -> svint16_t;
    }
    unsafe { _svext_s16(op1, op2, IMM3) }
}
#[doc = "Extract vector from pair of vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svext[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub fn svext_s32<const IMM3: i32>(op1: svint32_t, op2: svint32_t) -> svint32_t {
    static_assert_range!(IMM3, 0, 63);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ext.nxv4i32")]
        fn _svext_s32(op1: svint32_t, op2: svint32_t, imm3: i32) -> svint32_t;
    }
    unsafe { _svext_s32(op1, op2, IMM3) }
}
#[doc = "Extract vector from pair of vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svext[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub fn svext_s64<const IMM3: i32>(op1: svint64_t, op2: svint64_t) -> svint64_t {
    static_assert_range!(IMM3, 0, 31);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ext.nxv2i64")]
        fn _svext_s64(op1: svint64_t, op2: svint64_t, imm3: i32) -> svint64_t;
    }
    unsafe { _svext_s64(op1, op2, IMM3) }
}
#[doc = "Extract vector from pair of vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svext[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub fn svext_u8<const IMM3: i32>(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    static_assert_range!(IMM3, 0, 255);
    unsafe { svext_s8::<IMM3>(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Extract vector from pair of vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svext[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub fn svext_u16<const IMM3: i32>(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    static_assert_range!(IMM3, 0, 127);
    unsafe { svext_s16::<IMM3>(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Extract vector from pair of vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svext[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub fn svext_u32<const IMM3: i32>(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    static_assert_range!(IMM3, 0, 63);
    unsafe { svext_s32::<IMM3>(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Extract vector from pair of vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svext[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ext, IMM3 = 1))]
pub fn svext_u64<const IMM3: i32>(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    static_assert_range!(IMM3, 0, 31);
    unsafe { svext_s64::<IMM3>(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Sign-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub fn svextb_s16_m(inactive: svint16_t, pg: svbool_t, op: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sxtb.nxv8i16")]
        fn _svextb_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svextb_s16_m(inactive, pg.into(), op) }
}
#[doc = "Sign-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub fn svextb_s16_x(pg: svbool_t, op: svint16_t) -> svint16_t {
    svextb_s16_m(op, pg, op)
}
#[doc = "Sign-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub fn svextb_s16_z(pg: svbool_t, op: svint16_t) -> svint16_t {
    svextb_s16_m(svdup_n_s16(0), pg, op)
}
#[doc = "Sign-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub fn svextb_s32_m(inactive: svint32_t, pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sxtb.nxv4i32")]
        fn _svextb_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svextb_s32_m(inactive, pg.into(), op) }
}
#[doc = "Sign-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub fn svextb_s32_x(pg: svbool_t, op: svint32_t) -> svint32_t {
    svextb_s32_m(op, pg, op)
}
#[doc = "Sign-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub fn svextb_s32_z(pg: svbool_t, op: svint32_t) -> svint32_t {
    svextb_s32_m(svdup_n_s32(0), pg, op)
}
#[doc = "Sign-extend the low 16 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svexth[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxth))]
pub fn svexth_s32_m(inactive: svint32_t, pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sxth.nxv4i32")]
        fn _svexth_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svexth_s32_m(inactive, pg.into(), op) }
}
#[doc = "Sign-extend the low 16 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svexth[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxth))]
pub fn svexth_s32_x(pg: svbool_t, op: svint32_t) -> svint32_t {
    svexth_s32_m(op, pg, op)
}
#[doc = "Sign-extend the low 16 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svexth[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxth))]
pub fn svexth_s32_z(pg: svbool_t, op: svint32_t) -> svint32_t {
    svexth_s32_m(svdup_n_s32(0), pg, op)
}
#[doc = "Sign-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub fn svextb_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sxtb.nxv2i64")]
        fn _svextb_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svextb_s64_m(inactive, pg.into(), op) }
}
#[doc = "Sign-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub fn svextb_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svextb_s64_m(op, pg, op)
}
#[doc = "Sign-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtb))]
pub fn svextb_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svextb_s64_m(svdup_n_s64(0), pg, op)
}
#[doc = "Sign-extend the low 16 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svexth[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxth))]
pub fn svexth_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sxth.nxv2i64")]
        fn _svexth_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svexth_s64_m(inactive, pg.into(), op) }
}
#[doc = "Sign-extend the low 16 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svexth[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxth))]
pub fn svexth_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svexth_s64_m(op, pg, op)
}
#[doc = "Sign-extend the low 16 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svexth[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxth))]
pub fn svexth_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svexth_s64_m(svdup_n_s64(0), pg, op)
}
#[doc = "Sign-extend the low 32 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextw[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtw))]
pub fn svextw_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sxtw.nxv2i64")]
        fn _svextw_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svextw_s64_m(inactive, pg.into(), op) }
}
#[doc = "Sign-extend the low 32 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextw[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtw))]
pub fn svextw_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svextw_s64_m(op, pg, op)
}
#[doc = "Sign-extend the low 32 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextw[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sxtw))]
pub fn svextw_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svextw_s64_m(svdup_n_s64(0), pg, op)
}
#[doc = "Zero-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub fn svextb_u16_m(inactive: svuint16_t, pg: svbool_t, op: svuint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uxtb.nxv8i16")]
        fn _svextb_u16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svextb_u16_m(inactive.as_signed(), pg.into(), op.as_signed()).as_unsigned() }
}
#[doc = "Zero-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub fn svextb_u16_x(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svextb_u16_m(op, pg, op)
}
#[doc = "Zero-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub fn svextb_u16_z(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svextb_u16_m(svdup_n_u16(0), pg, op)
}
#[doc = "Zero-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub fn svextb_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uxtb.nxv4i32")]
        fn _svextb_u32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svextb_u32_m(inactive.as_signed(), pg.into(), op.as_signed()).as_unsigned() }
}
#[doc = "Zero-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub fn svextb_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svextb_u32_m(op, pg, op)
}
#[doc = "Zero-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub fn svextb_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svextb_u32_m(svdup_n_u32(0), pg, op)
}
#[doc = "Zero-extend the low 16 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svexth[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxth))]
pub fn svexth_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uxth.nxv4i32")]
        fn _svexth_u32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svexth_u32_m(inactive.as_signed(), pg.into(), op.as_signed()).as_unsigned() }
}
#[doc = "Zero-extend the low 16 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svexth[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxth))]
pub fn svexth_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svexth_u32_m(op, pg, op)
}
#[doc = "Zero-extend the low 16 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svexth[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxth))]
pub fn svexth_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svexth_u32_m(svdup_n_u32(0), pg, op)
}
#[doc = "Zero-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub fn svextb_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uxtb.nxv2i64")]
        fn _svextb_u64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svextb_u64_m(inactive.as_signed(), pg.into(), op.as_signed()).as_unsigned() }
}
#[doc = "Zero-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub fn svextb_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svextb_u64_m(op, pg, op)
}
#[doc = "Zero-extend the low 8 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextb[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtb))]
pub fn svextb_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svextb_u64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Zero-extend the low 16 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svexth[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxth))]
pub fn svexth_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uxth.nxv2i64")]
        fn _svexth_u64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svexth_u64_m(inactive.as_signed(), pg.into(), op.as_signed()).as_unsigned() }
}
#[doc = "Zero-extend the low 16 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svexth[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxth))]
pub fn svexth_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svexth_u64_m(op, pg, op)
}
#[doc = "Zero-extend the low 16 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svexth[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxth))]
pub fn svexth_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svexth_u64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Zero-extend the low 32 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextw[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtw))]
pub fn svextw_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uxtw.nxv2i64")]
        fn _svextw_u64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svextw_u64_m(inactive.as_signed(), pg.into(), op.as_signed()).as_unsigned() }
}
#[doc = "Zero-extend the low 32 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextw[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtw))]
pub fn svextw_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svextw_u64_m(op, pg, op)
}
#[doc = "Zero-extend the low 32 bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svextw[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uxtw))]
pub fn svextw_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svextw_u64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Extract one vector from a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget2[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget2_f32<const IMM_INDEX: i32>(tuple: svfloat32x2_t) -> svfloat32_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv4f32.nxv8f32"
        )]
        fn _svget2_f32(tuple: svfloat32x2_t, imm_index: i32) -> svfloat32_t;
    }
    unsafe { _svget2_f32(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget2[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget2_f64<const IMM_INDEX: i32>(tuple: svfloat64x2_t) -> svfloat64_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv2f64.nxv4f64"
        )]
        fn _svget2_f64(tuple: svfloat64x2_t, imm_index: i32) -> svfloat64_t;
    }
    unsafe { _svget2_f64(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget2[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget2_s8<const IMM_INDEX: i32>(tuple: svint8x2_t) -> svint8_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv16i8.nxv32i8"
        )]
        fn _svget2_s8(tuple: svint8x2_t, imm_index: i32) -> svint8_t;
    }
    unsafe { _svget2_s8(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget2[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget2_s16<const IMM_INDEX: i32>(tuple: svint16x2_t) -> svint16_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv8i16.nxv16i16"
        )]
        fn _svget2_s16(tuple: svint16x2_t, imm_index: i32) -> svint16_t;
    }
    unsafe { _svget2_s16(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget2[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget2_s32<const IMM_INDEX: i32>(tuple: svint32x2_t) -> svint32_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv4i32.nxv8i32"
        )]
        fn _svget2_s32(tuple: svint32x2_t, imm_index: i32) -> svint32_t;
    }
    unsafe { _svget2_s32(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget2[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget2_s64<const IMM_INDEX: i32>(tuple: svint64x2_t) -> svint64_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv2i64.nxv4i64"
        )]
        fn _svget2_s64(tuple: svint64x2_t, imm_index: i32) -> svint64_t;
    }
    unsafe { _svget2_s64(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget2[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget2_u8<const IMM_INDEX: i32>(tuple: svuint8x2_t) -> svuint8_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    unsafe { svget2_s8::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[doc = "Extract one vector from a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget2[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget2_u16<const IMM_INDEX: i32>(tuple: svuint16x2_t) -> svuint16_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    unsafe { svget2_s16::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[doc = "Extract one vector from a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget2[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget2_u32<const IMM_INDEX: i32>(tuple: svuint32x2_t) -> svuint32_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    unsafe { svget2_s32::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[doc = "Extract one vector from a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget2[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget2_u64<const IMM_INDEX: i32>(tuple: svuint64x2_t) -> svuint64_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    unsafe { svget2_s64::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[doc = "Extract one vector from a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget3[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget3_f32<const IMM_INDEX: i32>(tuple: svfloat32x3_t) -> svfloat32_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv4f32.nxv12f32"
        )]
        fn _svget3_f32(tuple: svfloat32x3_t, imm_index: i32) -> svfloat32_t;
    }
    unsafe { _svget3_f32(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget3[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget3_f64<const IMM_INDEX: i32>(tuple: svfloat64x3_t) -> svfloat64_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv2f64.nxv6f64"
        )]
        fn _svget3_f64(tuple: svfloat64x3_t, imm_index: i32) -> svfloat64_t;
    }
    unsafe { _svget3_f64(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget3[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget3_s8<const IMM_INDEX: i32>(tuple: svint8x3_t) -> svint8_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv16i8.nxv48i8"
        )]
        fn _svget3_s8(tuple: svint8x3_t, imm_index: i32) -> svint8_t;
    }
    unsafe { _svget3_s8(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget3[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget3_s16<const IMM_INDEX: i32>(tuple: svint16x3_t) -> svint16_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv8i16.nxv24i16"
        )]
        fn _svget3_s16(tuple: svint16x3_t, imm_index: i32) -> svint16_t;
    }
    unsafe { _svget3_s16(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget3[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget3_s32<const IMM_INDEX: i32>(tuple: svint32x3_t) -> svint32_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv4i32.nxv12i32"
        )]
        fn _svget3_s32(tuple: svint32x3_t, imm_index: i32) -> svint32_t;
    }
    unsafe { _svget3_s32(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget3[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget3_s64<const IMM_INDEX: i32>(tuple: svint64x3_t) -> svint64_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv2i64.nxv6i64"
        )]
        fn _svget3_s64(tuple: svint64x3_t, imm_index: i32) -> svint64_t;
    }
    unsafe { _svget3_s64(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget3[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget3_u8<const IMM_INDEX: i32>(tuple: svuint8x3_t) -> svuint8_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    unsafe { svget3_s8::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[doc = "Extract one vector from a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget3[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget3_u16<const IMM_INDEX: i32>(tuple: svuint16x3_t) -> svuint16_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    unsafe { svget3_s16::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[doc = "Extract one vector from a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget3[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget3_u32<const IMM_INDEX: i32>(tuple: svuint32x3_t) -> svuint32_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    unsafe { svget3_s32::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[doc = "Extract one vector from a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget3[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget3_u64<const IMM_INDEX: i32>(tuple: svuint64x3_t) -> svuint64_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    unsafe { svget3_s64::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[doc = "Extract one vector from a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget4[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget4_f32<const IMM_INDEX: i32>(tuple: svfloat32x4_t) -> svfloat32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv4f32.nxv16f32"
        )]
        fn _svget4_f32(tuple: svfloat32x4_t, imm_index: i32) -> svfloat32_t;
    }
    unsafe { _svget4_f32(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget4[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget4_f64<const IMM_INDEX: i32>(tuple: svfloat64x4_t) -> svfloat64_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv2f64.nxv8f64"
        )]
        fn _svget4_f64(tuple: svfloat64x4_t, imm_index: i32) -> svfloat64_t;
    }
    unsafe { _svget4_f64(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget4[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget4_s8<const IMM_INDEX: i32>(tuple: svint8x4_t) -> svint8_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv16i8.nxv64i8"
        )]
        fn _svget4_s8(tuple: svint8x4_t, imm_index: i32) -> svint8_t;
    }
    unsafe { _svget4_s8(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget4[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget4_s16<const IMM_INDEX: i32>(tuple: svint16x4_t) -> svint16_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv8i16.nxv32i16"
        )]
        fn _svget4_s16(tuple: svint16x4_t, imm_index: i32) -> svint16_t;
    }
    unsafe { _svget4_s16(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget4[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget4_s32<const IMM_INDEX: i32>(tuple: svint32x4_t) -> svint32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv4i32.nxv16i32"
        )]
        fn _svget4_s32(tuple: svint32x4_t, imm_index: i32) -> svint32_t;
    }
    unsafe { _svget4_s32(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget4[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget4_s64<const IMM_INDEX: i32>(tuple: svint64x4_t) -> svint64_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.get.nxv2i64.nxv8i64"
        )]
        fn _svget4_s64(tuple: svint64x4_t, imm_index: i32) -> svint64_t;
    }
    unsafe { _svget4_s64(tuple, IMM_INDEX) }
}
#[doc = "Extract one vector from a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget4[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget4_u8<const IMM_INDEX: i32>(tuple: svuint8x4_t) -> svuint8_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    unsafe { svget4_s8::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[doc = "Extract one vector from a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget4[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget4_u16<const IMM_INDEX: i32>(tuple: svuint16x4_t) -> svuint16_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    unsafe { svget4_s16::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[doc = "Extract one vector from a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget4[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget4_u32<const IMM_INDEX: i32>(tuple: svuint32x4_t) -> svuint32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    unsafe { svget4_s32::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[doc = "Extract one vector from a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svget4[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svget4_u64<const IMM_INDEX: i32>(tuple: svuint64x4_t) -> svuint64_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    unsafe { svget4_s64::<IMM_INDEX>(tuple.as_signed()).as_unsigned() }
}
#[doc = "Create linear series"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svindex_s8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(index))]
pub fn svindex_s8(base: i8, step: i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.index.nxv16i8")]
        fn _svindex_s8(base: i8, step: i8) -> svint8_t;
    }
    unsafe { _svindex_s8(base, step) }
}
#[doc = "Create linear series"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svindex_s16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(index))]
pub fn svindex_s16(base: i16, step: i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.index.nxv8i16")]
        fn _svindex_s16(base: i16, step: i16) -> svint16_t;
    }
    unsafe { _svindex_s16(base, step) }
}
#[doc = "Create linear series"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svindex_s32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(index))]
pub fn svindex_s32(base: i32, step: i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.index.nxv4i32")]
        fn _svindex_s32(base: i32, step: i32) -> svint32_t;
    }
    unsafe { _svindex_s32(base, step) }
}
#[doc = "Create linear series"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svindex_s64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(index))]
pub fn svindex_s64(base: i64, step: i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.index.nxv2i64")]
        fn _svindex_s64(base: i64, step: i64) -> svint64_t;
    }
    unsafe { _svindex_s64(base, step) }
}
#[doc = "Create linear series"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svindex_u8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(index))]
pub fn svindex_u8(base: u8, step: u8) -> svuint8_t {
    unsafe { svindex_s8(base.as_signed(), step.as_signed()).as_unsigned() }
}
#[doc = "Create linear series"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svindex_u16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(index))]
pub fn svindex_u16(base: u16, step: u16) -> svuint16_t {
    unsafe { svindex_s16(base.as_signed(), step.as_signed()).as_unsigned() }
}
#[doc = "Create linear series"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svindex_u32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(index))]
pub fn svindex_u32(base: u32, step: u32) -> svuint32_t {
    unsafe { svindex_s32(base.as_signed(), step.as_signed()).as_unsigned() }
}
#[doc = "Create linear series"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svindex_u64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(index))]
pub fn svindex_u64(base: u64, step: u64) -> svuint64_t {
    unsafe { svindex_s64(base.as_signed(), step.as_signed()).as_unsigned() }
}
#[doc = "Insert scalar in shifted vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svinsr[_n_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub fn svinsr_n_f32(op1: svfloat32_t, op2: f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.insr.nxv4f32")]
        fn _svinsr_n_f32(op1: svfloat32_t, op2: f32) -> svfloat32_t;
    }
    unsafe { _svinsr_n_f32(op1, op2) }
}
#[doc = "Insert scalar in shifted vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svinsr[_n_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub fn svinsr_n_f64(op1: svfloat64_t, op2: f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.insr.nxv2f64")]
        fn _svinsr_n_f64(op1: svfloat64_t, op2: f64) -> svfloat64_t;
    }
    unsafe { _svinsr_n_f64(op1, op2) }
}
#[doc = "Insert scalar in shifted vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svinsr[_n_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub fn svinsr_n_s8(op1: svint8_t, op2: i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.insr.nxv16i8")]
        fn _svinsr_n_s8(op1: svint8_t, op2: i8) -> svint8_t;
    }
    unsafe { _svinsr_n_s8(op1, op2) }
}
#[doc = "Insert scalar in shifted vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svinsr[_n_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub fn svinsr_n_s16(op1: svint16_t, op2: i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.insr.nxv8i16")]
        fn _svinsr_n_s16(op1: svint16_t, op2: i16) -> svint16_t;
    }
    unsafe { _svinsr_n_s16(op1, op2) }
}
#[doc = "Insert scalar in shifted vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svinsr[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub fn svinsr_n_s32(op1: svint32_t, op2: i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.insr.nxv4i32")]
        fn _svinsr_n_s32(op1: svint32_t, op2: i32) -> svint32_t;
    }
    unsafe { _svinsr_n_s32(op1, op2) }
}
#[doc = "Insert scalar in shifted vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svinsr[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub fn svinsr_n_s64(op1: svint64_t, op2: i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.insr.nxv2i64")]
        fn _svinsr_n_s64(op1: svint64_t, op2: i64) -> svint64_t;
    }
    unsafe { _svinsr_n_s64(op1, op2) }
}
#[doc = "Insert scalar in shifted vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svinsr[_n_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub fn svinsr_n_u8(op1: svuint8_t, op2: u8) -> svuint8_t {
    unsafe { svinsr_n_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Insert scalar in shifted vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svinsr[_n_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub fn svinsr_n_u16(op1: svuint16_t, op2: u16) -> svuint16_t {
    unsafe { svinsr_n_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Insert scalar in shifted vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svinsr[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub fn svinsr_n_u32(op1: svuint32_t, op2: u32) -> svuint32_t {
    unsafe { svinsr_n_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Insert scalar in shifted vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svinsr[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(insr))]
pub fn svinsr_n_u64(op1: svuint64_t, op2: u64) -> svuint64_t {
    unsafe { svinsr_n_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlasta[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub fn svlasta_f32(pg: svbool_t, op: svfloat32_t) -> f32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lasta.nxv4f32")]
        fn _svlasta_f32(pg: svbool4_t, op: svfloat32_t) -> f32;
    }
    unsafe { _svlasta_f32(pg.into(), op) }
}
#[doc = "Extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlasta[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub fn svlasta_f64(pg: svbool_t, op: svfloat64_t) -> f64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lasta.nxv2f64")]
        fn _svlasta_f64(pg: svbool2_t, op: svfloat64_t) -> f64;
    }
    unsafe { _svlasta_f64(pg.into(), op) }
}
#[doc = "Extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlasta[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub fn svlasta_s8(pg: svbool_t, op: svint8_t) -> i8 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lasta.nxv16i8")]
        fn _svlasta_s8(pg: svbool_t, op: svint8_t) -> i8;
    }
    unsafe { _svlasta_s8(pg, op) }
}
#[doc = "Extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlasta[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub fn svlasta_s16(pg: svbool_t, op: svint16_t) -> i16 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lasta.nxv8i16")]
        fn _svlasta_s16(pg: svbool8_t, op: svint16_t) -> i16;
    }
    unsafe { _svlasta_s16(pg.into(), op) }
}
#[doc = "Extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlasta[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub fn svlasta_s32(pg: svbool_t, op: svint32_t) -> i32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lasta.nxv4i32")]
        fn _svlasta_s32(pg: svbool4_t, op: svint32_t) -> i32;
    }
    unsafe { _svlasta_s32(pg.into(), op) }
}
#[doc = "Extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlasta[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub fn svlasta_s64(pg: svbool_t, op: svint64_t) -> i64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lasta.nxv2i64")]
        fn _svlasta_s64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _svlasta_s64(pg.into(), op) }
}
#[doc = "Extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlasta[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub fn svlasta_u8(pg: svbool_t, op: svuint8_t) -> u8 {
    unsafe { svlasta_s8(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlasta[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub fn svlasta_u16(pg: svbool_t, op: svuint16_t) -> u16 {
    unsafe { svlasta_s16(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlasta[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub fn svlasta_u32(pg: svbool_t, op: svuint32_t) -> u32 {
    unsafe { svlasta_s32(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Extract element after last"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlasta[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lasta))]
pub fn svlasta_u64(pg: svbool_t, op: svuint64_t) -> u64 {
    unsafe { svlasta_s64(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlastb[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub fn svlastb_f32(pg: svbool_t, op: svfloat32_t) -> f32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lastb.nxv4f32")]
        fn _svlastb_f32(pg: svbool4_t, op: svfloat32_t) -> f32;
    }
    unsafe { _svlastb_f32(pg.into(), op) }
}
#[doc = "Extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlastb[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub fn svlastb_f64(pg: svbool_t, op: svfloat64_t) -> f64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lastb.nxv2f64")]
        fn _svlastb_f64(pg: svbool2_t, op: svfloat64_t) -> f64;
    }
    unsafe { _svlastb_f64(pg.into(), op) }
}
#[doc = "Extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlastb[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub fn svlastb_s8(pg: svbool_t, op: svint8_t) -> i8 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lastb.nxv16i8")]
        fn _svlastb_s8(pg: svbool_t, op: svint8_t) -> i8;
    }
    unsafe { _svlastb_s8(pg, op) }
}
#[doc = "Extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlastb[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub fn svlastb_s16(pg: svbool_t, op: svint16_t) -> i16 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lastb.nxv8i16")]
        fn _svlastb_s16(pg: svbool8_t, op: svint16_t) -> i16;
    }
    unsafe { _svlastb_s16(pg.into(), op) }
}
#[doc = "Extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlastb[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub fn svlastb_s32(pg: svbool_t, op: svint32_t) -> i32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lastb.nxv4i32")]
        fn _svlastb_s32(pg: svbool4_t, op: svint32_t) -> i32;
    }
    unsafe { _svlastb_s32(pg.into(), op) }
}
#[doc = "Extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlastb[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub fn svlastb_s64(pg: svbool_t, op: svint64_t) -> i64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lastb.nxv2i64")]
        fn _svlastb_s64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _svlastb_s64(pg.into(), op) }
}
#[doc = "Extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlastb[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub fn svlastb_u8(pg: svbool_t, op: svuint8_t) -> u8 {
    unsafe { svlastb_s8(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlastb[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub fn svlastb_u16(pg: svbool_t, op: svuint16_t) -> u16 {
    unsafe { svlastb_s16(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlastb[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub fn svlastb_u32(pg: svbool_t, op: svuint32_t) -> u32 {
    unsafe { svlastb_s32(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Extract last element"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlastb[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lastb))]
pub fn svlastb_u64(pg: svbool_t, op: svuint64_t) -> u64 {
    unsafe { svlastb_s64(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_f32(pg: svbool_t, base: *const f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv4f32")]
        fn _svld1_f32(pg: svbool4_t, base: *const f32) -> svfloat32_t;
    }
    _svld1_f32(pg.into(), base)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_f64(pg: svbool_t, base: *const f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv2f64")]
        fn _svld1_f64(pg: svbool2_t, base: *const f64) -> svfloat64_t;
    }
    _svld1_f64(pg.into(), base)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1_s8(pg: svbool_t, base: *const i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv16i8")]
        fn _svld1_s8(pg: svbool_t, base: *const i8) -> svint8_t;
    }
    _svld1_s8(pg, base)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1_s16(pg: svbool_t, base: *const i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv8i16")]
        fn _svld1_s16(pg: svbool8_t, base: *const i16) -> svint16_t;
    }
    _svld1_s16(pg.into(), base)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_s32(pg: svbool_t, base: *const i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv4i32")]
        fn _svld1_s32(pg: svbool4_t, base: *const i32) -> svint32_t;
    }
    _svld1_s32(pg.into(), base)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_s64(pg: svbool_t, base: *const i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv2i64")]
        fn _svld1_s64(pg: svbool2_t, base: *const i64) -> svint64_t;
    }
    _svld1_s64(pg.into(), base)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1_u8(pg: svbool_t, base: *const u8) -> svuint8_t {
    svld1_s8(pg, base.as_signed()).as_unsigned()
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1_u16(pg: svbool_t, base: *const u16) -> svuint16_t {
    svld1_s16(pg, base.as_signed()).as_unsigned()
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_u32(pg: svbool_t, base: *const u32) -> svuint32_t {
    svld1_s32(pg, base.as_signed()).as_unsigned()
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_u64(pg: svbool_t, base: *const u64) -> svuint64_t {
    svld1_s64(pg, base.as_signed()).as_unsigned()
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[s32]index[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_s32index_f32(
    pg: svbool_t,
    base: *const f32,
    indices: svint32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.index.nxv4f32"
        )]
        fn _svld1_gather_s32index_f32(
            pg: svbool4_t,
            base: *const f32,
            indices: svint32_t,
        ) -> svfloat32_t;
    }
    _svld1_gather_s32index_f32(pg.into(), base, indices)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[s32]index[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_s32index_s32(
    pg: svbool_t,
    base: *const i32,
    indices: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.index.nxv4i32"
        )]
        fn _svld1_gather_s32index_s32(
            pg: svbool4_t,
            base: *const i32,
            indices: svint32_t,
        ) -> svint32_t;
    }
    _svld1_gather_s32index_s32(pg.into(), base, indices)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[s32]index[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_s32index_u32(
    pg: svbool_t,
    base: *const u32,
    indices: svint32_t,
) -> svuint32_t {
    svld1_gather_s32index_s32(pg, base.as_signed(), indices).as_unsigned()
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[s64]index[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_s64index_f64(
    pg: svbool_t,
    base: *const f64,
    indices: svint64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.index.nxv2f64"
        )]
        fn _svld1_gather_s64index_f64(
            pg: svbool2_t,
            base: *const f64,
            indices: svint64_t,
        ) -> svfloat64_t;
    }
    _svld1_gather_s64index_f64(pg.into(), base, indices)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[s64]index[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_s64index_s64(
    pg: svbool_t,
    base: *const i64,
    indices: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.index.nxv2i64"
        )]
        fn _svld1_gather_s64index_s64(
            pg: svbool2_t,
            base: *const i64,
            indices: svint64_t,
        ) -> svint64_t;
    }
    _svld1_gather_s64index_s64(pg.into(), base, indices)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[s64]index[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_s64index_u64(
    pg: svbool_t,
    base: *const u64,
    indices: svint64_t,
) -> svuint64_t {
    svld1_gather_s64index_s64(pg, base.as_signed(), indices).as_unsigned()
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[u32]index[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32index_f32(
    pg: svbool_t,
    base: *const f32,
    indices: svuint32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.index.nxv4f32"
        )]
        fn _svld1_gather_u32index_f32(
            pg: svbool4_t,
            base: *const f32,
            indices: svint32_t,
        ) -> svfloat32_t;
    }
    _svld1_gather_u32index_f32(pg.into(), base, indices.as_signed())
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[u32]index[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32index_s32(
    pg: svbool_t,
    base: *const i32,
    indices: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.index.nxv4i32"
        )]
        fn _svld1_gather_u32index_s32(
            pg: svbool4_t,
            base: *const i32,
            indices: svint32_t,
        ) -> svint32_t;
    }
    _svld1_gather_u32index_s32(pg.into(), base, indices.as_signed())
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[u32]index[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32index_u32(
    pg: svbool_t,
    base: *const u32,
    indices: svuint32_t,
) -> svuint32_t {
    svld1_gather_u32index_s32(pg, base.as_signed(), indices).as_unsigned()
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[u64]index[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64index_f64(
    pg: svbool_t,
    base: *const f64,
    indices: svuint64_t,
) -> svfloat64_t {
    svld1_gather_s64index_f64(pg, base, indices.as_signed())
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[u64]index[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64index_s64(
    pg: svbool_t,
    base: *const i64,
    indices: svuint64_t,
) -> svint64_t {
    svld1_gather_s64index_s64(pg, base, indices.as_signed())
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[u64]index[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64index_u64(
    pg: svbool_t,
    base: *const u64,
    indices: svuint64_t,
) -> svuint64_t {
    svld1_gather_s64index_s64(pg, base.as_signed(), indices.as_signed()).as_unsigned()
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[s32]offset[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_s32offset_f32(
    pg: svbool_t,
    base: *const f32,
    offsets: svint32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.nxv4f32"
        )]
        fn _svld1_gather_s32offset_f32(
            pg: svbool4_t,
            base: *const f32,
            offsets: svint32_t,
        ) -> svfloat32_t;
    }
    _svld1_gather_s32offset_f32(pg.into(), base, offsets)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[s32]offset[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_s32offset_s32(
    pg: svbool_t,
    base: *const i32,
    offsets: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.nxv4i32"
        )]
        fn _svld1_gather_s32offset_s32(
            pg: svbool4_t,
            base: *const i32,
            offsets: svint32_t,
        ) -> svint32_t;
    }
    _svld1_gather_s32offset_s32(pg.into(), base, offsets)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[s32]offset[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_s32offset_u32(
    pg: svbool_t,
    base: *const u32,
    offsets: svint32_t,
) -> svuint32_t {
    svld1_gather_s32offset_s32(pg, base.as_signed(), offsets).as_unsigned()
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[s64]offset[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_s64offset_f64(
    pg: svbool_t,
    base: *const f64,
    offsets: svint64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.nxv2f64"
        )]
        fn _svld1_gather_s64offset_f64(
            pg: svbool2_t,
            base: *const f64,
            offsets: svint64_t,
        ) -> svfloat64_t;
    }
    _svld1_gather_s64offset_f64(pg.into(), base, offsets)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[s64]offset[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_s64offset_s64(
    pg: svbool_t,
    base: *const i64,
    offsets: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.nxv2i64"
        )]
        fn _svld1_gather_s64offset_s64(
            pg: svbool2_t,
            base: *const i64,
            offsets: svint64_t,
        ) -> svint64_t;
    }
    _svld1_gather_s64offset_s64(pg.into(), base, offsets)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[s64]offset[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_s64offset_u64(
    pg: svbool_t,
    base: *const u64,
    offsets: svint64_t,
) -> svuint64_t {
    svld1_gather_s64offset_s64(pg, base.as_signed(), offsets).as_unsigned()
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[u32]offset[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32offset_f32(
    pg: svbool_t,
    base: *const f32,
    offsets: svuint32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.nxv4f32"
        )]
        fn _svld1_gather_u32offset_f32(
            pg: svbool4_t,
            base: *const f32,
            offsets: svint32_t,
        ) -> svfloat32_t;
    }
    _svld1_gather_u32offset_f32(pg.into(), base, offsets.as_signed())
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[u32]offset[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32offset_s32(
    pg: svbool_t,
    base: *const i32,
    offsets: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.nxv4i32"
        )]
        fn _svld1_gather_u32offset_s32(
            pg: svbool4_t,
            base: *const i32,
            offsets: svint32_t,
        ) -> svint32_t;
    }
    _svld1_gather_u32offset_s32(pg.into(), base, offsets.as_signed())
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[u32]offset[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32offset_u32(
    pg: svbool_t,
    base: *const u32,
    offsets: svuint32_t,
) -> svuint32_t {
    svld1_gather_u32offset_s32(pg, base.as_signed(), offsets).as_unsigned()
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[u64]offset[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64offset_f64(
    pg: svbool_t,
    base: *const f64,
    offsets: svuint64_t,
) -> svfloat64_t {
    svld1_gather_s64offset_f64(pg, base, offsets.as_signed())
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[u64]offset[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64offset_s64(
    pg: svbool_t,
    base: *const i64,
    offsets: svuint64_t,
) -> svint64_t {
    svld1_gather_s64offset_s64(pg, base, offsets.as_signed())
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather_[u64]offset[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64offset_u64(
    pg: svbool_t,
    base: *const u64,
    offsets: svuint64_t,
) -> svuint64_t {
    svld1_gather_s64offset_s64(pg, base.as_signed(), offsets.as_signed()).as_unsigned()
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u32base]_f32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_f32(pg: svbool_t, bases: svuint32_t) -> svfloat32_t {
    svld1_gather_u32base_offset_f32(pg, bases, 0)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u32base]_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svld1_gather_u32base_offset_s32(pg, bases, 0)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u32base]_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svld1_gather_u32base_offset_u32(pg, bases, 0)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u64base]_f64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_f64(pg: svbool_t, bases: svuint64_t) -> svfloat64_t {
    svld1_gather_u64base_offset_f64(pg, bases, 0)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u64base]_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svld1_gather_u64base_offset_s64(pg, bases, 0)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u64base]_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svld1_gather_u64base_offset_u64(pg, bases, 0)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u32base]_index_f32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_index_f32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svfloat32_t {
    svld1_gather_u32base_offset_f32(pg, bases, index.unchecked_shl(2))
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u32base]_index_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_index_s32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svint32_t {
    svld1_gather_u32base_offset_s32(pg, bases, index.unchecked_shl(2))
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u32base]_index_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_index_u32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svuint32_t {
    svld1_gather_u32base_offset_u32(pg, bases, index.unchecked_shl(2))
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u64base]_index_f64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_index_f64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svfloat64_t {
    svld1_gather_u64base_offset_f64(pg, bases, index.unchecked_shl(3))
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u64base]_index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svld1_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(3))
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u64base]_index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svld1_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(3))
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u32base]_offset_f32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_offset_f32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv4f32.nxv4i32"
        )]
        fn _svld1_gather_u32base_offset_f32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> svfloat32_t;
    }
    _svld1_gather_u32base_offset_f32(pg.into(), bases.as_signed(), offset)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u32base]_offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv4i32.nxv4i32"
        )]
        fn _svld1_gather_u32base_offset_s32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> svint32_t;
    }
    _svld1_gather_u32base_offset_s32(pg.into(), bases.as_signed(), offset)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u32base]_offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    svld1_gather_u32base_offset_s32(pg, bases, offset).as_unsigned()
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u64base]_offset_f64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_offset_f64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv2f64.nxv2i64"
        )]
        fn _svld1_gather_u64base_offset_f64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> svfloat64_t;
    }
    _svld1_gather_u64base_offset_f64(pg.into(), bases.as_signed(), offset)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u64base]_offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv2i64.nxv2i64"
        )]
        fn _svld1_gather_u64base_offset_s64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> svint64_t;
    }
    _svld1_gather_u64base_offset_s64(pg.into(), bases.as_signed(), offset)
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_gather[_u64base]_offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    svld1_gather_u64base_offset_s64(pg, bases, offset).as_unsigned()
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_vnum[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_vnum_f32(pg: svbool_t, base: *const f32, vnum: i64) -> svfloat32_t {
    svld1_f32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_vnum[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_vnum_f64(pg: svbool_t, base: *const f64, vnum: i64) -> svfloat64_t {
    svld1_f64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_vnum[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1_vnum_s8(pg: svbool_t, base: *const i8, vnum: i64) -> svint8_t {
    svld1_s8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_vnum[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1_vnum_s16(pg: svbool_t, base: *const i16, vnum: i64) -> svint16_t {
    svld1_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_vnum[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_vnum_s32(pg: svbool_t, base: *const i32, vnum: i64) -> svint32_t {
    svld1_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_vnum[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_vnum_s64(pg: svbool_t, base: *const i64, vnum: i64) -> svint64_t {
    svld1_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_vnum[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1_vnum_u8(pg: svbool_t, base: *const u8, vnum: i64) -> svuint8_t {
    svld1_u8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_vnum[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1_vnum_u16(pg: svbool_t, base: *const u16, vnum: i64) -> svuint16_t {
    svld1_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_vnum[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1_vnum_u32(pg: svbool_t, base: *const u32, vnum: i64) -> svuint32_t {
    svld1_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Unextended load"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1_vnum[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1d))]
pub unsafe fn svld1_vnum_u64(pg: svbool_t, base: *const u64, vnum: i64) -> svuint64_t {
    svld1_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load and replicate 256 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ro[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1row))]
pub unsafe fn svld1ro_f32(pg: svbool_t, base: *const f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1ro.nxv4f32")]
        fn _svld1ro_f32(pg: svbool4_t, base: *const f32) -> svfloat32_t;
    }
    _svld1ro_f32(pg.into(), base)
}
#[doc = "Load and replicate 256 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ro[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1rod))]
pub unsafe fn svld1ro_f64(pg: svbool_t, base: *const f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1ro.nxv2f64")]
        fn _svld1ro_f64(pg: svbool2_t, base: *const f64) -> svfloat64_t;
    }
    _svld1ro_f64(pg.into(), base)
}
#[doc = "Load and replicate 256 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ro[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1rob))]
pub unsafe fn svld1ro_s8(pg: svbool_t, base: *const i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1ro.nxv16i8")]
        fn _svld1ro_s8(pg: svbool_t, base: *const i8) -> svint8_t;
    }
    _svld1ro_s8(pg, base)
}
#[doc = "Load and replicate 256 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ro[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1roh))]
pub unsafe fn svld1ro_s16(pg: svbool_t, base: *const i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1ro.nxv8i16")]
        fn _svld1ro_s16(pg: svbool8_t, base: *const i16) -> svint16_t;
    }
    _svld1ro_s16(pg.into(), base)
}
#[doc = "Load and replicate 256 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ro[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1row))]
pub unsafe fn svld1ro_s32(pg: svbool_t, base: *const i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1ro.nxv4i32")]
        fn _svld1ro_s32(pg: svbool4_t, base: *const i32) -> svint32_t;
    }
    _svld1ro_s32(pg.into(), base)
}
#[doc = "Load and replicate 256 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ro[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1rod))]
pub unsafe fn svld1ro_s64(pg: svbool_t, base: *const i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1ro.nxv2i64")]
        fn _svld1ro_s64(pg: svbool2_t, base: *const i64) -> svint64_t;
    }
    _svld1ro_s64(pg.into(), base)
}
#[doc = "Load and replicate 256 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ro[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1rob))]
pub unsafe fn svld1ro_u8(pg: svbool_t, base: *const u8) -> svuint8_t {
    svld1ro_s8(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load and replicate 256 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ro[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1roh))]
pub unsafe fn svld1ro_u16(pg: svbool_t, base: *const u16) -> svuint16_t {
    svld1ro_s16(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load and replicate 256 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ro[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1row))]
pub unsafe fn svld1ro_u32(pg: svbool_t, base: *const u32) -> svuint32_t {
    svld1ro_s32(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load and replicate 256 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ro[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(ld1rod))]
pub unsafe fn svld1ro_u64(pg: svbool_t, base: *const u64) -> svuint64_t {
    svld1ro_s64(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load and replicate 128 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1rq[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqw))]
pub unsafe fn svld1rq_f32(pg: svbool_t, base: *const f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1rq.nxv4f32")]
        fn _svld1rq_f32(pg: svbool4_t, base: *const f32) -> svfloat32_t;
    }
    _svld1rq_f32(pg.into(), base)
}
#[doc = "Load and replicate 128 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1rq[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqd))]
pub unsafe fn svld1rq_f64(pg: svbool_t, base: *const f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1rq.nxv2f64")]
        fn _svld1rq_f64(pg: svbool2_t, base: *const f64) -> svfloat64_t;
    }
    _svld1rq_f64(pg.into(), base)
}
#[doc = "Load and replicate 128 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1rq[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqb))]
pub unsafe fn svld1rq_s8(pg: svbool_t, base: *const i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1rq.nxv16i8")]
        fn _svld1rq_s8(pg: svbool_t, base: *const i8) -> svint8_t;
    }
    _svld1rq_s8(pg, base)
}
#[doc = "Load and replicate 128 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1rq[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqh))]
pub unsafe fn svld1rq_s16(pg: svbool_t, base: *const i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1rq.nxv8i16")]
        fn _svld1rq_s16(pg: svbool8_t, base: *const i16) -> svint16_t;
    }
    _svld1rq_s16(pg.into(), base)
}
#[doc = "Load and replicate 128 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1rq[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqw))]
pub unsafe fn svld1rq_s32(pg: svbool_t, base: *const i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1rq.nxv4i32")]
        fn _svld1rq_s32(pg: svbool4_t, base: *const i32) -> svint32_t;
    }
    _svld1rq_s32(pg.into(), base)
}
#[doc = "Load and replicate 128 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1rq[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqd))]
pub unsafe fn svld1rq_s64(pg: svbool_t, base: *const i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1rq.nxv2i64")]
        fn _svld1rq_s64(pg: svbool2_t, base: *const i64) -> svint64_t;
    }
    _svld1rq_s64(pg.into(), base)
}
#[doc = "Load and replicate 128 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1rq[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqb))]
pub unsafe fn svld1rq_u8(pg: svbool_t, base: *const u8) -> svuint8_t {
    svld1rq_s8(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load and replicate 128 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1rq[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqh))]
pub unsafe fn svld1rq_u16(pg: svbool_t, base: *const u16) -> svuint16_t {
    svld1rq_s16(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load and replicate 128 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1rq[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqw))]
pub unsafe fn svld1rq_u32(pg: svbool_t, base: *const u32) -> svuint32_t {
    svld1rq_s32(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load and replicate 128 bits of data"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1rq[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1rqd))]
pub unsafe fn svld1rq_u64(pg: svbool_t, base: *const u64) -> svuint64_t {
    svld1rq_s64(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_gather_[s32]offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_s32offset_s32(
    pg: svbool_t,
    base: *const i8,
    offsets: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.nxv4i8"
        )]
        fn _svld1sb_gather_s32offset_s32(
            pg: svbool4_t,
            base: *const i8,
            offsets: svint32_t,
        ) -> nxv4i8;
    }
    simd_cast(_svld1sb_gather_s32offset_s32(pg.into(), base, offsets))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather_[s32]offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_s32offset_s32(
    pg: svbool_t,
    base: *const i16,
    offsets: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.nxv4i16"
        )]
        fn _svld1sh_gather_s32offset_s32(
            pg: svbool4_t,
            base: *const i16,
            offsets: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast(_svld1sh_gather_s32offset_s32(pg.into(), base, offsets))
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_gather_[s32]offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_s32offset_u32(
    pg: svbool_t,
    base: *const i8,
    offsets: svint32_t,
) -> svuint32_t {
    svld1sb_gather_s32offset_s32(pg, base, offsets).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather_[s32]offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_s32offset_u32(
    pg: svbool_t,
    base: *const i16,
    offsets: svint32_t,
) -> svuint32_t {
    svld1sh_gather_s32offset_s32(pg, base, offsets).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_gather_[s64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_s64offset_s64(
    pg: svbool_t,
    base: *const i8,
    offsets: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.nxv2i8"
        )]
        fn _svld1sb_gather_s64offset_s64(
            pg: svbool2_t,
            base: *const i8,
            offsets: svint64_t,
        ) -> nxv2i8;
    }
    simd_cast(_svld1sb_gather_s64offset_s64(pg.into(), base, offsets))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather_[s64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_s64offset_s64(
    pg: svbool_t,
    base: *const i16,
    offsets: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.nxv2i16"
        )]
        fn _svld1sh_gather_s64offset_s64(
            pg: svbool2_t,
            base: *const i16,
            offsets: svint64_t,
        ) -> nxv2i16;
    }
    simd_cast(_svld1sh_gather_s64offset_s64(pg.into(), base, offsets))
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_gather_[s64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_s64offset_s64(
    pg: svbool_t,
    base: *const i32,
    offsets: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.nxv2i32"
        )]
        fn _svld1sw_gather_s64offset_s64(
            pg: svbool2_t,
            base: *const i32,
            offsets: svint64_t,
        ) -> nxv2i32;
    }
    simd_cast(_svld1sw_gather_s64offset_s64(pg.into(), base, offsets))
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_gather_[s64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_s64offset_u64(
    pg: svbool_t,
    base: *const i8,
    offsets: svint64_t,
) -> svuint64_t {
    svld1sb_gather_s64offset_s64(pg, base, offsets).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather_[s64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_s64offset_u64(
    pg: svbool_t,
    base: *const i16,
    offsets: svint64_t,
) -> svuint64_t {
    svld1sh_gather_s64offset_s64(pg, base, offsets).as_unsigned()
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_gather_[s64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_s64offset_u64(
    pg: svbool_t,
    base: *const i32,
    offsets: svint64_t,
) -> svuint64_t {
    svld1sw_gather_s64offset_s64(pg, base, offsets).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_gather_[u32]offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u32offset_s32(
    pg: svbool_t,
    base: *const i8,
    offsets: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.nxv4i8"
        )]
        fn _svld1sb_gather_u32offset_s32(
            pg: svbool4_t,
            base: *const i8,
            offsets: svint32_t,
        ) -> nxv4i8;
    }
    simd_cast(_svld1sb_gather_u32offset_s32(
        pg.into(),
        base,
        offsets.as_signed(),
    ))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather_[u32]offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32offset_s32(
    pg: svbool_t,
    base: *const i16,
    offsets: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.nxv4i16"
        )]
        fn _svld1sh_gather_u32offset_s32(
            pg: svbool4_t,
            base: *const i16,
            offsets: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast(_svld1sh_gather_u32offset_s32(
        pg.into(),
        base,
        offsets.as_signed(),
    ))
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_gather_[u32]offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u32offset_u32(
    pg: svbool_t,
    base: *const i8,
    offsets: svuint32_t,
) -> svuint32_t {
    svld1sb_gather_u32offset_s32(pg, base, offsets).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather_[u32]offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32offset_u32(
    pg: svbool_t,
    base: *const i16,
    offsets: svuint32_t,
) -> svuint32_t {
    svld1sh_gather_u32offset_s32(pg, base, offsets).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_gather_[u64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u64offset_s64(
    pg: svbool_t,
    base: *const i8,
    offsets: svuint64_t,
) -> svint64_t {
    svld1sb_gather_s64offset_s64(pg, base, offsets.as_signed())
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather_[u64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64offset_s64(
    pg: svbool_t,
    base: *const i16,
    offsets: svuint64_t,
) -> svint64_t {
    svld1sh_gather_s64offset_s64(pg, base, offsets.as_signed())
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_gather_[u64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64offset_s64(
    pg: svbool_t,
    base: *const i32,
    offsets: svuint64_t,
) -> svint64_t {
    svld1sw_gather_s64offset_s64(pg, base, offsets.as_signed())
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_gather_[u64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u64offset_u64(
    pg: svbool_t,
    base: *const i8,
    offsets: svuint64_t,
) -> svuint64_t {
    svld1sb_gather_s64offset_s64(pg, base, offsets.as_signed()).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather_[u64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64offset_u64(
    pg: svbool_t,
    base: *const i16,
    offsets: svuint64_t,
) -> svuint64_t {
    svld1sh_gather_s64offset_s64(pg, base, offsets.as_signed()).as_unsigned()
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_gather_[u64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64offset_u64(
    pg: svbool_t,
    base: *const i32,
    offsets: svuint64_t,
) -> svuint64_t {
    svld1sw_gather_s64offset_s64(pg, base, offsets.as_signed()).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_gather[_u32base]_offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv4i8.nxv4i32"
        )]
        fn _svld1sb_gather_u32base_offset_s32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> nxv4i8;
    }
    simd_cast(_svld1sb_gather_u32base_offset_s32(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather[_u32base]_offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv4i16.nxv4i32"
        )]
        fn _svld1sh_gather_u32base_offset_s32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> nxv4i16;
    }
    simd_cast(_svld1sh_gather_u32base_offset_s32(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_gather[_u32base]_offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    svld1sb_gather_u32base_offset_s32(pg, bases, offset).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather[_u32base]_offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    svld1sh_gather_u32base_offset_s32(pg, bases, offset).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_gather[_u64base]_offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv2i8.nxv2i64"
        )]
        fn _svld1sb_gather_u64base_offset_s64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i8;
    }
    simd_cast(_svld1sb_gather_u64base_offset_s64(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather[_u64base]_offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv2i16.nxv2i64"
        )]
        fn _svld1sh_gather_u64base_offset_s64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i16;
    }
    simd_cast(_svld1sh_gather_u64base_offset_s64(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_gather[_u64base]_offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv2i32.nxv2i64"
        )]
        fn _svld1sw_gather_u64base_offset_s64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i32;
    }
    simd_cast(_svld1sw_gather_u64base_offset_s64(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_gather[_u64base]_offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    svld1sb_gather_u64base_offset_s64(pg, bases, offset).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather[_u64base]_offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    svld1sh_gather_u64base_offset_s64(pg, bases, offset).as_unsigned()
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_gather[_u64base]_offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    svld1sw_gather_u64base_offset_s64(pg, bases, offset).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_gather[_u32base]_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svld1sb_gather_u32base_offset_s32(pg, bases, 0)
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather[_u32base]_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svld1sh_gather_u32base_offset_s32(pg, bases, 0)
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_gather[_u32base]_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svld1sb_gather_u32base_offset_u32(pg, bases, 0)
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather[_u32base]_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svld1sh_gather_u32base_offset_u32(pg, bases, 0)
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_gather[_u64base]_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svld1sb_gather_u64base_offset_s64(pg, bases, 0)
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather[_u64base]_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svld1sh_gather_u64base_offset_s64(pg, bases, 0)
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_gather[_u64base]_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svld1sw_gather_u64base_offset_s64(pg, bases, 0)
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_gather[_u64base]_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svld1sb_gather_u64base_offset_u64(pg, bases, 0)
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather[_u64base]_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svld1sh_gather_u64base_offset_u64(pg, bases, 0)
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_gather[_u64base]_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svld1sw_gather_u64base_offset_u64(pg, bases, 0)
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_s16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_s16(pg: svbool_t, base: *const i8) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv8i8")]
        fn _svld1sb_s16(pg: svbool8_t, base: *const i8) -> nxv8i8;
    }
    simd_cast(_svld1sb_s16(pg.into(), base))
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_s32(pg: svbool_t, base: *const i8) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv4i8")]
        fn _svld1sb_s32(pg: svbool4_t, base: *const i8) -> nxv4i8;
    }
    simd_cast(_svld1sb_s32(pg.into(), base))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_s32(pg: svbool_t, base: *const i16) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv4i16")]
        fn _svld1sh_s32(pg: svbool4_t, base: *const i16) -> nxv4i16;
    }
    simd_cast(_svld1sh_s32(pg.into(), base))
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_s64(pg: svbool_t, base: *const i8) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv2i8")]
        fn _svld1sb_s64(pg: svbool2_t, base: *const i8) -> nxv2i8;
    }
    simd_cast(_svld1sb_s64(pg.into(), base))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_s64(pg: svbool_t, base: *const i16) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv2i16")]
        fn _svld1sh_s64(pg: svbool2_t, base: *const i16) -> nxv2i16;
    }
    simd_cast(_svld1sh_s64(pg.into(), base))
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_s64(pg: svbool_t, base: *const i32) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv2i32")]
        fn _svld1sw_s64(pg: svbool2_t, base: *const i32) -> nxv2i32;
    }
    simd_cast(_svld1sw_s64(pg.into(), base))
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_u16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_u16(pg: svbool_t, base: *const i8) -> svuint16_t {
    svld1sb_s16(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_u32(pg: svbool_t, base: *const i8) -> svuint32_t {
    svld1sb_s32(pg, base).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_u32(pg: svbool_t, base: *const i16) -> svuint32_t {
    svld1sh_s32(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_u64(pg: svbool_t, base: *const i8) -> svuint64_t {
    svld1sb_s64(pg, base).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_u64(pg: svbool_t, base: *const i16) -> svuint64_t {
    svld1sh_s64(pg, base).as_unsigned()
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_u64(pg: svbool_t, base: *const i32) -> svuint64_t {
    svld1sw_s64(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_vnum_s16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_vnum_s16(pg: svbool_t, base: *const i8, vnum: i64) -> svint16_t {
    svld1sb_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_vnum_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_vnum_s32(pg: svbool_t, base: *const i8, vnum: i64) -> svint32_t {
    svld1sb_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_vnum_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_vnum_s32(pg: svbool_t, base: *const i16, vnum: i64) -> svint32_t {
    svld1sh_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_vnum_s64(pg: svbool_t, base: *const i8, vnum: i64) -> svint64_t {
    svld1sb_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_vnum_s64(pg: svbool_t, base: *const i16, vnum: i64) -> svint64_t {
    svld1sh_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_vnum_s64(pg: svbool_t, base: *const i32, vnum: i64) -> svint64_t {
    svld1sw_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_vnum_u16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_vnum_u16(pg: svbool_t, base: *const i8, vnum: i64) -> svuint16_t {
    svld1sb_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_vnum_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_vnum_u32(pg: svbool_t, base: *const i8, vnum: i64) -> svuint32_t {
    svld1sb_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_vnum_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_vnum_u32(pg: svbool_t, base: *const i16, vnum: i64) -> svuint32_t {
    svld1sh_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sb_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sb))]
pub unsafe fn svld1sb_vnum_u64(pg: svbool_t, base: *const i8, vnum: i64) -> svuint64_t {
    svld1sb_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_vnum_u64(pg: svbool_t, base: *const i16, vnum: i64) -> svuint64_t {
    svld1sh_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_vnum_u64(pg: svbool_t, base: *const i32, vnum: i64) -> svuint64_t {
    svld1sw_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather_[s32]index_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_s32index_s32(
    pg: svbool_t,
    base: *const i16,
    indices: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.index.nxv4i16"
        )]
        fn _svld1sh_gather_s32index_s32(
            pg: svbool4_t,
            base: *const i16,
            indices: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast(_svld1sh_gather_s32index_s32(pg.into(), base, indices))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather_[s32]index_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_s32index_u32(
    pg: svbool_t,
    base: *const i16,
    indices: svint32_t,
) -> svuint32_t {
    svld1sh_gather_s32index_s32(pg, base, indices).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather_[s64]index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_s64index_s64(
    pg: svbool_t,
    base: *const i16,
    indices: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.index.nxv2i16"
        )]
        fn _svld1sh_gather_s64index_s64(
            pg: svbool2_t,
            base: *const i16,
            indices: svint64_t,
        ) -> nxv2i16;
    }
    simd_cast(_svld1sh_gather_s64index_s64(pg.into(), base, indices))
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_gather_[s64]index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_s64index_s64(
    pg: svbool_t,
    base: *const i32,
    indices: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.index.nxv2i32"
        )]
        fn _svld1sw_gather_s64index_s64(
            pg: svbool2_t,
            base: *const i32,
            indices: svint64_t,
        ) -> nxv2i32;
    }
    simd_cast(_svld1sw_gather_s64index_s64(pg.into(), base, indices))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather_[s64]index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_s64index_u64(
    pg: svbool_t,
    base: *const i16,
    indices: svint64_t,
) -> svuint64_t {
    svld1sh_gather_s64index_s64(pg, base, indices).as_unsigned()
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_gather_[s64]index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_s64index_u64(
    pg: svbool_t,
    base: *const i32,
    indices: svint64_t,
) -> svuint64_t {
    svld1sw_gather_s64index_s64(pg, base, indices).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather_[u32]index_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32index_s32(
    pg: svbool_t,
    base: *const i16,
    indices: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.index.nxv4i16"
        )]
        fn _svld1sh_gather_u32index_s32(
            pg: svbool4_t,
            base: *const i16,
            indices: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast(_svld1sh_gather_u32index_s32(
        pg.into(),
        base,
        indices.as_signed(),
    ))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather_[u32]index_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32index_u32(
    pg: svbool_t,
    base: *const i16,
    indices: svuint32_t,
) -> svuint32_t {
    svld1sh_gather_u32index_s32(pg, base, indices).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather_[u64]index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64index_s64(
    pg: svbool_t,
    base: *const i16,
    indices: svuint64_t,
) -> svint64_t {
    svld1sh_gather_s64index_s64(pg, base, indices.as_signed())
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_gather_[u64]index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64index_s64(
    pg: svbool_t,
    base: *const i32,
    indices: svuint64_t,
) -> svint64_t {
    svld1sw_gather_s64index_s64(pg, base, indices.as_signed())
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather_[u64]index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64index_u64(
    pg: svbool_t,
    base: *const i16,
    indices: svuint64_t,
) -> svuint64_t {
    svld1sh_gather_s64index_s64(pg, base, indices.as_signed()).as_unsigned()
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_gather_[u64]index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64index_u64(
    pg: svbool_t,
    base: *const i32,
    indices: svuint64_t,
) -> svuint64_t {
    svld1sw_gather_s64index_s64(pg, base, indices.as_signed()).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather[_u32base]_index_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32base_index_s32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svint32_t {
    svld1sh_gather_u32base_offset_s32(pg, bases, index.unchecked_shl(1))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather[_u32base]_index_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u32base_index_u32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svuint32_t {
    svld1sh_gather_u32base_offset_u32(pg, bases, index.unchecked_shl(1))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather[_u64base]_index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svld1sh_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(1))
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_gather[_u64base]_index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svld1sw_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(2))
}
#[doc = "Load 16-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sh_gather[_u64base]_index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sh))]
pub unsafe fn svld1sh_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svld1sh_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(1))
}
#[doc = "Load 32-bit data and sign-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1sw_gather[_u64base]_index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1sw))]
pub unsafe fn svld1sw_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svld1sw_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(2))
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_gather_[s32]offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_s32offset_s32(
    pg: svbool_t,
    base: *const u8,
    offsets: svint32_t,
) -> svint32_t {
    svld1ub_gather_s32offset_u32(pg, base, offsets).as_signed()
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather_[s32]offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_s32offset_s32(
    pg: svbool_t,
    base: *const u16,
    offsets: svint32_t,
) -> svint32_t {
    svld1uh_gather_s32offset_u32(pg, base, offsets).as_signed()
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_gather_[s32]offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_s32offset_u32(
    pg: svbool_t,
    base: *const u8,
    offsets: svint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.nxv4i8"
        )]
        fn _svld1ub_gather_s32offset_u32(
            pg: svbool4_t,
            base: *const i8,
            offsets: svint32_t,
        ) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(
        _svld1ub_gather_s32offset_u32(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather_[s32]offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_s32offset_u32(
    pg: svbool_t,
    base: *const u16,
    offsets: svint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.nxv4i16"
        )]
        fn _svld1uh_gather_s32offset_u32(
            pg: svbool4_t,
            base: *const i16,
            offsets: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svld1uh_gather_s32offset_u32(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_gather_[s64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_s64offset_s64(
    pg: svbool_t,
    base: *const u8,
    offsets: svint64_t,
) -> svint64_t {
    svld1ub_gather_s64offset_u64(pg, base, offsets).as_signed()
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather_[s64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_s64offset_s64(
    pg: svbool_t,
    base: *const u16,
    offsets: svint64_t,
) -> svint64_t {
    svld1uh_gather_s64offset_u64(pg, base, offsets).as_signed()
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_gather_[s64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_s64offset_s64(
    pg: svbool_t,
    base: *const u32,
    offsets: svint64_t,
) -> svint64_t {
    svld1uw_gather_s64offset_u64(pg, base, offsets).as_signed()
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_gather_[s64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_s64offset_u64(
    pg: svbool_t,
    base: *const u8,
    offsets: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.nxv2i8"
        )]
        fn _svld1ub_gather_s64offset_u64(
            pg: svbool2_t,
            base: *const i8,
            offsets: svint64_t,
        ) -> nxv2i8;
    }
    simd_cast::<nxv2u8, _>(
        _svld1ub_gather_s64offset_u64(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather_[s64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_s64offset_u64(
    pg: svbool_t,
    base: *const u16,
    offsets: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.nxv2i16"
        )]
        fn _svld1uh_gather_s64offset_u64(
            pg: svbool2_t,
            base: *const i16,
            offsets: svint64_t,
        ) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(
        _svld1uh_gather_s64offset_u64(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_gather_[s64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_s64offset_u64(
    pg: svbool_t,
    base: *const u32,
    offsets: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.nxv2i32"
        )]
        fn _svld1uw_gather_s64offset_u64(
            pg: svbool2_t,
            base: *const i32,
            offsets: svint64_t,
        ) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(
        _svld1uw_gather_s64offset_u64(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_gather_[u32]offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u32offset_s32(
    pg: svbool_t,
    base: *const u8,
    offsets: svuint32_t,
) -> svint32_t {
    svld1ub_gather_u32offset_u32(pg, base, offsets).as_signed()
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather_[u32]offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32offset_s32(
    pg: svbool_t,
    base: *const u16,
    offsets: svuint32_t,
) -> svint32_t {
    svld1uh_gather_u32offset_u32(pg, base, offsets).as_signed()
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_gather_[u32]offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u32offset_u32(
    pg: svbool_t,
    base: *const u8,
    offsets: svuint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.nxv4i8"
        )]
        fn _svld1ub_gather_u32offset_u32(
            pg: svbool4_t,
            base: *const i8,
            offsets: svint32_t,
        ) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(
        _svld1ub_gather_u32offset_u32(pg.into(), base.as_signed(), offsets.as_signed())
            .as_unsigned(),
    )
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather_[u32]offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32offset_u32(
    pg: svbool_t,
    base: *const u16,
    offsets: svuint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.nxv4i16"
        )]
        fn _svld1uh_gather_u32offset_u32(
            pg: svbool4_t,
            base: *const i16,
            offsets: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svld1uh_gather_u32offset_u32(pg.into(), base.as_signed(), offsets.as_signed())
            .as_unsigned(),
    )
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_gather_[u64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u64offset_s64(
    pg: svbool_t,
    base: *const u8,
    offsets: svuint64_t,
) -> svint64_t {
    svld1ub_gather_s64offset_u64(pg, base, offsets.as_signed()).as_signed()
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather_[u64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64offset_s64(
    pg: svbool_t,
    base: *const u16,
    offsets: svuint64_t,
) -> svint64_t {
    svld1uh_gather_s64offset_u64(pg, base, offsets.as_signed()).as_signed()
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_gather_[u64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64offset_s64(
    pg: svbool_t,
    base: *const u32,
    offsets: svuint64_t,
) -> svint64_t {
    svld1uw_gather_s64offset_u64(pg, base, offsets.as_signed()).as_signed()
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_gather_[u64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u64offset_u64(
    pg: svbool_t,
    base: *const u8,
    offsets: svuint64_t,
) -> svuint64_t {
    svld1ub_gather_s64offset_u64(pg, base, offsets.as_signed())
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather_[u64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64offset_u64(
    pg: svbool_t,
    base: *const u16,
    offsets: svuint64_t,
) -> svuint64_t {
    svld1uh_gather_s64offset_u64(pg, base, offsets.as_signed())
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_gather_[u64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64offset_u64(
    pg: svbool_t,
    base: *const u32,
    offsets: svuint64_t,
) -> svuint64_t {
    svld1uw_gather_s64offset_u64(pg, base, offsets.as_signed())
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_gather[_u32base]_offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    svld1ub_gather_u32base_offset_u32(pg, bases, offset).as_signed()
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather[_u32base]_offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    svld1uh_gather_u32base_offset_u32(pg, bases, offset).as_signed()
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_gather[_u32base]_offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv4i8.nxv4i32"
        )]
        fn _svld1ub_gather_u32base_offset_u32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(
        _svld1ub_gather_u32base_offset_u32(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather[_u32base]_offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv4i16.nxv4i32"
        )]
        fn _svld1uh_gather_u32base_offset_u32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svld1uh_gather_u32base_offset_u32(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_gather[_u64base]_offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    svld1ub_gather_u64base_offset_u64(pg, bases, offset).as_signed()
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather[_u64base]_offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    svld1uh_gather_u64base_offset_u64(pg, bases, offset).as_signed()
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_gather[_u64base]_offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    svld1uw_gather_u64base_offset_u64(pg, bases, offset).as_signed()
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_gather[_u64base]_offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv2i8.nxv2i64"
        )]
        fn _svld1ub_gather_u64base_offset_u64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i8;
    }
    simd_cast::<nxv2u8, _>(
        _svld1ub_gather_u64base_offset_u64(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather[_u64base]_offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv2i16.nxv2i64"
        )]
        fn _svld1uh_gather_u64base_offset_u64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(
        _svld1uh_gather_u64base_offset_u64(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_gather[_u64base]_offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.scalar.offset.nxv2i32.nxv2i64"
        )]
        fn _svld1uw_gather_u64base_offset_u64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(
        _svld1uw_gather_u64base_offset_u64(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_gather[_u32base]_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svld1ub_gather_u32base_offset_s32(pg, bases, 0)
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather[_u32base]_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svld1uh_gather_u32base_offset_s32(pg, bases, 0)
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_gather[_u32base]_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svld1ub_gather_u32base_offset_u32(pg, bases, 0)
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather[_u32base]_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svld1uh_gather_u32base_offset_u32(pg, bases, 0)
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_gather[_u64base]_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svld1ub_gather_u64base_offset_s64(pg, bases, 0)
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather[_u64base]_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svld1uh_gather_u64base_offset_s64(pg, bases, 0)
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_gather[_u64base]_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svld1uw_gather_u64base_offset_s64(pg, bases, 0)
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_gather[_u64base]_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svld1ub_gather_u64base_offset_u64(pg, bases, 0)
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather[_u64base]_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svld1uh_gather_u64base_offset_u64(pg, bases, 0)
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_gather[_u64base]_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svld1uw_gather_u64base_offset_u64(pg, bases, 0)
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_s16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_s16(pg: svbool_t, base: *const u8) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv8i8")]
        fn _svld1ub_s16(pg: svbool8_t, base: *const i8) -> nxv8i8;
    }
    simd_cast::<nxv8u8, _>(_svld1ub_s16(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_s32(pg: svbool_t, base: *const u8) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv4i8")]
        fn _svld1ub_s32(pg: svbool4_t, base: *const i8) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(_svld1ub_s32(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_s32(pg: svbool_t, base: *const u16) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv4i16")]
        fn _svld1uh_s32(pg: svbool4_t, base: *const i16) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(_svld1uh_s32(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_s64(pg: svbool_t, base: *const u8) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv2i8")]
        fn _svld1ub_s64(pg: svbool2_t, base: *const i8) -> nxv2i8;
    }
    simd_cast::<nxv2u8, _>(_svld1ub_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_s64(pg: svbool_t, base: *const u16) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv2i16")]
        fn _svld1uh_s64(pg: svbool2_t, base: *const i16) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(_svld1uh_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_s64(pg: svbool_t, base: *const u32) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ld1.nxv2i32")]
        fn _svld1uw_s64(pg: svbool2_t, base: *const i32) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(_svld1uw_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_u16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_u16(pg: svbool_t, base: *const u8) -> svuint16_t {
    svld1ub_s16(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_u32(pg: svbool_t, base: *const u8) -> svuint32_t {
    svld1ub_s32(pg, base).as_unsigned()
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_u32(pg: svbool_t, base: *const u16) -> svuint32_t {
    svld1uh_s32(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_u64(pg: svbool_t, base: *const u8) -> svuint64_t {
    svld1ub_s64(pg, base).as_unsigned()
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_u64(pg: svbool_t, base: *const u16) -> svuint64_t {
    svld1uh_s64(pg, base).as_unsigned()
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_u64(pg: svbool_t, base: *const u32) -> svuint64_t {
    svld1uw_s64(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_vnum_s16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_vnum_s16(pg: svbool_t, base: *const u8, vnum: i64) -> svint16_t {
    svld1ub_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_vnum_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_vnum_s32(pg: svbool_t, base: *const u8, vnum: i64) -> svint32_t {
    svld1ub_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_vnum_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_vnum_s32(pg: svbool_t, base: *const u16, vnum: i64) -> svint32_t {
    svld1uh_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_vnum_s64(pg: svbool_t, base: *const u8, vnum: i64) -> svint64_t {
    svld1ub_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_vnum_s64(pg: svbool_t, base: *const u16, vnum: i64) -> svint64_t {
    svld1uh_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_vnum_s64(pg: svbool_t, base: *const u32, vnum: i64) -> svint64_t {
    svld1uw_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_vnum_u16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_vnum_u16(pg: svbool_t, base: *const u8, vnum: i64) -> svuint16_t {
    svld1ub_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_vnum_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_vnum_u32(pg: svbool_t, base: *const u8, vnum: i64) -> svuint32_t {
    svld1ub_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_vnum_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_vnum_u32(pg: svbool_t, base: *const u16, vnum: i64) -> svuint32_t {
    svld1uh_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1ub_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1b))]
pub unsafe fn svld1ub_vnum_u64(pg: svbool_t, base: *const u8, vnum: i64) -> svuint64_t {
    svld1ub_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_vnum_u64(pg: svbool_t, base: *const u16, vnum: i64) -> svuint64_t {
    svld1uh_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_vnum_u64(pg: svbool_t, base: *const u32, vnum: i64) -> svuint64_t {
    svld1uw_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather_[s32]index_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_s32index_s32(
    pg: svbool_t,
    base: *const u16,
    indices: svint32_t,
) -> svint32_t {
    svld1uh_gather_s32index_u32(pg, base, indices).as_signed()
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather_[s32]index_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_s32index_u32(
    pg: svbool_t,
    base: *const u16,
    indices: svint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.sxtw.index.nxv4i16"
        )]
        fn _svld1uh_gather_s32index_u32(
            pg: svbool4_t,
            base: *const i16,
            indices: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svld1uh_gather_s32index_u32(pg.into(), base.as_signed(), indices).as_unsigned(),
    )
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather_[s64]index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_s64index_s64(
    pg: svbool_t,
    base: *const u16,
    indices: svint64_t,
) -> svint64_t {
    svld1uh_gather_s64index_u64(pg, base, indices).as_signed()
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_gather_[s64]index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_s64index_s64(
    pg: svbool_t,
    base: *const u32,
    indices: svint64_t,
) -> svint64_t {
    svld1uw_gather_s64index_u64(pg, base, indices).as_signed()
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather_[s64]index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_s64index_u64(
    pg: svbool_t,
    base: *const u16,
    indices: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.index.nxv2i16"
        )]
        fn _svld1uh_gather_s64index_u64(
            pg: svbool2_t,
            base: *const i16,
            indices: svint64_t,
        ) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(
        _svld1uh_gather_s64index_u64(pg.into(), base.as_signed(), indices).as_unsigned(),
    )
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_gather_[s64]index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_s64index_u64(
    pg: svbool_t,
    base: *const u32,
    indices: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.index.nxv2i32"
        )]
        fn _svld1uw_gather_s64index_u64(
            pg: svbool2_t,
            base: *const i32,
            indices: svint64_t,
        ) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(
        _svld1uw_gather_s64index_u64(pg.into(), base.as_signed(), indices).as_unsigned(),
    )
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather_[u32]index_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32index_s32(
    pg: svbool_t,
    base: *const u16,
    indices: svuint32_t,
) -> svint32_t {
    svld1uh_gather_u32index_u32(pg, base, indices).as_signed()
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather_[u32]index_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32index_u32(
    pg: svbool_t,
    base: *const u16,
    indices: svuint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld1.gather.uxtw.index.nxv4i16"
        )]
        fn _svld1uh_gather_u32index_u32(
            pg: svbool4_t,
            base: *const i16,
            indices: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svld1uh_gather_u32index_u32(pg.into(), base.as_signed(), indices.as_signed())
            .as_unsigned(),
    )
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather_[u64]index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64index_s64(
    pg: svbool_t,
    base: *const u16,
    indices: svuint64_t,
) -> svint64_t {
    svld1uh_gather_s64index_u64(pg, base, indices.as_signed()).as_signed()
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_gather_[u64]index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64index_s64(
    pg: svbool_t,
    base: *const u32,
    indices: svuint64_t,
) -> svint64_t {
    svld1uw_gather_s64index_u64(pg, base, indices.as_signed()).as_signed()
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather_[u64]index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64index_u64(
    pg: svbool_t,
    base: *const u16,
    indices: svuint64_t,
) -> svuint64_t {
    svld1uh_gather_s64index_u64(pg, base, indices.as_signed())
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_gather_[u64]index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64index_u64(
    pg: svbool_t,
    base: *const u32,
    indices: svuint64_t,
) -> svuint64_t {
    svld1uw_gather_s64index_u64(pg, base, indices.as_signed())
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather[_u32base]_index_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32base_index_s32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svint32_t {
    svld1uh_gather_u32base_offset_s32(pg, bases, index.unchecked_shl(1))
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather[_u32base]_index_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u32base_index_u32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svuint32_t {
    svld1uh_gather_u32base_offset_u32(pg, bases, index.unchecked_shl(1))
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather[_u64base]_index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svld1uh_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(1))
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_gather[_u64base]_index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svld1uw_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(2))
}
#[doc = "Load 16-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uh_gather[_u64base]_index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1h))]
pub unsafe fn svld1uh_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svld1uh_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(1))
}
#[doc = "Load 32-bit data and zero-extend"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld1uw_gather[_u64base]_index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld1w))]
pub unsafe fn svld1uw_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svld1uw_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(2))
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2w))]
pub unsafe fn svld2_f32(pg: svbool_t, base: *const f32) -> svfloat32x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld2.nxv8f32.nxv4i1"
        )]
        fn _svld2_f32(pg: svbool4_t, base: *const f32) -> svfloat32x2_t;
    }
    _svld2_f32(pg.into(), base)
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2d))]
pub unsafe fn svld2_f64(pg: svbool_t, base: *const f64) -> svfloat64x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld2.nxv4f64.nxv2i1"
        )]
        fn _svld2_f64(pg: svbool2_t, base: *const f64) -> svfloat64x2_t;
    }
    _svld2_f64(pg.into(), base)
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2b))]
pub unsafe fn svld2_s8(pg: svbool_t, base: *const i8) -> svint8x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld2.nxv32i8.nxv16i1"
        )]
        fn _svld2_s8(pg: svbool_t, base: *const i8) -> svint8x2_t;
    }
    _svld2_s8(pg, base)
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2h))]
pub unsafe fn svld2_s16(pg: svbool_t, base: *const i16) -> svint16x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld2.nxv16i16.nxv8i1"
        )]
        fn _svld2_s16(pg: svbool8_t, base: *const i16) -> svint16x2_t;
    }
    _svld2_s16(pg.into(), base)
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2w))]
pub unsafe fn svld2_s32(pg: svbool_t, base: *const i32) -> svint32x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld2.nxv8i32.nxv4i1"
        )]
        fn _svld2_s32(pg: svbool4_t, base: *const i32) -> svint32x2_t;
    }
    _svld2_s32(pg.into(), base)
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2d))]
pub unsafe fn svld2_s64(pg: svbool_t, base: *const i64) -> svint64x2_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld2.nxv4i64.nxv2i1"
        )]
        fn _svld2_s64(pg: svbool2_t, base: *const i64) -> svint64x2_t;
    }
    _svld2_s64(pg.into(), base)
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2b))]
pub unsafe fn svld2_u8(pg: svbool_t, base: *const u8) -> svuint8x2_t {
    svld2_s8(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2h))]
pub unsafe fn svld2_u16(pg: svbool_t, base: *const u16) -> svuint16x2_t {
    svld2_s16(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2w))]
pub unsafe fn svld2_u32(pg: svbool_t, base: *const u32) -> svuint32x2_t {
    svld2_s32(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2d))]
pub unsafe fn svld2_u64(pg: svbool_t, base: *const u64) -> svuint64x2_t {
    svld2_s64(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2_vnum[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2w))]
pub unsafe fn svld2_vnum_f32(pg: svbool_t, base: *const f32, vnum: i64) -> svfloat32x2_t {
    svld2_f32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2_vnum[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2d))]
pub unsafe fn svld2_vnum_f64(pg: svbool_t, base: *const f64, vnum: i64) -> svfloat64x2_t {
    svld2_f64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2_vnum[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2b))]
pub unsafe fn svld2_vnum_s8(pg: svbool_t, base: *const i8, vnum: i64) -> svint8x2_t {
    svld2_s8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2_vnum[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2h))]
pub unsafe fn svld2_vnum_s16(pg: svbool_t, base: *const i16, vnum: i64) -> svint16x2_t {
    svld2_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2_vnum[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2w))]
pub unsafe fn svld2_vnum_s32(pg: svbool_t, base: *const i32, vnum: i64) -> svint32x2_t {
    svld2_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2_vnum[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2d))]
pub unsafe fn svld2_vnum_s64(pg: svbool_t, base: *const i64, vnum: i64) -> svint64x2_t {
    svld2_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2_vnum[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2b))]
pub unsafe fn svld2_vnum_u8(pg: svbool_t, base: *const u8, vnum: i64) -> svuint8x2_t {
    svld2_u8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2_vnum[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2h))]
pub unsafe fn svld2_vnum_u16(pg: svbool_t, base: *const u16, vnum: i64) -> svuint16x2_t {
    svld2_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2_vnum[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2w))]
pub unsafe fn svld2_vnum_u32(pg: svbool_t, base: *const u32, vnum: i64) -> svuint32x2_t {
    svld2_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load two-element tuples into two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld2_vnum[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld2d))]
pub unsafe fn svld2_vnum_u64(pg: svbool_t, base: *const u64, vnum: i64) -> svuint64x2_t {
    svld2_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3w))]
pub unsafe fn svld3_f32(pg: svbool_t, base: *const f32) -> svfloat32x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld3.nxv12f32.nxv4i1"
        )]
        fn _svld3_f32(pg: svbool4_t, base: *const f32) -> svfloat32x3_t;
    }
    _svld3_f32(pg.into(), base)
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3d))]
pub unsafe fn svld3_f64(pg: svbool_t, base: *const f64) -> svfloat64x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld3.nxv6f64.nxv2i1"
        )]
        fn _svld3_f64(pg: svbool2_t, base: *const f64) -> svfloat64x3_t;
    }
    _svld3_f64(pg.into(), base)
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3b))]
pub unsafe fn svld3_s8(pg: svbool_t, base: *const i8) -> svint8x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld3.nxv48i8.nxv16i1"
        )]
        fn _svld3_s8(pg: svbool_t, base: *const i8) -> svint8x3_t;
    }
    _svld3_s8(pg, base)
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3h))]
pub unsafe fn svld3_s16(pg: svbool_t, base: *const i16) -> svint16x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld3.nxv24i16.nxv8i1"
        )]
        fn _svld3_s16(pg: svbool8_t, base: *const i16) -> svint16x3_t;
    }
    _svld3_s16(pg.into(), base)
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3w))]
pub unsafe fn svld3_s32(pg: svbool_t, base: *const i32) -> svint32x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld3.nxv12i32.nxv4i1"
        )]
        fn _svld3_s32(pg: svbool4_t, base: *const i32) -> svint32x3_t;
    }
    _svld3_s32(pg.into(), base)
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3d))]
pub unsafe fn svld3_s64(pg: svbool_t, base: *const i64) -> svint64x3_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld3.nxv6i64.nxv2i1"
        )]
        fn _svld3_s64(pg: svbool2_t, base: *const i64) -> svint64x3_t;
    }
    _svld3_s64(pg.into(), base)
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3b))]
pub unsafe fn svld3_u8(pg: svbool_t, base: *const u8) -> svuint8x3_t {
    svld3_s8(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3h))]
pub unsafe fn svld3_u16(pg: svbool_t, base: *const u16) -> svuint16x3_t {
    svld3_s16(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3w))]
pub unsafe fn svld3_u32(pg: svbool_t, base: *const u32) -> svuint32x3_t {
    svld3_s32(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3d))]
pub unsafe fn svld3_u64(pg: svbool_t, base: *const u64) -> svuint64x3_t {
    svld3_s64(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3_vnum[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3w))]
pub unsafe fn svld3_vnum_f32(pg: svbool_t, base: *const f32, vnum: i64) -> svfloat32x3_t {
    svld3_f32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3_vnum[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3d))]
pub unsafe fn svld3_vnum_f64(pg: svbool_t, base: *const f64, vnum: i64) -> svfloat64x3_t {
    svld3_f64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3_vnum[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3b))]
pub unsafe fn svld3_vnum_s8(pg: svbool_t, base: *const i8, vnum: i64) -> svint8x3_t {
    svld3_s8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3_vnum[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3h))]
pub unsafe fn svld3_vnum_s16(pg: svbool_t, base: *const i16, vnum: i64) -> svint16x3_t {
    svld3_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3_vnum[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3w))]
pub unsafe fn svld3_vnum_s32(pg: svbool_t, base: *const i32, vnum: i64) -> svint32x3_t {
    svld3_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3_vnum[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3d))]
pub unsafe fn svld3_vnum_s64(pg: svbool_t, base: *const i64, vnum: i64) -> svint64x3_t {
    svld3_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3_vnum[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3b))]
pub unsafe fn svld3_vnum_u8(pg: svbool_t, base: *const u8, vnum: i64) -> svuint8x3_t {
    svld3_u8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3_vnum[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3h))]
pub unsafe fn svld3_vnum_u16(pg: svbool_t, base: *const u16, vnum: i64) -> svuint16x3_t {
    svld3_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3_vnum[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3w))]
pub unsafe fn svld3_vnum_u32(pg: svbool_t, base: *const u32, vnum: i64) -> svuint32x3_t {
    svld3_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load three-element tuples into three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld3_vnum[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld3d))]
pub unsafe fn svld3_vnum_u64(pg: svbool_t, base: *const u64, vnum: i64) -> svuint64x3_t {
    svld3_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4w))]
pub unsafe fn svld4_f32(pg: svbool_t, base: *const f32) -> svfloat32x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld4.nxv16f32.nxv4i1"
        )]
        fn _svld4_f32(pg: svbool4_t, base: *const f32) -> svfloat32x4_t;
    }
    _svld4_f32(pg.into(), base)
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4d))]
pub unsafe fn svld4_f64(pg: svbool_t, base: *const f64) -> svfloat64x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld4.nxv8f64.nxv2i1"
        )]
        fn _svld4_f64(pg: svbool2_t, base: *const f64) -> svfloat64x4_t;
    }
    _svld4_f64(pg.into(), base)
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4b))]
pub unsafe fn svld4_s8(pg: svbool_t, base: *const i8) -> svint8x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld4.nxv64i8.nxv16i1"
        )]
        fn _svld4_s8(pg: svbool_t, base: *const i8) -> svint8x4_t;
    }
    _svld4_s8(pg, base)
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4h))]
pub unsafe fn svld4_s16(pg: svbool_t, base: *const i16) -> svint16x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld4.nxv32i16.nxv8i1"
        )]
        fn _svld4_s16(pg: svbool8_t, base: *const i16) -> svint16x4_t;
    }
    _svld4_s16(pg.into(), base)
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4w))]
pub unsafe fn svld4_s32(pg: svbool_t, base: *const i32) -> svint32x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld4.nxv16i32.nxv4i1"
        )]
        fn _svld4_s32(pg: svbool4_t, base: *const i32) -> svint32x4_t;
    }
    _svld4_s32(pg.into(), base)
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4d))]
pub unsafe fn svld4_s64(pg: svbool_t, base: *const i64) -> svint64x4_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ld4.nxv8i64.nxv2i1"
        )]
        fn _svld4_s64(pg: svbool2_t, base: *const i64) -> svint64x4_t;
    }
    _svld4_s64(pg.into(), base)
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4b))]
pub unsafe fn svld4_u8(pg: svbool_t, base: *const u8) -> svuint8x4_t {
    svld4_s8(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4h))]
pub unsafe fn svld4_u16(pg: svbool_t, base: *const u16) -> svuint16x4_t {
    svld4_s16(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4w))]
pub unsafe fn svld4_u32(pg: svbool_t, base: *const u32) -> svuint32x4_t {
    svld4_s32(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4d))]
pub unsafe fn svld4_u64(pg: svbool_t, base: *const u64) -> svuint64x4_t {
    svld4_s64(pg, base.as_signed()).as_unsigned()
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4_vnum[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4w))]
pub unsafe fn svld4_vnum_f32(pg: svbool_t, base: *const f32, vnum: i64) -> svfloat32x4_t {
    svld4_f32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4_vnum[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4d))]
pub unsafe fn svld4_vnum_f64(pg: svbool_t, base: *const f64, vnum: i64) -> svfloat64x4_t {
    svld4_f64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4_vnum[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4b))]
pub unsafe fn svld4_vnum_s8(pg: svbool_t, base: *const i8, vnum: i64) -> svint8x4_t {
    svld4_s8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4_vnum[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4h))]
pub unsafe fn svld4_vnum_s16(pg: svbool_t, base: *const i16, vnum: i64) -> svint16x4_t {
    svld4_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4_vnum[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4w))]
pub unsafe fn svld4_vnum_s32(pg: svbool_t, base: *const i32, vnum: i64) -> svint32x4_t {
    svld4_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4_vnum[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4d))]
pub unsafe fn svld4_vnum_s64(pg: svbool_t, base: *const i64, vnum: i64) -> svint64x4_t {
    svld4_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4_vnum[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4b))]
pub unsafe fn svld4_vnum_u8(pg: svbool_t, base: *const u8, vnum: i64) -> svuint8x4_t {
    svld4_u8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4_vnum[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4h))]
pub unsafe fn svld4_vnum_u16(pg: svbool_t, base: *const u16, vnum: i64) -> svuint16x4_t {
    svld4_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4_vnum[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4w))]
pub unsafe fn svld4_vnum_u32(pg: svbool_t, base: *const u32, vnum: i64) -> svuint32x4_t {
    svld4_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load four-element tuples into four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svld4_vnum[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ld4d))]
pub unsafe fn svld4_vnum_u64(pg: svbool_t, base: *const u64, vnum: i64) -> svuint64x4_t {
    svld4_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_f32(pg: svbool_t, base: *const f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv4f32")]
        fn _svldff1_f32(pg: svbool4_t, base: *const f32) -> svfloat32_t;
    }
    _svldff1_f32(pg.into(), base)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_f64(pg: svbool_t, base: *const f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv2f64")]
        fn _svldff1_f64(pg: svbool2_t, base: *const f64) -> svfloat64_t;
    }
    _svldff1_f64(pg.into(), base)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1_s8(pg: svbool_t, base: *const i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv16i8")]
        fn _svldff1_s8(pg: svbool_t, base: *const i8) -> svint8_t;
    }
    _svldff1_s8(pg, base)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1_s16(pg: svbool_t, base: *const i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv8i16")]
        fn _svldff1_s16(pg: svbool8_t, base: *const i16) -> svint16_t;
    }
    _svldff1_s16(pg.into(), base)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_s32(pg: svbool_t, base: *const i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv4i32")]
        fn _svldff1_s32(pg: svbool4_t, base: *const i32) -> svint32_t;
    }
    _svldff1_s32(pg.into(), base)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_s64(pg: svbool_t, base: *const i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv2i64")]
        fn _svldff1_s64(pg: svbool2_t, base: *const i64) -> svint64_t;
    }
    _svldff1_s64(pg.into(), base)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1_u8(pg: svbool_t, base: *const u8) -> svuint8_t {
    svldff1_s8(pg, base.as_signed()).as_unsigned()
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1_u16(pg: svbool_t, base: *const u16) -> svuint16_t {
    svldff1_s16(pg, base.as_signed()).as_unsigned()
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_u32(pg: svbool_t, base: *const u32) -> svuint32_t {
    svldff1_s32(pg, base.as_signed()).as_unsigned()
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_u64(pg: svbool_t, base: *const u64) -> svuint64_t {
    svldff1_s64(pg, base.as_signed()).as_unsigned()
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[s32]index[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_s32index_f32(
    pg: svbool_t,
    base: *const f32,
    indices: svint32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.index.nxv4f32"
        )]
        fn _svldff1_gather_s32index_f32(
            pg: svbool4_t,
            base: *const f32,
            indices: svint32_t,
        ) -> svfloat32_t;
    }
    _svldff1_gather_s32index_f32(pg.into(), base, indices)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[s32]index[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_s32index_s32(
    pg: svbool_t,
    base: *const i32,
    indices: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.index.nxv4i32"
        )]
        fn _svldff1_gather_s32index_s32(
            pg: svbool4_t,
            base: *const i32,
            indices: svint32_t,
        ) -> svint32_t;
    }
    _svldff1_gather_s32index_s32(pg.into(), base, indices)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[s32]index[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_s32index_u32(
    pg: svbool_t,
    base: *const u32,
    indices: svint32_t,
) -> svuint32_t {
    svldff1_gather_s32index_s32(pg, base.as_signed(), indices).as_unsigned()
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[s64]index[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_s64index_f64(
    pg: svbool_t,
    base: *const f64,
    indices: svint64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.index.nxv2f64"
        )]
        fn _svldff1_gather_s64index_f64(
            pg: svbool2_t,
            base: *const f64,
            indices: svint64_t,
        ) -> svfloat64_t;
    }
    _svldff1_gather_s64index_f64(pg.into(), base, indices)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[s64]index[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_s64index_s64(
    pg: svbool_t,
    base: *const i64,
    indices: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.index.nxv2i64"
        )]
        fn _svldff1_gather_s64index_s64(
            pg: svbool2_t,
            base: *const i64,
            indices: svint64_t,
        ) -> svint64_t;
    }
    _svldff1_gather_s64index_s64(pg.into(), base, indices)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[s64]index[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_s64index_u64(
    pg: svbool_t,
    base: *const u64,
    indices: svint64_t,
) -> svuint64_t {
    svldff1_gather_s64index_s64(pg, base.as_signed(), indices).as_unsigned()
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[u32]index[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32index_f32(
    pg: svbool_t,
    base: *const f32,
    indices: svuint32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.index.nxv4f32"
        )]
        fn _svldff1_gather_u32index_f32(
            pg: svbool4_t,
            base: *const f32,
            indices: svint32_t,
        ) -> svfloat32_t;
    }
    _svldff1_gather_u32index_f32(pg.into(), base, indices.as_signed())
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[u32]index[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32index_s32(
    pg: svbool_t,
    base: *const i32,
    indices: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.index.nxv4i32"
        )]
        fn _svldff1_gather_u32index_s32(
            pg: svbool4_t,
            base: *const i32,
            indices: svint32_t,
        ) -> svint32_t;
    }
    _svldff1_gather_u32index_s32(pg.into(), base, indices.as_signed())
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[u32]index[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32index_u32(
    pg: svbool_t,
    base: *const u32,
    indices: svuint32_t,
) -> svuint32_t {
    svldff1_gather_u32index_s32(pg, base.as_signed(), indices).as_unsigned()
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[u64]index[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64index_f64(
    pg: svbool_t,
    base: *const f64,
    indices: svuint64_t,
) -> svfloat64_t {
    svldff1_gather_s64index_f64(pg, base, indices.as_signed())
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[u64]index[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64index_s64(
    pg: svbool_t,
    base: *const i64,
    indices: svuint64_t,
) -> svint64_t {
    svldff1_gather_s64index_s64(pg, base, indices.as_signed())
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[u64]index[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64index_u64(
    pg: svbool_t,
    base: *const u64,
    indices: svuint64_t,
) -> svuint64_t {
    svldff1_gather_s64index_s64(pg, base.as_signed(), indices.as_signed()).as_unsigned()
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[s32]offset[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_s32offset_f32(
    pg: svbool_t,
    base: *const f32,
    offsets: svint32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.nxv4f32"
        )]
        fn _svldff1_gather_s32offset_f32(
            pg: svbool4_t,
            base: *const f32,
            offsets: svint32_t,
        ) -> svfloat32_t;
    }
    _svldff1_gather_s32offset_f32(pg.into(), base, offsets)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[s32]offset[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_s32offset_s32(
    pg: svbool_t,
    base: *const i32,
    offsets: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.nxv4i32"
        )]
        fn _svldff1_gather_s32offset_s32(
            pg: svbool4_t,
            base: *const i32,
            offsets: svint32_t,
        ) -> svint32_t;
    }
    _svldff1_gather_s32offset_s32(pg.into(), base, offsets)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[s32]offset[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_s32offset_u32(
    pg: svbool_t,
    base: *const u32,
    offsets: svint32_t,
) -> svuint32_t {
    svldff1_gather_s32offset_s32(pg, base.as_signed(), offsets).as_unsigned()
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[s64]offset[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_s64offset_f64(
    pg: svbool_t,
    base: *const f64,
    offsets: svint64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.nxv2f64"
        )]
        fn _svldff1_gather_s64offset_f64(
            pg: svbool2_t,
            base: *const f64,
            offsets: svint64_t,
        ) -> svfloat64_t;
    }
    _svldff1_gather_s64offset_f64(pg.into(), base, offsets)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[s64]offset[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_s64offset_s64(
    pg: svbool_t,
    base: *const i64,
    offsets: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.nxv2i64"
        )]
        fn _svldff1_gather_s64offset_s64(
            pg: svbool2_t,
            base: *const i64,
            offsets: svint64_t,
        ) -> svint64_t;
    }
    _svldff1_gather_s64offset_s64(pg.into(), base, offsets)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[s64]offset[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_s64offset_u64(
    pg: svbool_t,
    base: *const u64,
    offsets: svint64_t,
) -> svuint64_t {
    svldff1_gather_s64offset_s64(pg, base.as_signed(), offsets).as_unsigned()
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[u32]offset[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32offset_f32(
    pg: svbool_t,
    base: *const f32,
    offsets: svuint32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.nxv4f32"
        )]
        fn _svldff1_gather_u32offset_f32(
            pg: svbool4_t,
            base: *const f32,
            offsets: svint32_t,
        ) -> svfloat32_t;
    }
    _svldff1_gather_u32offset_f32(pg.into(), base, offsets.as_signed())
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[u32]offset[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32offset_s32(
    pg: svbool_t,
    base: *const i32,
    offsets: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.nxv4i32"
        )]
        fn _svldff1_gather_u32offset_s32(
            pg: svbool4_t,
            base: *const i32,
            offsets: svint32_t,
        ) -> svint32_t;
    }
    _svldff1_gather_u32offset_s32(pg.into(), base, offsets.as_signed())
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[u32]offset[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32offset_u32(
    pg: svbool_t,
    base: *const u32,
    offsets: svuint32_t,
) -> svuint32_t {
    svldff1_gather_u32offset_s32(pg, base.as_signed(), offsets).as_unsigned()
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[u64]offset[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64offset_f64(
    pg: svbool_t,
    base: *const f64,
    offsets: svuint64_t,
) -> svfloat64_t {
    svldff1_gather_s64offset_f64(pg, base, offsets.as_signed())
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[u64]offset[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64offset_s64(
    pg: svbool_t,
    base: *const i64,
    offsets: svuint64_t,
) -> svint64_t {
    svldff1_gather_s64offset_s64(pg, base, offsets.as_signed())
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather_[u64]offset[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64offset_u64(
    pg: svbool_t,
    base: *const u64,
    offsets: svuint64_t,
) -> svuint64_t {
    svldff1_gather_s64offset_s64(pg, base.as_signed(), offsets.as_signed()).as_unsigned()
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u32base]_f32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_f32(pg: svbool_t, bases: svuint32_t) -> svfloat32_t {
    svldff1_gather_u32base_offset_f32(pg, bases, 0)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u32base]_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svldff1_gather_u32base_offset_s32(pg, bases, 0)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u32base]_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svldff1_gather_u32base_offset_u32(pg, bases, 0)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u64base]_f64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_f64(pg: svbool_t, bases: svuint64_t) -> svfloat64_t {
    svldff1_gather_u64base_offset_f64(pg, bases, 0)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u64base]_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svldff1_gather_u64base_offset_s64(pg, bases, 0)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u64base]_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svldff1_gather_u64base_offset_u64(pg, bases, 0)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u32base]_index_f32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_index_f32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svfloat32_t {
    svldff1_gather_u32base_offset_f32(pg, bases, index.unchecked_shl(2))
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u32base]_index_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_index_s32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svint32_t {
    svldff1_gather_u32base_offset_s32(pg, bases, index.unchecked_shl(2))
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u32base]_index_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_index_u32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svuint32_t {
    svldff1_gather_u32base_offset_u32(pg, bases, index.unchecked_shl(2))
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u64base]_index_f64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_index_f64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svfloat64_t {
    svldff1_gather_u64base_offset_f64(pg, bases, index.unchecked_shl(3))
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u64base]_index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svldff1_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(3))
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u64base]_index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svldff1_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(3))
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u32base]_offset_f32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_offset_f32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv4f32.nxv4i32"
        )]
        fn _svldff1_gather_u32base_offset_f32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> svfloat32_t;
    }
    _svldff1_gather_u32base_offset_f32(pg.into(), bases.as_signed(), offset)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u32base]_offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv4i32.nxv4i32"
        )]
        fn _svldff1_gather_u32base_offset_s32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> svint32_t;
    }
    _svldff1_gather_u32base_offset_s32(pg.into(), bases.as_signed(), offset)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u32base]_offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    svldff1_gather_u32base_offset_s32(pg, bases, offset).as_unsigned()
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u64base]_offset_f64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_offset_f64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv2f64.nxv2i64"
        )]
        fn _svldff1_gather_u64base_offset_f64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> svfloat64_t;
    }
    _svldff1_gather_u64base_offset_f64(pg.into(), bases.as_signed(), offset)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u64base]_offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv2i64.nxv2i64"
        )]
        fn _svldff1_gather_u64base_offset_s64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> svint64_t;
    }
    _svldff1_gather_u64base_offset_s64(pg.into(), bases.as_signed(), offset)
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_gather[_u64base]_offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    svldff1_gather_u64base_offset_s64(pg, bases, offset).as_unsigned()
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_vnum[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_vnum_f32(pg: svbool_t, base: *const f32, vnum: i64) -> svfloat32_t {
    svldff1_f32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_vnum[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_vnum_f64(pg: svbool_t, base: *const f64, vnum: i64) -> svfloat64_t {
    svldff1_f64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_vnum[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1_vnum_s8(pg: svbool_t, base: *const i8, vnum: i64) -> svint8_t {
    svldff1_s8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_vnum[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1_vnum_s16(pg: svbool_t, base: *const i16, vnum: i64) -> svint16_t {
    svldff1_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_vnum[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_vnum_s32(pg: svbool_t, base: *const i32, vnum: i64) -> svint32_t {
    svldff1_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_vnum[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_vnum_s64(pg: svbool_t, base: *const i64, vnum: i64) -> svint64_t {
    svldff1_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_vnum[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1_vnum_u8(pg: svbool_t, base: *const u8, vnum: i64) -> svuint8_t {
    svldff1_u8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_vnum[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1_vnum_u16(pg: svbool_t, base: *const u16, vnum: i64) -> svuint16_t {
    svldff1_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_vnum[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1_vnum_u32(pg: svbool_t, base: *const u32, vnum: i64) -> svuint32_t {
    svldff1_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Unextended load, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1_vnum[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1d))]
pub unsafe fn svldff1_vnum_u64(pg: svbool_t, base: *const u64, vnum: i64) -> svuint64_t {
    svldff1_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_gather_[s32]offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_s32offset_s32(
    pg: svbool_t,
    base: *const i8,
    offsets: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.nxv4i8"
        )]
        fn _svldff1sb_gather_s32offset_s32(
            pg: svbool4_t,
            base: *const i8,
            offsets: svint32_t,
        ) -> nxv4i8;
    }
    simd_cast(_svldff1sb_gather_s32offset_s32(pg.into(), base, offsets))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather_[s32]offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_s32offset_s32(
    pg: svbool_t,
    base: *const i16,
    offsets: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.nxv4i16"
        )]
        fn _svldff1sh_gather_s32offset_s32(
            pg: svbool4_t,
            base: *const i16,
            offsets: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast(_svldff1sh_gather_s32offset_s32(pg.into(), base, offsets))
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_gather_[s32]offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_s32offset_u32(
    pg: svbool_t,
    base: *const i8,
    offsets: svint32_t,
) -> svuint32_t {
    svldff1sb_gather_s32offset_s32(pg, base, offsets).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather_[s32]offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_s32offset_u32(
    pg: svbool_t,
    base: *const i16,
    offsets: svint32_t,
) -> svuint32_t {
    svldff1sh_gather_s32offset_s32(pg, base, offsets).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_gather_[s64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_s64offset_s64(
    pg: svbool_t,
    base: *const i8,
    offsets: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.nxv2i8"
        )]
        fn _svldff1sb_gather_s64offset_s64(
            pg: svbool2_t,
            base: *const i8,
            offsets: svint64_t,
        ) -> nxv2i8;
    }
    simd_cast(_svldff1sb_gather_s64offset_s64(pg.into(), base, offsets))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather_[s64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_s64offset_s64(
    pg: svbool_t,
    base: *const i16,
    offsets: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.nxv2i16"
        )]
        fn _svldff1sh_gather_s64offset_s64(
            pg: svbool2_t,
            base: *const i16,
            offsets: svint64_t,
        ) -> nxv2i16;
    }
    simd_cast(_svldff1sh_gather_s64offset_s64(pg.into(), base, offsets))
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_gather_[s64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_s64offset_s64(
    pg: svbool_t,
    base: *const i32,
    offsets: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.nxv2i32"
        )]
        fn _svldff1sw_gather_s64offset_s64(
            pg: svbool2_t,
            base: *const i32,
            offsets: svint64_t,
        ) -> nxv2i32;
    }
    simd_cast(_svldff1sw_gather_s64offset_s64(pg.into(), base, offsets))
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_gather_[s64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_s64offset_u64(
    pg: svbool_t,
    base: *const i8,
    offsets: svint64_t,
) -> svuint64_t {
    svldff1sb_gather_s64offset_s64(pg, base, offsets).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather_[s64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_s64offset_u64(
    pg: svbool_t,
    base: *const i16,
    offsets: svint64_t,
) -> svuint64_t {
    svldff1sh_gather_s64offset_s64(pg, base, offsets).as_unsigned()
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_gather_[s64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_s64offset_u64(
    pg: svbool_t,
    base: *const i32,
    offsets: svint64_t,
) -> svuint64_t {
    svldff1sw_gather_s64offset_s64(pg, base, offsets).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_gather_[u32]offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u32offset_s32(
    pg: svbool_t,
    base: *const i8,
    offsets: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.nxv4i8"
        )]
        fn _svldff1sb_gather_u32offset_s32(
            pg: svbool4_t,
            base: *const i8,
            offsets: svint32_t,
        ) -> nxv4i8;
    }
    simd_cast(_svldff1sb_gather_u32offset_s32(
        pg.into(),
        base,
        offsets.as_signed(),
    ))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather_[u32]offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32offset_s32(
    pg: svbool_t,
    base: *const i16,
    offsets: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.nxv4i16"
        )]
        fn _svldff1sh_gather_u32offset_s32(
            pg: svbool4_t,
            base: *const i16,
            offsets: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast(_svldff1sh_gather_u32offset_s32(
        pg.into(),
        base,
        offsets.as_signed(),
    ))
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_gather_[u32]offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u32offset_u32(
    pg: svbool_t,
    base: *const i8,
    offsets: svuint32_t,
) -> svuint32_t {
    svldff1sb_gather_u32offset_s32(pg, base, offsets).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather_[u32]offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32offset_u32(
    pg: svbool_t,
    base: *const i16,
    offsets: svuint32_t,
) -> svuint32_t {
    svldff1sh_gather_u32offset_s32(pg, base, offsets).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_gather_[u64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u64offset_s64(
    pg: svbool_t,
    base: *const i8,
    offsets: svuint64_t,
) -> svint64_t {
    svldff1sb_gather_s64offset_s64(pg, base, offsets.as_signed())
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather_[u64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64offset_s64(
    pg: svbool_t,
    base: *const i16,
    offsets: svuint64_t,
) -> svint64_t {
    svldff1sh_gather_s64offset_s64(pg, base, offsets.as_signed())
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_gather_[u64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64offset_s64(
    pg: svbool_t,
    base: *const i32,
    offsets: svuint64_t,
) -> svint64_t {
    svldff1sw_gather_s64offset_s64(pg, base, offsets.as_signed())
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_gather_[u64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u64offset_u64(
    pg: svbool_t,
    base: *const i8,
    offsets: svuint64_t,
) -> svuint64_t {
    svldff1sb_gather_s64offset_s64(pg, base, offsets.as_signed()).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather_[u64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64offset_u64(
    pg: svbool_t,
    base: *const i16,
    offsets: svuint64_t,
) -> svuint64_t {
    svldff1sh_gather_s64offset_s64(pg, base, offsets.as_signed()).as_unsigned()
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_gather_[u64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64offset_u64(
    pg: svbool_t,
    base: *const i32,
    offsets: svuint64_t,
) -> svuint64_t {
    svldff1sw_gather_s64offset_s64(pg, base, offsets.as_signed()).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_gather[_u32base]_offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv4i8.nxv4i32"
        )]
        fn _svldff1sb_gather_u32base_offset_s32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> nxv4i8;
    }
    simd_cast(_svldff1sb_gather_u32base_offset_s32(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather[_u32base]_offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv4i16.nxv4i32"
        )]
        fn _svldff1sh_gather_u32base_offset_s32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> nxv4i16;
    }
    simd_cast(_svldff1sh_gather_u32base_offset_s32(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_gather[_u32base]_offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    svldff1sb_gather_u32base_offset_s32(pg, bases, offset).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather[_u32base]_offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    svldff1sh_gather_u32base_offset_s32(pg, bases, offset).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_gather[_u64base]_offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv2i8.nxv2i64"
        )]
        fn _svldff1sb_gather_u64base_offset_s64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i8;
    }
    simd_cast(_svldff1sb_gather_u64base_offset_s64(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather[_u64base]_offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv2i16.nxv2i64"
        )]
        fn _svldff1sh_gather_u64base_offset_s64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i16;
    }
    simd_cast(_svldff1sh_gather_u64base_offset_s64(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_gather[_u64base]_offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv2i32.nxv2i64"
        )]
        fn _svldff1sw_gather_u64base_offset_s64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i32;
    }
    simd_cast(_svldff1sw_gather_u64base_offset_s64(
        pg.into(),
        bases.as_signed(),
        offset,
    ))
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_gather[_u64base]_offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    svldff1sb_gather_u64base_offset_s64(pg, bases, offset).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather[_u64base]_offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    svldff1sh_gather_u64base_offset_s64(pg, bases, offset).as_unsigned()
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_gather[_u64base]_offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    svldff1sw_gather_u64base_offset_s64(pg, bases, offset).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_gather[_u32base]_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svldff1sb_gather_u32base_offset_s32(pg, bases, 0)
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather[_u32base]_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svldff1sh_gather_u32base_offset_s32(pg, bases, 0)
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_gather[_u32base]_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svldff1sb_gather_u32base_offset_u32(pg, bases, 0)
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather[_u32base]_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svldff1sh_gather_u32base_offset_u32(pg, bases, 0)
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_gather[_u64base]_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svldff1sb_gather_u64base_offset_s64(pg, bases, 0)
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather[_u64base]_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svldff1sh_gather_u64base_offset_s64(pg, bases, 0)
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_gather[_u64base]_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svldff1sw_gather_u64base_offset_s64(pg, bases, 0)
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_gather[_u64base]_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svldff1sb_gather_u64base_offset_u64(pg, bases, 0)
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather[_u64base]_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svldff1sh_gather_u64base_offset_u64(pg, bases, 0)
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_gather[_u64base]_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svldff1sw_gather_u64base_offset_u64(pg, bases, 0)
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_s16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_s16(pg: svbool_t, base: *const i8) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv8i8")]
        fn _svldff1sb_s16(pg: svbool8_t, base: *const i8) -> nxv8i8;
    }
    simd_cast(_svldff1sb_s16(pg.into(), base))
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_s32(pg: svbool_t, base: *const i8) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv4i8")]
        fn _svldff1sb_s32(pg: svbool4_t, base: *const i8) -> nxv4i8;
    }
    simd_cast(_svldff1sb_s32(pg.into(), base))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_s32(pg: svbool_t, base: *const i16) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv4i16")]
        fn _svldff1sh_s32(pg: svbool4_t, base: *const i16) -> nxv4i16;
    }
    simd_cast(_svldff1sh_s32(pg.into(), base))
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_s64(pg: svbool_t, base: *const i8) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv2i8")]
        fn _svldff1sb_s64(pg: svbool2_t, base: *const i8) -> nxv2i8;
    }
    simd_cast(_svldff1sb_s64(pg.into(), base))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_s64(pg: svbool_t, base: *const i16) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv2i16")]
        fn _svldff1sh_s64(pg: svbool2_t, base: *const i16) -> nxv2i16;
    }
    simd_cast(_svldff1sh_s64(pg.into(), base))
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_s64(pg: svbool_t, base: *const i32) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv2i32")]
        fn _svldff1sw_s64(pg: svbool2_t, base: *const i32) -> nxv2i32;
    }
    simd_cast(_svldff1sw_s64(pg.into(), base))
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_u16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_u16(pg: svbool_t, base: *const i8) -> svuint16_t {
    svldff1sb_s16(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_u32(pg: svbool_t, base: *const i8) -> svuint32_t {
    svldff1sb_s32(pg, base).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_u32(pg: svbool_t, base: *const i16) -> svuint32_t {
    svldff1sh_s32(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_u64(pg: svbool_t, base: *const i8) -> svuint64_t {
    svldff1sb_s64(pg, base).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_u64(pg: svbool_t, base: *const i16) -> svuint64_t {
    svldff1sh_s64(pg, base).as_unsigned()
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_u64(pg: svbool_t, base: *const i32) -> svuint64_t {
    svldff1sw_s64(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_vnum_s16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_vnum_s16(pg: svbool_t, base: *const i8, vnum: i64) -> svint16_t {
    svldff1sb_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_vnum_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_vnum_s32(pg: svbool_t, base: *const i8, vnum: i64) -> svint32_t {
    svldff1sb_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_vnum_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_vnum_s32(pg: svbool_t, base: *const i16, vnum: i64) -> svint32_t {
    svldff1sh_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_vnum_s64(pg: svbool_t, base: *const i8, vnum: i64) -> svint64_t {
    svldff1sb_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_vnum_s64(pg: svbool_t, base: *const i16, vnum: i64) -> svint64_t {
    svldff1sh_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_vnum_s64(pg: svbool_t, base: *const i32, vnum: i64) -> svint64_t {
    svldff1sw_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_vnum_u16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_vnum_u16(pg: svbool_t, base: *const i8, vnum: i64) -> svuint16_t {
    svldff1sb_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_vnum_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_vnum_u32(pg: svbool_t, base: *const i8, vnum: i64) -> svuint32_t {
    svldff1sb_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_vnum_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_vnum_u32(pg: svbool_t, base: *const i16, vnum: i64) -> svuint32_t {
    svldff1sh_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sb_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sb))]
pub unsafe fn svldff1sb_vnum_u64(pg: svbool_t, base: *const i8, vnum: i64) -> svuint64_t {
    svldff1sb_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_vnum_u64(pg: svbool_t, base: *const i16, vnum: i64) -> svuint64_t {
    svldff1sh_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_vnum_u64(pg: svbool_t, base: *const i32, vnum: i64) -> svuint64_t {
    svldff1sw_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather_[s32]index_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_s32index_s32(
    pg: svbool_t,
    base: *const i16,
    indices: svint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.index.nxv4i16"
        )]
        fn _svldff1sh_gather_s32index_s32(
            pg: svbool4_t,
            base: *const i16,
            indices: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast(_svldff1sh_gather_s32index_s32(pg.into(), base, indices))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather_[s32]index_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_s32index_u32(
    pg: svbool_t,
    base: *const i16,
    indices: svint32_t,
) -> svuint32_t {
    svldff1sh_gather_s32index_s32(pg, base, indices).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather_[s64]index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_s64index_s64(
    pg: svbool_t,
    base: *const i16,
    indices: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.index.nxv2i16"
        )]
        fn _svldff1sh_gather_s64index_s64(
            pg: svbool2_t,
            base: *const i16,
            indices: svint64_t,
        ) -> nxv2i16;
    }
    simd_cast(_svldff1sh_gather_s64index_s64(pg.into(), base, indices))
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_gather_[s64]index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_s64index_s64(
    pg: svbool_t,
    base: *const i32,
    indices: svint64_t,
) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.index.nxv2i32"
        )]
        fn _svldff1sw_gather_s64index_s64(
            pg: svbool2_t,
            base: *const i32,
            indices: svint64_t,
        ) -> nxv2i32;
    }
    simd_cast(_svldff1sw_gather_s64index_s64(pg.into(), base, indices))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather_[s64]index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_s64index_u64(
    pg: svbool_t,
    base: *const i16,
    indices: svint64_t,
) -> svuint64_t {
    svldff1sh_gather_s64index_s64(pg, base, indices).as_unsigned()
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_gather_[s64]index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_s64index_u64(
    pg: svbool_t,
    base: *const i32,
    indices: svint64_t,
) -> svuint64_t {
    svldff1sw_gather_s64index_s64(pg, base, indices).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather_[u32]index_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32index_s32(
    pg: svbool_t,
    base: *const i16,
    indices: svuint32_t,
) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.index.nxv4i16"
        )]
        fn _svldff1sh_gather_u32index_s32(
            pg: svbool4_t,
            base: *const i16,
            indices: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast(_svldff1sh_gather_u32index_s32(
        pg.into(),
        base,
        indices.as_signed(),
    ))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather_[u32]index_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32index_u32(
    pg: svbool_t,
    base: *const i16,
    indices: svuint32_t,
) -> svuint32_t {
    svldff1sh_gather_u32index_s32(pg, base, indices).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather_[u64]index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64index_s64(
    pg: svbool_t,
    base: *const i16,
    indices: svuint64_t,
) -> svint64_t {
    svldff1sh_gather_s64index_s64(pg, base, indices.as_signed())
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_gather_[u64]index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64index_s64(
    pg: svbool_t,
    base: *const i32,
    indices: svuint64_t,
) -> svint64_t {
    svldff1sw_gather_s64index_s64(pg, base, indices.as_signed())
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather_[u64]index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64index_u64(
    pg: svbool_t,
    base: *const i16,
    indices: svuint64_t,
) -> svuint64_t {
    svldff1sh_gather_s64index_s64(pg, base, indices.as_signed()).as_unsigned()
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_gather_[u64]index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64index_u64(
    pg: svbool_t,
    base: *const i32,
    indices: svuint64_t,
) -> svuint64_t {
    svldff1sw_gather_s64index_s64(pg, base, indices.as_signed()).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather[_u32base]_index_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32base_index_s32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svint32_t {
    svldff1sh_gather_u32base_offset_s32(pg, bases, index.unchecked_shl(1))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather[_u32base]_index_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u32base_index_u32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svuint32_t {
    svldff1sh_gather_u32base_offset_u32(pg, bases, index.unchecked_shl(1))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather[_u64base]_index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svldff1sh_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(1))
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_gather[_u64base]_index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svldff1sw_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(2))
}
#[doc = "Load 16-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sh_gather[_u64base]_index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sh))]
pub unsafe fn svldff1sh_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svldff1sh_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(1))
}
#[doc = "Load 32-bit data and sign-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1sw_gather[_u64base]_index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1sw))]
pub unsafe fn svldff1sw_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svldff1sw_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(2))
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_gather_[s32]offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_s32offset_s32(
    pg: svbool_t,
    base: *const u8,
    offsets: svint32_t,
) -> svint32_t {
    svldff1ub_gather_s32offset_u32(pg, base, offsets).as_signed()
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather_[s32]offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_s32offset_s32(
    pg: svbool_t,
    base: *const u16,
    offsets: svint32_t,
) -> svint32_t {
    svldff1uh_gather_s32offset_u32(pg, base, offsets).as_signed()
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_gather_[s32]offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_s32offset_u32(
    pg: svbool_t,
    base: *const u8,
    offsets: svint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.nxv4i8"
        )]
        fn _svldff1ub_gather_s32offset_u32(
            pg: svbool4_t,
            base: *const i8,
            offsets: svint32_t,
        ) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(
        _svldff1ub_gather_s32offset_u32(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather_[s32]offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_s32offset_u32(
    pg: svbool_t,
    base: *const u16,
    offsets: svint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.nxv4i16"
        )]
        fn _svldff1uh_gather_s32offset_u32(
            pg: svbool4_t,
            base: *const i16,
            offsets: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svldff1uh_gather_s32offset_u32(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_gather_[s64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_s64offset_s64(
    pg: svbool_t,
    base: *const u8,
    offsets: svint64_t,
) -> svint64_t {
    svldff1ub_gather_s64offset_u64(pg, base, offsets).as_signed()
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather_[s64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_s64offset_s64(
    pg: svbool_t,
    base: *const u16,
    offsets: svint64_t,
) -> svint64_t {
    svldff1uh_gather_s64offset_u64(pg, base, offsets).as_signed()
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_gather_[s64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_s64offset_s64(
    pg: svbool_t,
    base: *const u32,
    offsets: svint64_t,
) -> svint64_t {
    svldff1uw_gather_s64offset_u64(pg, base, offsets).as_signed()
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_gather_[s64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_s64offset_u64(
    pg: svbool_t,
    base: *const u8,
    offsets: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.nxv2i8"
        )]
        fn _svldff1ub_gather_s64offset_u64(
            pg: svbool2_t,
            base: *const i8,
            offsets: svint64_t,
        ) -> nxv2i8;
    }
    simd_cast::<nxv2u8, _>(
        _svldff1ub_gather_s64offset_u64(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather_[s64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_s64offset_u64(
    pg: svbool_t,
    base: *const u16,
    offsets: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.nxv2i16"
        )]
        fn _svldff1uh_gather_s64offset_u64(
            pg: svbool2_t,
            base: *const i16,
            offsets: svint64_t,
        ) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(
        _svldff1uh_gather_s64offset_u64(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_gather_[s64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_s64offset_u64(
    pg: svbool_t,
    base: *const u32,
    offsets: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.nxv2i32"
        )]
        fn _svldff1uw_gather_s64offset_u64(
            pg: svbool2_t,
            base: *const i32,
            offsets: svint64_t,
        ) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(
        _svldff1uw_gather_s64offset_u64(pg.into(), base.as_signed(), offsets).as_unsigned(),
    )
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_gather_[u32]offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u32offset_s32(
    pg: svbool_t,
    base: *const u8,
    offsets: svuint32_t,
) -> svint32_t {
    svldff1ub_gather_u32offset_u32(pg, base, offsets).as_signed()
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather_[u32]offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32offset_s32(
    pg: svbool_t,
    base: *const u16,
    offsets: svuint32_t,
) -> svint32_t {
    svldff1uh_gather_u32offset_u32(pg, base, offsets).as_signed()
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_gather_[u32]offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u32offset_u32(
    pg: svbool_t,
    base: *const u8,
    offsets: svuint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.nxv4i8"
        )]
        fn _svldff1ub_gather_u32offset_u32(
            pg: svbool4_t,
            base: *const i8,
            offsets: svint32_t,
        ) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(
        _svldff1ub_gather_u32offset_u32(pg.into(), base.as_signed(), offsets.as_signed())
            .as_unsigned(),
    )
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather_[u32]offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32offset_u32(
    pg: svbool_t,
    base: *const u16,
    offsets: svuint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.nxv4i16"
        )]
        fn _svldff1uh_gather_u32offset_u32(
            pg: svbool4_t,
            base: *const i16,
            offsets: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svldff1uh_gather_u32offset_u32(pg.into(), base.as_signed(), offsets.as_signed())
            .as_unsigned(),
    )
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_gather_[u64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u64offset_s64(
    pg: svbool_t,
    base: *const u8,
    offsets: svuint64_t,
) -> svint64_t {
    svldff1ub_gather_s64offset_u64(pg, base, offsets.as_signed()).as_signed()
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather_[u64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64offset_s64(
    pg: svbool_t,
    base: *const u16,
    offsets: svuint64_t,
) -> svint64_t {
    svldff1uh_gather_s64offset_u64(pg, base, offsets.as_signed()).as_signed()
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_gather_[u64]offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64offset_s64(
    pg: svbool_t,
    base: *const u32,
    offsets: svuint64_t,
) -> svint64_t {
    svldff1uw_gather_s64offset_u64(pg, base, offsets.as_signed()).as_signed()
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_gather_[u64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u64offset_u64(
    pg: svbool_t,
    base: *const u8,
    offsets: svuint64_t,
) -> svuint64_t {
    svldff1ub_gather_s64offset_u64(pg, base, offsets.as_signed())
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather_[u64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64offset_u64(
    pg: svbool_t,
    base: *const u16,
    offsets: svuint64_t,
) -> svuint64_t {
    svldff1uh_gather_s64offset_u64(pg, base, offsets.as_signed())
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_gather_[u64]offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64offset_u64(
    pg: svbool_t,
    base: *const u32,
    offsets: svuint64_t,
) -> svuint64_t {
    svldff1uw_gather_s64offset_u64(pg, base, offsets.as_signed())
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_gather[_u32base]_offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    svldff1ub_gather_u32base_offset_u32(pg, bases, offset).as_signed()
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather[_u32base]_offset_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svint32_t {
    svldff1uh_gather_u32base_offset_u32(pg, bases, offset).as_signed()
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_gather[_u32base]_offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv4i8.nxv4i32"
        )]
        fn _svldff1ub_gather_u32base_offset_u32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(
        _svldff1ub_gather_u32base_offset_u32(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather[_u32base]_offset_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv4i16.nxv4i32"
        )]
        fn _svldff1uh_gather_u32base_offset_u32(
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svldff1uh_gather_u32base_offset_u32(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_gather[_u64base]_offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    svldff1ub_gather_u64base_offset_u64(pg, bases, offset).as_signed()
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather[_u64base]_offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    svldff1uh_gather_u64base_offset_u64(pg, bases, offset).as_signed()
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_gather[_u64base]_offset_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svint64_t {
    svldff1uw_gather_u64base_offset_u64(pg, bases, offset).as_signed()
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_gather[_u64base]_offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv2i8.nxv2i64"
        )]
        fn _svldff1ub_gather_u64base_offset_u64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i8;
    }
    simd_cast::<nxv2u8, _>(
        _svldff1ub_gather_u64base_offset_u64(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather[_u64base]_offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv2i16.nxv2i64"
        )]
        fn _svldff1uh_gather_u64base_offset_u64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(
        _svldff1uh_gather_u64base_offset_u64(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_gather[_u64base]_offset_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.scalar.offset.nxv2i32.nxv2i64"
        )]
        fn _svldff1uw_gather_u64base_offset_u64(
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        ) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(
        _svldff1uw_gather_u64base_offset_u64(pg.into(), bases.as_signed(), offset).as_unsigned(),
    )
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_gather[_u32base]_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svldff1ub_gather_u32base_offset_s32(pg, bases, 0)
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather[_u32base]_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32base_s32(pg: svbool_t, bases: svuint32_t) -> svint32_t {
    svldff1uh_gather_u32base_offset_s32(pg, bases, 0)
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_gather[_u32base]_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svldff1ub_gather_u32base_offset_u32(pg, bases, 0)
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather[_u32base]_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32base_u32(pg: svbool_t, bases: svuint32_t) -> svuint32_t {
    svldff1uh_gather_u32base_offset_u32(pg, bases, 0)
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_gather[_u64base]_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svldff1ub_gather_u64base_offset_s64(pg, bases, 0)
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather[_u64base]_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svldff1uh_gather_u64base_offset_s64(pg, bases, 0)
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_gather[_u64base]_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64base_s64(pg: svbool_t, bases: svuint64_t) -> svint64_t {
    svldff1uw_gather_u64base_offset_s64(pg, bases, 0)
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_gather[_u64base]_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svldff1ub_gather_u64base_offset_u64(pg, bases, 0)
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather[_u64base]_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svldff1uh_gather_u64base_offset_u64(pg, bases, 0)
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_gather[_u64base]_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64base_u64(pg: svbool_t, bases: svuint64_t) -> svuint64_t {
    svldff1uw_gather_u64base_offset_u64(pg, bases, 0)
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_s16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_s16(pg: svbool_t, base: *const u8) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv8i8")]
        fn _svldff1ub_s16(pg: svbool8_t, base: *const i8) -> nxv8i8;
    }
    simd_cast::<nxv8u8, _>(_svldff1ub_s16(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_s32(pg: svbool_t, base: *const u8) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv4i8")]
        fn _svldff1ub_s32(pg: svbool4_t, base: *const i8) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(_svldff1ub_s32(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_s32(pg: svbool_t, base: *const u16) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv4i16")]
        fn _svldff1uh_s32(pg: svbool4_t, base: *const i16) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(_svldff1uh_s32(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_s64(pg: svbool_t, base: *const u8) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv2i8")]
        fn _svldff1ub_s64(pg: svbool2_t, base: *const i8) -> nxv2i8;
    }
    simd_cast::<nxv2u8, _>(_svldff1ub_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_s64(pg: svbool_t, base: *const u16) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv2i16")]
        fn _svldff1uh_s64(pg: svbool2_t, base: *const i16) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(_svldff1uh_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_s64(pg: svbool_t, base: *const u32) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldff1.nxv2i32")]
        fn _svldff1uw_s64(pg: svbool2_t, base: *const i32) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(_svldff1uw_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_u16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_u16(pg: svbool_t, base: *const u8) -> svuint16_t {
    svldff1ub_s16(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_u32(pg: svbool_t, base: *const u8) -> svuint32_t {
    svldff1ub_s32(pg, base).as_unsigned()
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_u32(pg: svbool_t, base: *const u16) -> svuint32_t {
    svldff1uh_s32(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_u64(pg: svbool_t, base: *const u8) -> svuint64_t {
    svldff1ub_s64(pg, base).as_unsigned()
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_u64(pg: svbool_t, base: *const u16) -> svuint64_t {
    svldff1uh_s64(pg, base).as_unsigned()
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_u64(pg: svbool_t, base: *const u32) -> svuint64_t {
    svldff1uw_s64(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_vnum_s16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_vnum_s16(pg: svbool_t, base: *const u8, vnum: i64) -> svint16_t {
    svldff1ub_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_vnum_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_vnum_s32(pg: svbool_t, base: *const u8, vnum: i64) -> svint32_t {
    svldff1ub_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_vnum_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_vnum_s32(pg: svbool_t, base: *const u16, vnum: i64) -> svint32_t {
    svldff1uh_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_vnum_s64(pg: svbool_t, base: *const u8, vnum: i64) -> svint64_t {
    svldff1ub_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_vnum_s64(pg: svbool_t, base: *const u16, vnum: i64) -> svint64_t {
    svldff1uh_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_vnum_s64(pg: svbool_t, base: *const u32, vnum: i64) -> svint64_t {
    svldff1uw_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_vnum_u16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_vnum_u16(pg: svbool_t, base: *const u8, vnum: i64) -> svuint16_t {
    svldff1ub_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_vnum_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_vnum_u32(pg: svbool_t, base: *const u8, vnum: i64) -> svuint32_t {
    svldff1ub_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_vnum_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_vnum_u32(pg: svbool_t, base: *const u16, vnum: i64) -> svuint32_t {
    svldff1uh_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1ub_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1b))]
pub unsafe fn svldff1ub_vnum_u64(pg: svbool_t, base: *const u8, vnum: i64) -> svuint64_t {
    svldff1ub_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_vnum_u64(pg: svbool_t, base: *const u16, vnum: i64) -> svuint64_t {
    svldff1uh_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_vnum_u64(pg: svbool_t, base: *const u32, vnum: i64) -> svuint64_t {
    svldff1uw_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather_[s32]index_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_s32index_s32(
    pg: svbool_t,
    base: *const u16,
    indices: svint32_t,
) -> svint32_t {
    svldff1uh_gather_s32index_u32(pg, base, indices).as_signed()
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather_[s32]index_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_s32index_u32(
    pg: svbool_t,
    base: *const u16,
    indices: svint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.sxtw.index.nxv4i16"
        )]
        fn _svldff1uh_gather_s32index_u32(
            pg: svbool4_t,
            base: *const i16,
            indices: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svldff1uh_gather_s32index_u32(pg.into(), base.as_signed(), indices).as_unsigned(),
    )
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather_[s64]index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_s64index_s64(
    pg: svbool_t,
    base: *const u16,
    indices: svint64_t,
) -> svint64_t {
    svldff1uh_gather_s64index_u64(pg, base, indices).as_signed()
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_gather_[s64]index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_s64index_s64(
    pg: svbool_t,
    base: *const u32,
    indices: svint64_t,
) -> svint64_t {
    svldff1uw_gather_s64index_u64(pg, base, indices).as_signed()
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather_[s64]index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_s64index_u64(
    pg: svbool_t,
    base: *const u16,
    indices: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.index.nxv2i16"
        )]
        fn _svldff1uh_gather_s64index_u64(
            pg: svbool2_t,
            base: *const i16,
            indices: svint64_t,
        ) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(
        _svldff1uh_gather_s64index_u64(pg.into(), base.as_signed(), indices).as_unsigned(),
    )
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_gather_[s64]index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_s64index_u64(
    pg: svbool_t,
    base: *const u32,
    indices: svint64_t,
) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.index.nxv2i32"
        )]
        fn _svldff1uw_gather_s64index_u64(
            pg: svbool2_t,
            base: *const i32,
            indices: svint64_t,
        ) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(
        _svldff1uw_gather_s64index_u64(pg.into(), base.as_signed(), indices).as_unsigned(),
    )
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather_[u32]index_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32index_s32(
    pg: svbool_t,
    base: *const u16,
    indices: svuint32_t,
) -> svint32_t {
    svldff1uh_gather_u32index_u32(pg, base, indices).as_signed()
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather_[u32]index_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32index_u32(
    pg: svbool_t,
    base: *const u16,
    indices: svuint32_t,
) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ldff1.gather.uxtw.index.nxv4i16"
        )]
        fn _svldff1uh_gather_u32index_u32(
            pg: svbool4_t,
            base: *const i16,
            indices: svint32_t,
        ) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(
        _svldff1uh_gather_u32index_u32(pg.into(), base.as_signed(), indices.as_signed())
            .as_unsigned(),
    )
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather_[u64]index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64index_s64(
    pg: svbool_t,
    base: *const u16,
    indices: svuint64_t,
) -> svint64_t {
    svldff1uh_gather_s64index_u64(pg, base, indices.as_signed()).as_signed()
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_gather_[u64]index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64index_s64(
    pg: svbool_t,
    base: *const u32,
    indices: svuint64_t,
) -> svint64_t {
    svldff1uw_gather_s64index_u64(pg, base, indices.as_signed()).as_signed()
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather_[u64]index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64index_u64(
    pg: svbool_t,
    base: *const u16,
    indices: svuint64_t,
) -> svuint64_t {
    svldff1uh_gather_s64index_u64(pg, base, indices.as_signed())
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_gather_[u64]index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64index_u64(
    pg: svbool_t,
    base: *const u32,
    indices: svuint64_t,
) -> svuint64_t {
    svldff1uw_gather_s64index_u64(pg, base, indices.as_signed())
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather[_u32base]_index_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32base_index_s32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svint32_t {
    svldff1uh_gather_u32base_offset_s32(pg, bases, index.unchecked_shl(1))
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather[_u32base]_index_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u32base_index_u32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) -> svuint32_t {
    svldff1uh_gather_u32base_offset_u32(pg, bases, index.unchecked_shl(1))
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather[_u64base]_index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svldff1uh_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(1))
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_gather[_u64base]_index_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svint64_t {
    svldff1uw_gather_u64base_offset_s64(pg, bases, index.unchecked_shl(2))
}
#[doc = "Load 16-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uh_gather[_u64base]_index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1h))]
pub unsafe fn svldff1uh_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svldff1uh_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(1))
}
#[doc = "Load 32-bit data and zero-extend, first-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldff1uw_gather[_u64base]_index_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and first-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldff1w))]
pub unsafe fn svldff1uw_gather_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) -> svuint64_t {
    svldff1uw_gather_u64base_offset_u64(pg, bases, index.unchecked_shl(2))
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1_f32(pg: svbool_t, base: *const f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv4f32")]
        fn _svldnf1_f32(pg: svbool4_t, base: *const f32) -> svfloat32_t;
    }
    _svldnf1_f32(pg.into(), base)
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1d))]
pub unsafe fn svldnf1_f64(pg: svbool_t, base: *const f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv2f64")]
        fn _svldnf1_f64(pg: svbool2_t, base: *const f64) -> svfloat64_t;
    }
    _svldnf1_f64(pg.into(), base)
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1_s8(pg: svbool_t, base: *const i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv16i8")]
        fn _svldnf1_s8(pg: svbool_t, base: *const i8) -> svint8_t;
    }
    _svldnf1_s8(pg, base)
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1_s16(pg: svbool_t, base: *const i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv8i16")]
        fn _svldnf1_s16(pg: svbool8_t, base: *const i16) -> svint16_t;
    }
    _svldnf1_s16(pg.into(), base)
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1_s32(pg: svbool_t, base: *const i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv4i32")]
        fn _svldnf1_s32(pg: svbool4_t, base: *const i32) -> svint32_t;
    }
    _svldnf1_s32(pg.into(), base)
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1d))]
pub unsafe fn svldnf1_s64(pg: svbool_t, base: *const i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv2i64")]
        fn _svldnf1_s64(pg: svbool2_t, base: *const i64) -> svint64_t;
    }
    _svldnf1_s64(pg.into(), base)
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1_u8(pg: svbool_t, base: *const u8) -> svuint8_t {
    svldnf1_s8(pg, base.as_signed()).as_unsigned()
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1_u16(pg: svbool_t, base: *const u16) -> svuint16_t {
    svldnf1_s16(pg, base.as_signed()).as_unsigned()
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1_u32(pg: svbool_t, base: *const u32) -> svuint32_t {
    svldnf1_s32(pg, base.as_signed()).as_unsigned()
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1d))]
pub unsafe fn svldnf1_u64(pg: svbool_t, base: *const u64) -> svuint64_t {
    svldnf1_s64(pg, base.as_signed()).as_unsigned()
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1_vnum[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1_vnum_f32(pg: svbool_t, base: *const f32, vnum: i64) -> svfloat32_t {
    svldnf1_f32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1_vnum[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1d))]
pub unsafe fn svldnf1_vnum_f64(pg: svbool_t, base: *const f64, vnum: i64) -> svfloat64_t {
    svldnf1_f64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1_vnum[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1_vnum_s8(pg: svbool_t, base: *const i8, vnum: i64) -> svint8_t {
    svldnf1_s8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1_vnum[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1_vnum_s16(pg: svbool_t, base: *const i16, vnum: i64) -> svint16_t {
    svldnf1_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1_vnum[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1_vnum_s32(pg: svbool_t, base: *const i32, vnum: i64) -> svint32_t {
    svldnf1_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1_vnum[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1d))]
pub unsafe fn svldnf1_vnum_s64(pg: svbool_t, base: *const i64, vnum: i64) -> svint64_t {
    svldnf1_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1_vnum[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1_vnum_u8(pg: svbool_t, base: *const u8, vnum: i64) -> svuint8_t {
    svldnf1_u8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1_vnum[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1_vnum_u16(pg: svbool_t, base: *const u16, vnum: i64) -> svuint16_t {
    svldnf1_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1_vnum[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1_vnum_u32(pg: svbool_t, base: *const u32, vnum: i64) -> svuint32_t {
    svldnf1_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Unextended load, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1_vnum[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1d))]
pub unsafe fn svldnf1_vnum_u64(pg: svbool_t, base: *const u64, vnum: i64) -> svuint64_t {
    svldnf1_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sb_s16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_s16(pg: svbool_t, base: *const i8) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv8i8")]
        fn _svldnf1sb_s16(pg: svbool8_t, base: *const i8) -> nxv8i8;
    }
    simd_cast(_svldnf1sb_s16(pg.into(), base))
}
#[doc = "Load 8-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sb_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_s32(pg: svbool_t, base: *const i8) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv4i8")]
        fn _svldnf1sb_s32(pg: svbool4_t, base: *const i8) -> nxv4i8;
    }
    simd_cast(_svldnf1sb_s32(pg.into(), base))
}
#[doc = "Load 16-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sh_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sh))]
pub unsafe fn svldnf1sh_s32(pg: svbool_t, base: *const i16) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv4i16")]
        fn _svldnf1sh_s32(pg: svbool4_t, base: *const i16) -> nxv4i16;
    }
    simd_cast(_svldnf1sh_s32(pg.into(), base))
}
#[doc = "Load 8-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sb_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_s64(pg: svbool_t, base: *const i8) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv2i8")]
        fn _svldnf1sb_s64(pg: svbool2_t, base: *const i8) -> nxv2i8;
    }
    simd_cast(_svldnf1sb_s64(pg.into(), base))
}
#[doc = "Load 16-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sh_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sh))]
pub unsafe fn svldnf1sh_s64(pg: svbool_t, base: *const i16) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv2i16")]
        fn _svldnf1sh_s64(pg: svbool2_t, base: *const i16) -> nxv2i16;
    }
    simd_cast(_svldnf1sh_s64(pg.into(), base))
}
#[doc = "Load 32-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sw_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sw))]
pub unsafe fn svldnf1sw_s64(pg: svbool_t, base: *const i32) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv2i32")]
        fn _svldnf1sw_s64(pg: svbool2_t, base: *const i32) -> nxv2i32;
    }
    simd_cast(_svldnf1sw_s64(pg.into(), base))
}
#[doc = "Load 8-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sb_u16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_u16(pg: svbool_t, base: *const i8) -> svuint16_t {
    svldnf1sb_s16(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sb_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_u32(pg: svbool_t, base: *const i8) -> svuint32_t {
    svldnf1sb_s32(pg, base).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sh_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sh))]
pub unsafe fn svldnf1sh_u32(pg: svbool_t, base: *const i16) -> svuint32_t {
    svldnf1sh_s32(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sb_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_u64(pg: svbool_t, base: *const i8) -> svuint64_t {
    svldnf1sb_s64(pg, base).as_unsigned()
}
#[doc = "Load 16-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sh_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sh))]
pub unsafe fn svldnf1sh_u64(pg: svbool_t, base: *const i16) -> svuint64_t {
    svldnf1sh_s64(pg, base).as_unsigned()
}
#[doc = "Load 32-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sw_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sw))]
pub unsafe fn svldnf1sw_u64(pg: svbool_t, base: *const i32) -> svuint64_t {
    svldnf1sw_s64(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sb_vnum_s16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_vnum_s16(pg: svbool_t, base: *const i8, vnum: i64) -> svint16_t {
    svldnf1sb_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sb_vnum_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_vnum_s32(pg: svbool_t, base: *const i8, vnum: i64) -> svint32_t {
    svldnf1sb_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sh_vnum_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sh))]
pub unsafe fn svldnf1sh_vnum_s32(pg: svbool_t, base: *const i16, vnum: i64) -> svint32_t {
    svldnf1sh_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sb_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_vnum_s64(pg: svbool_t, base: *const i8, vnum: i64) -> svint64_t {
    svldnf1sb_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sh_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sh))]
pub unsafe fn svldnf1sh_vnum_s64(pg: svbool_t, base: *const i16, vnum: i64) -> svint64_t {
    svldnf1sh_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 32-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sw_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sw))]
pub unsafe fn svldnf1sw_vnum_s64(pg: svbool_t, base: *const i32, vnum: i64) -> svint64_t {
    svldnf1sw_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sb_vnum_u16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_vnum_u16(pg: svbool_t, base: *const i8, vnum: i64) -> svuint16_t {
    svldnf1sb_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sb_vnum_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_vnum_u32(pg: svbool_t, base: *const i8, vnum: i64) -> svuint32_t {
    svldnf1sb_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sh_vnum_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sh))]
pub unsafe fn svldnf1sh_vnum_u32(pg: svbool_t, base: *const i16, vnum: i64) -> svuint32_t {
    svldnf1sh_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sb_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sb))]
pub unsafe fn svldnf1sb_vnum_u64(pg: svbool_t, base: *const i8, vnum: i64) -> svuint64_t {
    svldnf1sb_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sh_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sh))]
pub unsafe fn svldnf1sh_vnum_u64(pg: svbool_t, base: *const i16, vnum: i64) -> svuint64_t {
    svldnf1sh_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 32-bit data and sign-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1sw_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1sw))]
pub unsafe fn svldnf1sw_vnum_u64(pg: svbool_t, base: *const i32, vnum: i64) -> svuint64_t {
    svldnf1sw_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1ub_s16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_s16(pg: svbool_t, base: *const u8) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv8i8")]
        fn _svldnf1ub_s16(pg: svbool8_t, base: *const i8) -> nxv8i8;
    }
    simd_cast::<nxv8u8, _>(_svldnf1ub_s16(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 8-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1ub_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_s32(pg: svbool_t, base: *const u8) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv4i8")]
        fn _svldnf1ub_s32(pg: svbool4_t, base: *const i8) -> nxv4i8;
    }
    simd_cast::<nxv4u8, _>(_svldnf1ub_s32(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 16-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1uh_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1uh_s32(pg: svbool_t, base: *const u16) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv4i16")]
        fn _svldnf1uh_s32(pg: svbool4_t, base: *const i16) -> nxv4i16;
    }
    simd_cast::<nxv4u16, _>(_svldnf1uh_s32(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 8-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1ub_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_s64(pg: svbool_t, base: *const u8) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv2i8")]
        fn _svldnf1ub_s64(pg: svbool2_t, base: *const i8) -> nxv2i8;
    }
    simd_cast::<nxv2u8, _>(_svldnf1ub_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 16-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1uh_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1uh_s64(pg: svbool_t, base: *const u16) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv2i16")]
        fn _svldnf1uh_s64(pg: svbool2_t, base: *const i16) -> nxv2i16;
    }
    simd_cast::<nxv2u16, _>(_svldnf1uh_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 32-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1uw_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1uw_s64(pg: svbool_t, base: *const u32) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnf1.nxv2i32")]
        fn _svldnf1uw_s64(pg: svbool2_t, base: *const i32) -> nxv2i32;
    }
    simd_cast::<nxv2u32, _>(_svldnf1uw_s64(pg.into(), base.as_signed()).as_unsigned())
}
#[doc = "Load 8-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1ub_u16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_u16(pg: svbool_t, base: *const u8) -> svuint16_t {
    svldnf1ub_s16(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1ub_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_u32(pg: svbool_t, base: *const u8) -> svuint32_t {
    svldnf1ub_s32(pg, base).as_unsigned()
}
#[doc = "Load 16-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1uh_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1uh_u32(pg: svbool_t, base: *const u16) -> svuint32_t {
    svldnf1uh_s32(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1ub_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_u64(pg: svbool_t, base: *const u8) -> svuint64_t {
    svldnf1ub_s64(pg, base).as_unsigned()
}
#[doc = "Load 16-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1uh_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1uh_u64(pg: svbool_t, base: *const u16) -> svuint64_t {
    svldnf1uh_s64(pg, base).as_unsigned()
}
#[doc = "Load 32-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1uw_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1uw_u64(pg: svbool_t, base: *const u32) -> svuint64_t {
    svldnf1uw_s64(pg, base).as_unsigned()
}
#[doc = "Load 8-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1ub_vnum_s16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_vnum_s16(pg: svbool_t, base: *const u8, vnum: i64) -> svint16_t {
    svldnf1ub_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1ub_vnum_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_vnum_s32(pg: svbool_t, base: *const u8, vnum: i64) -> svint32_t {
    svldnf1ub_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1uh_vnum_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1uh_vnum_s32(pg: svbool_t, base: *const u16, vnum: i64) -> svint32_t {
    svldnf1uh_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1ub_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_vnum_s64(pg: svbool_t, base: *const u8, vnum: i64) -> svint64_t {
    svldnf1ub_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1uh_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1uh_vnum_s64(pg: svbool_t, base: *const u16, vnum: i64) -> svint64_t {
    svldnf1uh_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 32-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1uw_vnum_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1uw_vnum_s64(pg: svbool_t, base: *const u32, vnum: i64) -> svint64_t {
    svldnf1uw_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1ub_vnum_u16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_vnum_u16(pg: svbool_t, base: *const u8, vnum: i64) -> svuint16_t {
    svldnf1ub_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1ub_vnum_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_vnum_u32(pg: svbool_t, base: *const u8, vnum: i64) -> svuint32_t {
    svldnf1ub_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1uh_vnum_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1uh_vnum_u32(pg: svbool_t, base: *const u16, vnum: i64) -> svuint32_t {
    svldnf1uh_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Load 8-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1ub_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1b))]
pub unsafe fn svldnf1ub_vnum_u64(pg: svbool_t, base: *const u8, vnum: i64) -> svuint64_t {
    svldnf1ub_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 16-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1uh_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1h))]
pub unsafe fn svldnf1uh_vnum_u64(pg: svbool_t, base: *const u16, vnum: i64) -> svuint64_t {
    svldnf1uh_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Load 32-bit data and zero-extend, non-faulting"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnf1uw_vnum_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`, the first-fault register (`FFR`) and non-faulting behaviour)."]
#[doc = "  * Result lanes corresponding to inactive FFR lanes (either before or as a result of this intrinsic) have \"CONSTRAINED UNPREDICTABLE\" values, irrespective of predication. Refer to architectural documentation for details."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnf1w))]
pub unsafe fn svldnf1uw_vnum_u64(pg: svbool_t, base: *const u32, vnum: i64) -> svuint64_t {
    svldnf1uw_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1w))]
pub unsafe fn svldnt1_f32(pg: svbool_t, base: *const f32) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnt1.nxv4f32")]
        fn _svldnt1_f32(pg: svbool4_t, base: *const f32) -> svfloat32_t;
    }
    _svldnt1_f32(pg.into(), base)
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1d))]
pub unsafe fn svldnt1_f64(pg: svbool_t, base: *const f64) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnt1.nxv2f64")]
        fn _svldnt1_f64(pg: svbool2_t, base: *const f64) -> svfloat64_t;
    }
    _svldnt1_f64(pg.into(), base)
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1b))]
pub unsafe fn svldnt1_s8(pg: svbool_t, base: *const i8) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnt1.nxv16i8")]
        fn _svldnt1_s8(pg: svbool_t, base: *const i8) -> svint8_t;
    }
    _svldnt1_s8(pg, base)
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1h))]
pub unsafe fn svldnt1_s16(pg: svbool_t, base: *const i16) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnt1.nxv8i16")]
        fn _svldnt1_s16(pg: svbool8_t, base: *const i16) -> svint16_t;
    }
    _svldnt1_s16(pg.into(), base)
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1w))]
pub unsafe fn svldnt1_s32(pg: svbool_t, base: *const i32) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnt1.nxv4i32")]
        fn _svldnt1_s32(pg: svbool4_t, base: *const i32) -> svint32_t;
    }
    _svldnt1_s32(pg.into(), base)
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1d))]
pub unsafe fn svldnt1_s64(pg: svbool_t, base: *const i64) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ldnt1.nxv2i64")]
        fn _svldnt1_s64(pg: svbool2_t, base: *const i64) -> svint64_t;
    }
    _svldnt1_s64(pg.into(), base)
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1b))]
pub unsafe fn svldnt1_u8(pg: svbool_t, base: *const u8) -> svuint8_t {
    svldnt1_s8(pg, base.as_signed()).as_unsigned()
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1h))]
pub unsafe fn svldnt1_u16(pg: svbool_t, base: *const u16) -> svuint16_t {
    svldnt1_s16(pg, base.as_signed()).as_unsigned()
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1w))]
pub unsafe fn svldnt1_u32(pg: svbool_t, base: *const u32) -> svuint32_t {
    svldnt1_s32(pg, base.as_signed()).as_unsigned()
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1d))]
pub unsafe fn svldnt1_u64(pg: svbool_t, base: *const u64) -> svuint64_t {
    svldnt1_s64(pg, base.as_signed()).as_unsigned()
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1_vnum[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1w))]
pub unsafe fn svldnt1_vnum_f32(pg: svbool_t, base: *const f32, vnum: i64) -> svfloat32_t {
    svldnt1_f32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1_vnum[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1d))]
pub unsafe fn svldnt1_vnum_f64(pg: svbool_t, base: *const f64, vnum: i64) -> svfloat64_t {
    svldnt1_f64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1_vnum[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1b))]
pub unsafe fn svldnt1_vnum_s8(pg: svbool_t, base: *const i8, vnum: i64) -> svint8_t {
    svldnt1_s8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1_vnum[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1h))]
pub unsafe fn svldnt1_vnum_s16(pg: svbool_t, base: *const i16, vnum: i64) -> svint16_t {
    svldnt1_s16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1_vnum[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1w))]
pub unsafe fn svldnt1_vnum_s32(pg: svbool_t, base: *const i32, vnum: i64) -> svint32_t {
    svldnt1_s32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1_vnum[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1d))]
pub unsafe fn svldnt1_vnum_s64(pg: svbool_t, base: *const i64, vnum: i64) -> svint64_t {
    svldnt1_s64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1_vnum[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1b))]
pub unsafe fn svldnt1_vnum_u8(pg: svbool_t, base: *const u8, vnum: i64) -> svuint8_t {
    svldnt1_u8(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1_vnum[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1h))]
pub unsafe fn svldnt1_vnum_u16(pg: svbool_t, base: *const u16, vnum: i64) -> svuint16_t {
    svldnt1_u16(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1_vnum[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1w))]
pub unsafe fn svldnt1_vnum_u32(pg: svbool_t, base: *const u32, vnum: i64) -> svuint32_t {
    svldnt1_u32(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Unextended load, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svldnt1_vnum[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ldnt1d))]
pub unsafe fn svldnt1_vnum_u64(pg: svbool_t, base: *const u64, vnum: i64) -> svuint64_t {
    svldnt1_u64(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Count the number of elements in a full vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlen[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntw))]
pub fn svlen_f32(_op: svfloat32_t) -> u64 {
    svcntw()
}
#[doc = "Count the number of elements in a full vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlen[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntd))]
pub fn svlen_f64(_op: svfloat64_t) -> u64 {
    svcntd()
}
#[doc = "Count the number of elements in a full vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlen[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rdvl))]
pub fn svlen_s8(_op: svint8_t) -> u64 {
    svcntb()
}
#[doc = "Count the number of elements in a full vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlen[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnth))]
pub fn svlen_s16(_op: svint16_t) -> u64 {
    svcnth()
}
#[doc = "Count the number of elements in a full vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlen[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntw))]
pub fn svlen_s32(_op: svint32_t) -> u64 {
    svcntw()
}
#[doc = "Count the number of elements in a full vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlen[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntd))]
pub fn svlen_s64(_op: svint64_t) -> u64 {
    svcntd()
}
#[doc = "Count the number of elements in a full vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlen[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rdvl))]
pub fn svlen_u8(_op: svuint8_t) -> u64 {
    svcntb()
}
#[doc = "Count the number of elements in a full vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlen[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cnth))]
pub fn svlen_u16(_op: svuint16_t) -> u64 {
    svcnth()
}
#[doc = "Count the number of elements in a full vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlen[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntw))]
pub fn svlen_u32(_op: svuint32_t) -> u64 {
    svcntw()
}
#[doc = "Count the number of elements in a full vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlen[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(cntd))]
pub fn svlen_u64(_op: svuint64_t) -> u64 {
    svcntd()
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_s8_m(pg: svbool_t, op1: svint8_t, op2: svuint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lsl.nxv16i8")]
        fn _svlsl_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svlsl_s8_m(pg, op1, op2.as_signed()) }
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_s8_m(pg: svbool_t, op1: svint8_t, op2: u8) -> svint8_t {
    svlsl_s8_m(pg, op1, svdup_n_u8(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_s8_x(pg: svbool_t, op1: svint8_t, op2: svuint8_t) -> svint8_t {
    svlsl_s8_m(pg, op1, op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_s8_x(pg: svbool_t, op1: svint8_t, op2: u8) -> svint8_t {
    svlsl_s8_x(pg, op1, svdup_n_u8(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_s8_z(pg: svbool_t, op1: svint8_t, op2: svuint8_t) -> svint8_t {
    svlsl_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_s8_z(pg: svbool_t, op1: svint8_t, op2: u8) -> svint8_t {
    svlsl_s8_z(pg, op1, svdup_n_u8(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_s16_m(pg: svbool_t, op1: svint16_t, op2: svuint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lsl.nxv8i16")]
        fn _svlsl_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svlsl_s16_m(pg.into(), op1, op2.as_signed()) }
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_s16_m(pg: svbool_t, op1: svint16_t, op2: u16) -> svint16_t {
    svlsl_s16_m(pg, op1, svdup_n_u16(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_s16_x(pg: svbool_t, op1: svint16_t, op2: svuint16_t) -> svint16_t {
    svlsl_s16_m(pg, op1, op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_s16_x(pg: svbool_t, op1: svint16_t, op2: u16) -> svint16_t {
    svlsl_s16_x(pg, op1, svdup_n_u16(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_s16_z(pg: svbool_t, op1: svint16_t, op2: svuint16_t) -> svint16_t {
    svlsl_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_s16_z(pg: svbool_t, op1: svint16_t, op2: u16) -> svint16_t {
    svlsl_s16_z(pg, op1, svdup_n_u16(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_s32_m(pg: svbool_t, op1: svint32_t, op2: svuint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lsl.nxv4i32")]
        fn _svlsl_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svlsl_s32_m(pg.into(), op1, op2.as_signed()) }
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_s32_m(pg: svbool_t, op1: svint32_t, op2: u32) -> svint32_t {
    svlsl_s32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_s32_x(pg: svbool_t, op1: svint32_t, op2: svuint32_t) -> svint32_t {
    svlsl_s32_m(pg, op1, op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_s32_x(pg: svbool_t, op1: svint32_t, op2: u32) -> svint32_t {
    svlsl_s32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_s32_z(pg: svbool_t, op1: svint32_t, op2: svuint32_t) -> svint32_t {
    svlsl_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_s32_z(pg: svbool_t, op1: svint32_t, op2: u32) -> svint32_t {
    svlsl_s32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_s64_m(pg: svbool_t, op1: svint64_t, op2: svuint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lsl.nxv2i64")]
        fn _svlsl_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svlsl_s64_m(pg.into(), op1, op2.as_signed()) }
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_s64_m(pg: svbool_t, op1: svint64_t, op2: u64) -> svint64_t {
    svlsl_s64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_s64_x(pg: svbool_t, op1: svint64_t, op2: svuint64_t) -> svint64_t {
    svlsl_s64_m(pg, op1, op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_s64_x(pg: svbool_t, op1: svint64_t, op2: u64) -> svint64_t {
    svlsl_s64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_s64_z(pg: svbool_t, op1: svint64_t, op2: svuint64_t) -> svint64_t {
    svlsl_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_s64_z(pg: svbool_t, op1: svint64_t, op2: u64) -> svint64_t {
    svlsl_s64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svlsl_s8_m(pg, op1.as_signed(), op2).as_unsigned() }
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svlsl_u8_m(pg, op1, svdup_n_u8(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svlsl_u8_m(pg, op1, op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svlsl_u8_x(pg, op1, svdup_n_u8(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svlsl_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svlsl_u8_z(pg, op1, svdup_n_u8(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svlsl_s16_m(pg, op1.as_signed(), op2).as_unsigned() }
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svlsl_u16_m(pg, op1, svdup_n_u16(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svlsl_u16_m(pg, op1, op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svlsl_u16_x(pg, op1, svdup_n_u16(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svlsl_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svlsl_u16_z(pg, op1, svdup_n_u16(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svlsl_s32_m(pg, op1.as_signed(), op2).as_unsigned() }
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svlsl_u32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svlsl_u32_m(pg, op1, op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svlsl_u32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svlsl_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svlsl_u32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svlsl_s64_m(pg, op1.as_signed(), op2).as_unsigned() }
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svlsl_u64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svlsl_u64_m(pg, op1, op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svlsl_u64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svlsl_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svlsl_u64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_s8_m(pg: svbool_t, op1: svint8_t, op2: svuint64_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.lsl.wide.nxv16i8"
        )]
        fn _svlsl_wide_s8_m(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svint8_t;
    }
    unsafe { _svlsl_wide_s8_m(pg, op1, op2.as_signed()) }
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_s8_m(pg: svbool_t, op1: svint8_t, op2: u64) -> svint8_t {
    svlsl_wide_s8_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_s8_x(pg: svbool_t, op1: svint8_t, op2: svuint64_t) -> svint8_t {
    svlsl_wide_s8_m(pg, op1, op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_s8_x(pg: svbool_t, op1: svint8_t, op2: u64) -> svint8_t {
    svlsl_wide_s8_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_s8_z(pg: svbool_t, op1: svint8_t, op2: svuint64_t) -> svint8_t {
    svlsl_wide_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_s8_z(pg: svbool_t, op1: svint8_t, op2: u64) -> svint8_t {
    svlsl_wide_s8_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_s16_m(pg: svbool_t, op1: svint16_t, op2: svuint64_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.lsl.wide.nxv8i16"
        )]
        fn _svlsl_wide_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svint16_t;
    }
    unsafe { _svlsl_wide_s16_m(pg.into(), op1, op2.as_signed()) }
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_s16_m(pg: svbool_t, op1: svint16_t, op2: u64) -> svint16_t {
    svlsl_wide_s16_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_s16_x(pg: svbool_t, op1: svint16_t, op2: svuint64_t) -> svint16_t {
    svlsl_wide_s16_m(pg, op1, op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_s16_x(pg: svbool_t, op1: svint16_t, op2: u64) -> svint16_t {
    svlsl_wide_s16_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_s16_z(pg: svbool_t, op1: svint16_t, op2: svuint64_t) -> svint16_t {
    svlsl_wide_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_s16_z(pg: svbool_t, op1: svint16_t, op2: u64) -> svint16_t {
    svlsl_wide_s16_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_s32_m(pg: svbool_t, op1: svint32_t, op2: svuint64_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.lsl.wide.nxv4i32"
        )]
        fn _svlsl_wide_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svint32_t;
    }
    unsafe { _svlsl_wide_s32_m(pg.into(), op1, op2.as_signed()) }
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_s32_m(pg: svbool_t, op1: svint32_t, op2: u64) -> svint32_t {
    svlsl_wide_s32_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_s32_x(pg: svbool_t, op1: svint32_t, op2: svuint64_t) -> svint32_t {
    svlsl_wide_s32_m(pg, op1, op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_s32_x(pg: svbool_t, op1: svint32_t, op2: u64) -> svint32_t {
    svlsl_wide_s32_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_s32_z(pg: svbool_t, op1: svint32_t, op2: svuint64_t) -> svint32_t {
    svlsl_wide_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_s32_z(pg: svbool_t, op1: svint32_t, op2: u64) -> svint32_t {
    svlsl_wide_s32_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svuint8_t {
    unsafe { svlsl_wide_s8_m(pg, op1.as_signed(), op2).as_unsigned() }
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u64) -> svuint8_t {
    svlsl_wide_u8_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svuint8_t {
    svlsl_wide_u8_m(pg, op1, op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u64) -> svuint8_t {
    svlsl_wide_u8_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svuint8_t {
    svlsl_wide_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u64) -> svuint8_t {
    svlsl_wide_u8_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svuint16_t {
    unsafe { svlsl_wide_s16_m(pg, op1.as_signed(), op2).as_unsigned() }
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u64) -> svuint16_t {
    svlsl_wide_u16_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svuint16_t {
    svlsl_wide_u16_m(pg, op1, op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u64) -> svuint16_t {
    svlsl_wide_u16_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svuint16_t {
    svlsl_wide_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u64) -> svuint16_t {
    svlsl_wide_u16_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svuint32_t {
    unsafe { svlsl_wide_s32_m(pg, op1.as_signed(), op2).as_unsigned() }
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u64) -> svuint32_t {
    svlsl_wide_u32_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svuint32_t {
    svlsl_wide_u32_m(pg, op1, op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u64) -> svuint32_t {
    svlsl_wide_u32_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svuint32_t {
    svlsl_wide_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Logical shift left"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsl_wide[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsl))]
pub fn svlsl_wide_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u64) -> svuint32_t {
    svlsl_wide_u32_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lsr.nxv16i8")]
        fn _svlsr_u8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svlsr_u8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svlsr_u8_m(pg, op1, svdup_n_u8(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svlsr_u8_m(pg, op1, op2)
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svlsr_u8_x(pg, op1, svdup_n_u8(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svlsr_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svlsr_u8_z(pg, op1, svdup_n_u8(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lsr.nxv8i16")]
        fn _svlsr_u16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svlsr_u16_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svlsr_u16_m(pg, op1, svdup_n_u16(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svlsr_u16_m(pg, op1, op2)
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svlsr_u16_x(pg, op1, svdup_n_u16(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svlsr_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svlsr_u16_z(pg, op1, svdup_n_u16(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lsr.nxv4i32")]
        fn _svlsr_u32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svlsr_u32_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svlsr_u32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svlsr_u32_m(pg, op1, op2)
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svlsr_u32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svlsr_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svlsr_u32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.lsr.nxv2i64")]
        fn _svlsr_u64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svlsr_u64_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svlsr_u64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svlsr_u64_m(pg, op1, op2)
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svlsr_u64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svlsr_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svlsr_u64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.lsr.wide.nxv16i8"
        )]
        fn _svlsr_wide_u8_m(pg: svbool_t, op1: svint8_t, op2: svint64_t) -> svint8_t;
    }
    unsafe { _svlsr_wide_u8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u64) -> svuint8_t {
    svlsr_wide_u8_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svuint8_t {
    svlsr_wide_u8_m(pg, op1, op2)
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u64) -> svuint8_t {
    svlsr_wide_u8_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint64_t) -> svuint8_t {
    svlsr_wide_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u64) -> svuint8_t {
    svlsr_wide_u8_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.lsr.wide.nxv8i16"
        )]
        fn _svlsr_wide_u16_m(pg: svbool8_t, op1: svint16_t, op2: svint64_t) -> svint16_t;
    }
    unsafe { _svlsr_wide_u16_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u64) -> svuint16_t {
    svlsr_wide_u16_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svuint16_t {
    svlsr_wide_u16_m(pg, op1, op2)
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u64) -> svuint16_t {
    svlsr_wide_u16_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint64_t) -> svuint16_t {
    svlsr_wide_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u64) -> svuint16_t {
    svlsr_wide_u16_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.lsr.wide.nxv4i32"
        )]
        fn _svlsr_wide_u32_m(pg: svbool4_t, op1: svint32_t, op2: svint64_t) -> svint32_t;
    }
    unsafe { _svlsr_wide_u32_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u64) -> svuint32_t {
    svlsr_wide_u32_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svuint32_t {
    svlsr_wide_u32_m(pg, op1, op2)
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u64) -> svuint32_t {
    svlsr_wide_u32_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint64_t) -> svuint32_t {
    svlsr_wide_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Logical shift right"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svlsr_wide[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(lsr))]
pub fn svlsr_wide_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u64) -> svuint32_t {
    svlsr_wide_u32_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub fn svmad_f32_m(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmad.nxv4f32")]
        fn _svmad_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
        ) -> svfloat32_t;
    }
    unsafe { _svmad_f32_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub fn svmad_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmad_f32_m(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub fn svmad_f32_x(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svmad_f32_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub fn svmad_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmad_f32_x(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub fn svmad_f32_z(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svmad_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub fn svmad_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmad_f32_z(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub fn svmad_f64_m(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmad.nxv2f64")]
        fn _svmad_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
        ) -> svfloat64_t;
    }
    unsafe { _svmad_f64_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub fn svmad_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmad_f64_m(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub fn svmad_f64_x(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svmad_f64_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub fn svmad_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmad_f64_x(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub fn svmad_f64_z(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svmad_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmad))]
pub fn svmad_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmad_f64_z(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mad.nxv16i8")]
        fn _svmad_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t;
    }
    unsafe { _svmad_s8_m(pg, op1, op2, op3) }
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmad_s8_m(pg, op1, op2, svdup_n_s8(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    svmad_s8_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmad_s8_x(pg, op1, op2, svdup_n_s8(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    svmad_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmad_s8_z(pg, op1, op2, svdup_n_s8(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mad.nxv8i16")]
        fn _svmad_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t, op3: svint16_t)
            -> svint16_t;
    }
    unsafe { _svmad_s16_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmad_s16_m(pg, op1, op2, svdup_n_s16(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    svmad_s16_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmad_s16_x(pg, op1, op2, svdup_n_s16(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    svmad_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmad_s16_z(pg, op1, op2, svdup_n_s16(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mad.nxv4i32")]
        fn _svmad_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t, op3: svint32_t)
            -> svint32_t;
    }
    unsafe { _svmad_s32_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmad_s32_m(pg, op1, op2, svdup_n_s32(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    svmad_s32_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmad_s32_x(pg, op1, op2, svdup_n_s32(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    svmad_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmad_s32_z(pg, op1, op2, svdup_n_s32(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mad.nxv2i64")]
        fn _svmad_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t, op3: svint64_t)
            -> svint64_t;
    }
    unsafe { _svmad_s64_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmad_s64_m(pg, op1, op2, svdup_n_s64(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    svmad_s64_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmad_s64_x(pg, op1, op2, svdup_n_s64(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    svmad_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmad_s64_z(pg, op1, op2, svdup_n_s64(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    unsafe { svmad_s8_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmad_u8_m(pg, op1, op2, svdup_n_u8(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    svmad_u8_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmad_u8_x(pg, op1, op2, svdup_n_u8(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    svmad_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmad_u8_z(pg, op1, op2, svdup_n_u8(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    unsafe { svmad_s16_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmad_u16_m(pg, op1, op2, svdup_n_u16(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    svmad_u16_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmad_u16_x(pg, op1, op2, svdup_n_u16(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    svmad_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmad_u16_z(pg, op1, op2, svdup_n_u16(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    unsafe { svmad_s32_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmad_u32_m(pg, op1, op2, svdup_n_u32(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    svmad_u32_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmad_u32_x(pg, op1, op2, svdup_n_u32(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    svmad_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmad_u32_z(pg, op1, op2, svdup_n_u32(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    unsafe { svmad_s64_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmad_u64_m(pg, op1, op2, svdup_n_u64(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    svmad_u64_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmad_u64_x(pg, op1, op2, svdup_n_u64(op3))
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    svmad_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2, op3)
}
#[doc = "Multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmad[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mad))]
pub fn svmad_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmad_u64_z(pg, op1, op2, svdup_n_u64(op3))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub fn svmax_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmax.nxv4f32")]
        fn _svmax_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svmax_f32_m(pg.into(), op1, op2) }
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub fn svmax_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmax_f32_m(pg, op1, svdup_n_f32(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub fn svmax_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmax_f32_m(pg, op1, op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub fn svmax_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmax_f32_x(pg, op1, svdup_n_f32(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub fn svmax_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmax_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub fn svmax_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmax_f32_z(pg, op1, svdup_n_f32(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub fn svmax_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmax.nxv2f64")]
        fn _svmax_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svmax_f64_m(pg.into(), op1, op2) }
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub fn svmax_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmax_f64_m(pg, op1, svdup_n_f64(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub fn svmax_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmax_f64_m(pg, op1, op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub fn svmax_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmax_f64_x(pg, op1, svdup_n_f64(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub fn svmax_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmax_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmax))]
pub fn svmax_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmax_f64_z(pg, op1, svdup_n_f64(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smax.nxv16i8")]
        fn _svmax_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svmax_s8_m(pg, op1, op2) }
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmax_s8_m(pg, op1, svdup_n_s8(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svmax_s8_m(pg, op1, op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmax_s8_x(pg, op1, svdup_n_s8(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svmax_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmax_s8_z(pg, op1, svdup_n_s8(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smax.nxv8i16")]
        fn _svmax_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svmax_s16_m(pg.into(), op1, op2) }
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmax_s16_m(pg, op1, svdup_n_s16(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svmax_s16_m(pg, op1, op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmax_s16_x(pg, op1, svdup_n_s16(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svmax_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmax_s16_z(pg, op1, svdup_n_s16(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smax.nxv4i32")]
        fn _svmax_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svmax_s32_m(pg.into(), op1, op2) }
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmax_s32_m(pg, op1, svdup_n_s32(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svmax_s32_m(pg, op1, op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmax_s32_x(pg, op1, svdup_n_s32(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svmax_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmax_s32_z(pg, op1, svdup_n_s32(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smax.nxv2i64")]
        fn _svmax_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svmax_s64_m(pg.into(), op1, op2) }
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmax_s64_m(pg, op1, svdup_n_s64(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svmax_s64_m(pg, op1, op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmax_s64_x(pg, op1, svdup_n_s64(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svmax_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smax))]
pub fn svmax_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmax_s64_z(pg, op1, svdup_n_s64(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umax.nxv16i8")]
        fn _svmax_u8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svmax_u8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmax_u8_m(pg, op1, svdup_n_u8(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svmax_u8_m(pg, op1, op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmax_u8_x(pg, op1, svdup_n_u8(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svmax_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmax_u8_z(pg, op1, svdup_n_u8(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umax.nxv8i16")]
        fn _svmax_u16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svmax_u16_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmax_u16_m(pg, op1, svdup_n_u16(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svmax_u16_m(pg, op1, op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmax_u16_x(pg, op1, svdup_n_u16(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svmax_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmax_u16_z(pg, op1, svdup_n_u16(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umax.nxv4i32")]
        fn _svmax_u32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svmax_u32_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmax_u32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svmax_u32_m(pg, op1, op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmax_u32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svmax_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmax_u32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umax.nxv2i64")]
        fn _svmax_u64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svmax_u64_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmax_u64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svmax_u64_m(pg, op1, op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmax_u64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svmax_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[doc = "Maximum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmax[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umax))]
pub fn svmax_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmax_u64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Maximum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxnm[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub fn svmaxnm_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmaxnm.nxv4f32")]
        fn _svmaxnm_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svmaxnm_f32_m(pg.into(), op1, op2) }
}
#[doc = "Maximum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxnm[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub fn svmaxnm_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmaxnm_f32_m(pg, op1, svdup_n_f32(op2))
}
#[doc = "Maximum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxnm[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub fn svmaxnm_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmaxnm_f32_m(pg, op1, op2)
}
#[doc = "Maximum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxnm[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub fn svmaxnm_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmaxnm_f32_x(pg, op1, svdup_n_f32(op2))
}
#[doc = "Maximum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxnm[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub fn svmaxnm_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmaxnm_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[doc = "Maximum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxnm[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub fn svmaxnm_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmaxnm_f32_z(pg, op1, svdup_n_f32(op2))
}
#[doc = "Maximum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxnm[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub fn svmaxnm_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmaxnm.nxv2f64")]
        fn _svmaxnm_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svmaxnm_f64_m(pg.into(), op1, op2) }
}
#[doc = "Maximum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxnm[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub fn svmaxnm_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmaxnm_f64_m(pg, op1, svdup_n_f64(op2))
}
#[doc = "Maximum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxnm[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub fn svmaxnm_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmaxnm_f64_m(pg, op1, op2)
}
#[doc = "Maximum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxnm[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub fn svmaxnm_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmaxnm_f64_x(pg, op1, svdup_n_f64(op2))
}
#[doc = "Maximum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxnm[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub fn svmaxnm_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmaxnm_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[doc = "Maximum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxnm[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnm))]
pub fn svmaxnm_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmaxnm_f64_z(pg, op1, svdup_n_f64(op2))
}
#[doc = "Maximum number reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxnmv[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnmv))]
pub fn svmaxnmv_f32(pg: svbool_t, op: svfloat32_t) -> f32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fmaxnmv.nxv4f32"
        )]
        fn _svmaxnmv_f32(pg: svbool4_t, op: svfloat32_t) -> f32;
    }
    unsafe { _svmaxnmv_f32(pg.into(), op) }
}
#[doc = "Maximum number reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxnmv[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxnmv))]
pub fn svmaxnmv_f64(pg: svbool_t, op: svfloat64_t) -> f64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fmaxnmv.nxv2f64"
        )]
        fn _svmaxnmv_f64(pg: svbool2_t, op: svfloat64_t) -> f64;
    }
    unsafe { _svmaxnmv_f64(pg.into(), op) }
}
#[doc = "Maximum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxv[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxv))]
pub fn svmaxv_f32(pg: svbool_t, op: svfloat32_t) -> f32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmaxv.nxv4f32")]
        fn _svmaxv_f32(pg: svbool4_t, op: svfloat32_t) -> f32;
    }
    unsafe { _svmaxv_f32(pg.into(), op) }
}
#[doc = "Maximum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxv[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmaxv))]
pub fn svmaxv_f64(pg: svbool_t, op: svfloat64_t) -> f64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmaxv.nxv2f64")]
        fn _svmaxv_f64(pg: svbool2_t, op: svfloat64_t) -> f64;
    }
    unsafe { _svmaxv_f64(pg.into(), op) }
}
#[doc = "Maximum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxv[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smaxv))]
pub fn svmaxv_s8(pg: svbool_t, op: svint8_t) -> i8 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smaxv.nxv16i8")]
        fn _svmaxv_s8(pg: svbool_t, op: svint8_t) -> i8;
    }
    unsafe { _svmaxv_s8(pg, op) }
}
#[doc = "Maximum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxv[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smaxv))]
pub fn svmaxv_s16(pg: svbool_t, op: svint16_t) -> i16 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smaxv.nxv8i16")]
        fn _svmaxv_s16(pg: svbool8_t, op: svint16_t) -> i16;
    }
    unsafe { _svmaxv_s16(pg.into(), op) }
}
#[doc = "Maximum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxv[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smaxv))]
pub fn svmaxv_s32(pg: svbool_t, op: svint32_t) -> i32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smaxv.nxv4i32")]
        fn _svmaxv_s32(pg: svbool4_t, op: svint32_t) -> i32;
    }
    unsafe { _svmaxv_s32(pg.into(), op) }
}
#[doc = "Maximum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxv[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smaxv))]
pub fn svmaxv_s64(pg: svbool_t, op: svint64_t) -> i64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smaxv.nxv2i64")]
        fn _svmaxv_s64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _svmaxv_s64(pg.into(), op) }
}
#[doc = "Maximum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxv[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umaxv))]
pub fn svmaxv_u8(pg: svbool_t, op: svuint8_t) -> u8 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umaxv.nxv16i8")]
        fn _svmaxv_u8(pg: svbool_t, op: svint8_t) -> i8;
    }
    unsafe { _svmaxv_u8(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Maximum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxv[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umaxv))]
pub fn svmaxv_u16(pg: svbool_t, op: svuint16_t) -> u16 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umaxv.nxv8i16")]
        fn _svmaxv_u16(pg: svbool8_t, op: svint16_t) -> i16;
    }
    unsafe { _svmaxv_u16(pg.into(), op.as_signed()).as_unsigned() }
}
#[doc = "Maximum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxv[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umaxv))]
pub fn svmaxv_u32(pg: svbool_t, op: svuint32_t) -> u32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umaxv.nxv4i32")]
        fn _svmaxv_u32(pg: svbool4_t, op: svint32_t) -> i32;
    }
    unsafe { _svmaxv_u32(pg.into(), op.as_signed()).as_unsigned() }
}
#[doc = "Maximum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmaxv[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umaxv))]
pub fn svmaxv_u64(pg: svbool_t, op: svuint64_t) -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umaxv.nxv2i64")]
        fn _svmaxv_u64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _svmaxv_u64(pg.into(), op.as_signed()).as_unsigned() }
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub fn svmin_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmin.nxv4f32")]
        fn _svmin_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svmin_f32_m(pg.into(), op1, op2) }
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub fn svmin_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmin_f32_m(pg, op1, svdup_n_f32(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub fn svmin_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmin_f32_m(pg, op1, op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub fn svmin_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmin_f32_x(pg, op1, svdup_n_f32(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub fn svmin_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmin_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub fn svmin_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmin_f32_z(pg, op1, svdup_n_f32(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub fn svmin_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmin.nxv2f64")]
        fn _svmin_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svmin_f64_m(pg.into(), op1, op2) }
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub fn svmin_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmin_f64_m(pg, op1, svdup_n_f64(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub fn svmin_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmin_f64_m(pg, op1, op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub fn svmin_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmin_f64_x(pg, op1, svdup_n_f64(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub fn svmin_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmin_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmin))]
pub fn svmin_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmin_f64_z(pg, op1, svdup_n_f64(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smin.nxv16i8")]
        fn _svmin_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svmin_s8_m(pg, op1, op2) }
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmin_s8_m(pg, op1, svdup_n_s8(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svmin_s8_m(pg, op1, op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmin_s8_x(pg, op1, svdup_n_s8(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svmin_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmin_s8_z(pg, op1, svdup_n_s8(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smin.nxv8i16")]
        fn _svmin_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svmin_s16_m(pg.into(), op1, op2) }
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmin_s16_m(pg, op1, svdup_n_s16(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svmin_s16_m(pg, op1, op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmin_s16_x(pg, op1, svdup_n_s16(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svmin_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmin_s16_z(pg, op1, svdup_n_s16(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smin.nxv4i32")]
        fn _svmin_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svmin_s32_m(pg.into(), op1, op2) }
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmin_s32_m(pg, op1, svdup_n_s32(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svmin_s32_m(pg, op1, op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmin_s32_x(pg, op1, svdup_n_s32(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svmin_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmin_s32_z(pg, op1, svdup_n_s32(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smin.nxv2i64")]
        fn _svmin_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svmin_s64_m(pg.into(), op1, op2) }
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmin_s64_m(pg, op1, svdup_n_s64(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svmin_s64_m(pg, op1, op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmin_s64_x(pg, op1, svdup_n_s64(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svmin_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smin))]
pub fn svmin_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmin_s64_z(pg, op1, svdup_n_s64(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umin.nxv16i8")]
        fn _svmin_u8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svmin_u8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmin_u8_m(pg, op1, svdup_n_u8(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svmin_u8_m(pg, op1, op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmin_u8_x(pg, op1, svdup_n_u8(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svmin_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmin_u8_z(pg, op1, svdup_n_u8(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umin.nxv8i16")]
        fn _svmin_u16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svmin_u16_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmin_u16_m(pg, op1, svdup_n_u16(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svmin_u16_m(pg, op1, op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmin_u16_x(pg, op1, svdup_n_u16(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svmin_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmin_u16_z(pg, op1, svdup_n_u16(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umin.nxv4i32")]
        fn _svmin_u32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svmin_u32_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmin_u32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svmin_u32_m(pg, op1, op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmin_u32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svmin_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmin_u32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umin.nxv2i64")]
        fn _svmin_u64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svmin_u64_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmin_u64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svmin_u64_m(pg, op1, op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmin_u64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svmin_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[doc = "Minimum"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmin[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umin))]
pub fn svmin_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmin_u64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Minimum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminnm[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub fn svminnm_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fminnm.nxv4f32")]
        fn _svminnm_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svminnm_f32_m(pg.into(), op1, op2) }
}
#[doc = "Minimum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminnm[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub fn svminnm_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svminnm_f32_m(pg, op1, svdup_n_f32(op2))
}
#[doc = "Minimum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminnm[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub fn svminnm_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svminnm_f32_m(pg, op1, op2)
}
#[doc = "Minimum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminnm[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub fn svminnm_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svminnm_f32_x(pg, op1, svdup_n_f32(op2))
}
#[doc = "Minimum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminnm[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub fn svminnm_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svminnm_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[doc = "Minimum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminnm[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub fn svminnm_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svminnm_f32_z(pg, op1, svdup_n_f32(op2))
}
#[doc = "Minimum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminnm[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub fn svminnm_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fminnm.nxv2f64")]
        fn _svminnm_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svminnm_f64_m(pg.into(), op1, op2) }
}
#[doc = "Minimum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminnm[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub fn svminnm_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svminnm_f64_m(pg, op1, svdup_n_f64(op2))
}
#[doc = "Minimum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminnm[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub fn svminnm_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svminnm_f64_m(pg, op1, op2)
}
#[doc = "Minimum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminnm[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub fn svminnm_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svminnm_f64_x(pg, op1, svdup_n_f64(op2))
}
#[doc = "Minimum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminnm[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub fn svminnm_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svminnm_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[doc = "Minimum number"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminnm[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnm))]
pub fn svminnm_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svminnm_f64_z(pg, op1, svdup_n_f64(op2))
}
#[doc = "Minimum number reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminnmv[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnmv))]
pub fn svminnmv_f32(pg: svbool_t, op: svfloat32_t) -> f32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fminnmv.nxv4f32"
        )]
        fn _svminnmv_f32(pg: svbool4_t, op: svfloat32_t) -> f32;
    }
    unsafe { _svminnmv_f32(pg.into(), op) }
}
#[doc = "Minimum number reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminnmv[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminnmv))]
pub fn svminnmv_f64(pg: svbool_t, op: svfloat64_t) -> f64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fminnmv.nxv2f64"
        )]
        fn _svminnmv_f64(pg: svbool2_t, op: svfloat64_t) -> f64;
    }
    unsafe { _svminnmv_f64(pg.into(), op) }
}
#[doc = "Minimum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminv[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminv))]
pub fn svminv_f32(pg: svbool_t, op: svfloat32_t) -> f32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fminv.nxv4f32")]
        fn _svminv_f32(pg: svbool4_t, op: svfloat32_t) -> f32;
    }
    unsafe { _svminv_f32(pg.into(), op) }
}
#[doc = "Minimum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminv[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fminv))]
pub fn svminv_f64(pg: svbool_t, op: svfloat64_t) -> f64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fminv.nxv2f64")]
        fn _svminv_f64(pg: svbool2_t, op: svfloat64_t) -> f64;
    }
    unsafe { _svminv_f64(pg.into(), op) }
}
#[doc = "Minimum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminv[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sminv))]
pub fn svminv_s8(pg: svbool_t, op: svint8_t) -> i8 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sminv.nxv16i8")]
        fn _svminv_s8(pg: svbool_t, op: svint8_t) -> i8;
    }
    unsafe { _svminv_s8(pg, op) }
}
#[doc = "Minimum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminv[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sminv))]
pub fn svminv_s16(pg: svbool_t, op: svint16_t) -> i16 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sminv.nxv8i16")]
        fn _svminv_s16(pg: svbool8_t, op: svint16_t) -> i16;
    }
    unsafe { _svminv_s16(pg.into(), op) }
}
#[doc = "Minimum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminv[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sminv))]
pub fn svminv_s32(pg: svbool_t, op: svint32_t) -> i32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sminv.nxv4i32")]
        fn _svminv_s32(pg: svbool4_t, op: svint32_t) -> i32;
    }
    unsafe { _svminv_s32(pg.into(), op) }
}
#[doc = "Minimum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminv[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sminv))]
pub fn svminv_s64(pg: svbool_t, op: svint64_t) -> i64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sminv.nxv2i64")]
        fn _svminv_s64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _svminv_s64(pg.into(), op) }
}
#[doc = "Minimum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminv[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uminv))]
pub fn svminv_u8(pg: svbool_t, op: svuint8_t) -> u8 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uminv.nxv16i8")]
        fn _svminv_u8(pg: svbool_t, op: svint8_t) -> i8;
    }
    unsafe { _svminv_u8(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Minimum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminv[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uminv))]
pub fn svminv_u16(pg: svbool_t, op: svuint16_t) -> u16 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uminv.nxv8i16")]
        fn _svminv_u16(pg: svbool8_t, op: svint16_t) -> i16;
    }
    unsafe { _svminv_u16(pg.into(), op.as_signed()).as_unsigned() }
}
#[doc = "Minimum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminv[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uminv))]
pub fn svminv_u32(pg: svbool_t, op: svuint32_t) -> u32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uminv.nxv4i32")]
        fn _svminv_u32(pg: svbool4_t, op: svint32_t) -> i32;
    }
    unsafe { _svminv_u32(pg.into(), op.as_signed()).as_unsigned() }
}
#[doc = "Minimum reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svminv[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uminv))]
pub fn svminv_u64(pg: svbool_t, op: svuint64_t) -> u64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uminv.nxv2i64")]
        fn _svminv_u64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _svminv_u64(pg.into(), op.as_signed()).as_unsigned() }
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub fn svmla_f32_m(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmla.nxv4f32")]
        fn _svmla_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
        ) -> svfloat32_t;
    }
    unsafe { _svmla_f32_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub fn svmla_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmla_f32_m(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub fn svmla_f32_x(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svmla_f32_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub fn svmla_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmla_f32_x(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub fn svmla_f32_z(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svmla_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub fn svmla_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmla_f32_z(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub fn svmla_f64_m(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmla.nxv2f64")]
        fn _svmla_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
        ) -> svfloat64_t;
    }
    unsafe { _svmla_f64_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub fn svmla_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmla_f64_m(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub fn svmla_f64_x(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svmla_f64_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub fn svmla_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmla_f64_x(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub fn svmla_f64_z(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svmla_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla))]
pub fn svmla_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmla_f64_z(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mla.nxv16i8")]
        fn _svmla_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t;
    }
    unsafe { _svmla_s8_m(pg, op1, op2, op3) }
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmla_s8_m(pg, op1, op2, svdup_n_s8(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    svmla_s8_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmla_s8_x(pg, op1, op2, svdup_n_s8(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    svmla_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmla_s8_z(pg, op1, op2, svdup_n_s8(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mla.nxv8i16")]
        fn _svmla_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t, op3: svint16_t)
            -> svint16_t;
    }
    unsafe { _svmla_s16_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmla_s16_m(pg, op1, op2, svdup_n_s16(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    svmla_s16_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmla_s16_x(pg, op1, op2, svdup_n_s16(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    svmla_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmla_s16_z(pg, op1, op2, svdup_n_s16(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mla.nxv4i32")]
        fn _svmla_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t, op3: svint32_t)
            -> svint32_t;
    }
    unsafe { _svmla_s32_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmla_s32_m(pg, op1, op2, svdup_n_s32(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    svmla_s32_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmla_s32_x(pg, op1, op2, svdup_n_s32(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    svmla_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmla_s32_z(pg, op1, op2, svdup_n_s32(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mla.nxv2i64")]
        fn _svmla_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t, op3: svint64_t)
            -> svint64_t;
    }
    unsafe { _svmla_s64_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmla_s64_m(pg, op1, op2, svdup_n_s64(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    svmla_s64_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmla_s64_x(pg, op1, op2, svdup_n_s64(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    svmla_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmla_s64_z(pg, op1, op2, svdup_n_s64(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    unsafe { svmla_s8_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmla_u8_m(pg, op1, op2, svdup_n_u8(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    svmla_u8_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmla_u8_x(pg, op1, op2, svdup_n_u8(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    svmla_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmla_u8_z(pg, op1, op2, svdup_n_u8(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    unsafe { svmla_s16_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmla_u16_m(pg, op1, op2, svdup_n_u16(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    svmla_u16_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmla_u16_x(pg, op1, op2, svdup_n_u16(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    svmla_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmla_u16_z(pg, op1, op2, svdup_n_u16(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    unsafe { svmla_s32_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmla_u32_m(pg, op1, op2, svdup_n_u32(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    svmla_u32_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmla_u32_x(pg, op1, op2, svdup_n_u32(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    svmla_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmla_u32_z(pg, op1, op2, svdup_n_u32(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    unsafe { svmla_s64_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmla_u64_m(pg, op1, op2, svdup_n_u64(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    svmla_u64_m(pg, op1, op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmla_u64_x(pg, op1, op2, svdup_n_u64(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    svmla_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2, op3)
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mla))]
pub fn svmla_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmla_u64_z(pg, op1, op2, svdup_n_u64(op3))
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla_lane[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla, IMM_INDEX = 0))]
pub fn svmla_lane_f32<const IMM_INDEX: i32>(
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fmla.lane.nxv4f32"
        )]
        fn _svmla_lane_f32(
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
            IMM_INDEX: i32,
        ) -> svfloat32_t;
    }
    unsafe { _svmla_lane_f32(op1, op2, op3, IMM_INDEX) }
}
#[doc = "Multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmla_lane[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmla, IMM_INDEX = 0))]
pub fn svmla_lane_f64<const IMM_INDEX: i32>(
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fmla.lane.nxv2f64"
        )]
        fn _svmla_lane_f64(
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
            IMM_INDEX: i32,
        ) -> svfloat64_t;
    }
    unsafe { _svmla_lane_f64(op1, op2, op3, IMM_INDEX) }
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub fn svmls_f32_m(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmls.nxv4f32")]
        fn _svmls_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
        ) -> svfloat32_t;
    }
    unsafe { _svmls_f32_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub fn svmls_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmls_f32_m(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub fn svmls_f32_x(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svmls_f32_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub fn svmls_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmls_f32_x(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub fn svmls_f32_z(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svmls_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub fn svmls_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmls_f32_z(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub fn svmls_f64_m(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmls.nxv2f64")]
        fn _svmls_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
        ) -> svfloat64_t;
    }
    unsafe { _svmls_f64_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub fn svmls_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmls_f64_m(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub fn svmls_f64_x(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svmls_f64_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub fn svmls_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmls_f64_x(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub fn svmls_f64_z(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svmls_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls))]
pub fn svmls_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmls_f64_z(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mls.nxv16i8")]
        fn _svmls_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t;
    }
    unsafe { _svmls_s8_m(pg, op1, op2, op3) }
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmls_s8_m(pg, op1, op2, svdup_n_s8(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    svmls_s8_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmls_s8_x(pg, op1, op2, svdup_n_s8(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    svmls_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmls_s8_z(pg, op1, op2, svdup_n_s8(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mls.nxv8i16")]
        fn _svmls_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t, op3: svint16_t)
            -> svint16_t;
    }
    unsafe { _svmls_s16_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmls_s16_m(pg, op1, op2, svdup_n_s16(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    svmls_s16_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmls_s16_x(pg, op1, op2, svdup_n_s16(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    svmls_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmls_s16_z(pg, op1, op2, svdup_n_s16(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mls.nxv4i32")]
        fn _svmls_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t, op3: svint32_t)
            -> svint32_t;
    }
    unsafe { _svmls_s32_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmls_s32_m(pg, op1, op2, svdup_n_s32(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    svmls_s32_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmls_s32_x(pg, op1, op2, svdup_n_s32(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    svmls_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmls_s32_z(pg, op1, op2, svdup_n_s32(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mls.nxv2i64")]
        fn _svmls_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t, op3: svint64_t)
            -> svint64_t;
    }
    unsafe { _svmls_s64_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmls_s64_m(pg, op1, op2, svdup_n_s64(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    svmls_s64_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmls_s64_x(pg, op1, op2, svdup_n_s64(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    svmls_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmls_s64_z(pg, op1, op2, svdup_n_s64(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    unsafe { svmls_s8_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmls_u8_m(pg, op1, op2, svdup_n_u8(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    svmls_u8_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmls_u8_x(pg, op1, op2, svdup_n_u8(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    svmls_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmls_u8_z(pg, op1, op2, svdup_n_u8(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    unsafe { svmls_s16_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmls_u16_m(pg, op1, op2, svdup_n_u16(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    svmls_u16_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmls_u16_x(pg, op1, op2, svdup_n_u16(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    svmls_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmls_u16_z(pg, op1, op2, svdup_n_u16(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    unsafe { svmls_s32_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmls_u32_m(pg, op1, op2, svdup_n_u32(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    svmls_u32_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmls_u32_x(pg, op1, op2, svdup_n_u32(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    svmls_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmls_u32_z(pg, op1, op2, svdup_n_u32(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    unsafe { svmls_s64_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmls_u64_m(pg, op1, op2, svdup_n_u64(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    svmls_u64_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmls_u64_x(pg, op1, op2, svdup_n_u64(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    svmls_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2, op3)
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mls))]
pub fn svmls_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmls_u64_z(pg, op1, op2, svdup_n_u64(op3))
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls_lane[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls, IMM_INDEX = 0))]
pub fn svmls_lane_f32<const IMM_INDEX: i32>(
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fmls.lane.nxv4f32"
        )]
        fn _svmls_lane_f32(
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
            IMM_INDEX: i32,
        ) -> svfloat32_t;
    }
    unsafe { _svmls_lane_f32(op1, op2, op3, IMM_INDEX) }
}
#[doc = "Multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmls_lane[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmls, IMM_INDEX = 0))]
pub fn svmls_lane_f64<const IMM_INDEX: i32>(
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.fmls.lane.nxv2f64"
        )]
        fn _svmls_lane_f64(
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
            IMM_INDEX: i32,
        ) -> svfloat64_t;
    }
    unsafe { _svmls_lane_f64(op1, op2, op3, IMM_INDEX) }
}
#[doc = "Matrix multiply-accumulate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmmla[_f32])"]
#[inline]
#[target_feature(enable = "sve,f32mm")]
#[cfg_attr(test, assert_instr(fmmla))]
pub fn svmmla_f32(op1: svfloat32_t, op2: svfloat32_t, op3: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmmla.nxv4f32")]
        fn _svmmla_f32(op1: svfloat32_t, op2: svfloat32_t, op3: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svmmla_f32(op1, op2, op3) }
}
#[doc = "Matrix multiply-accumulate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmmla[_f64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(fmmla))]
pub fn svmmla_f64(op1: svfloat64_t, op2: svfloat64_t, op3: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmmla.nxv2f64")]
        fn _svmmla_f64(op1: svfloat64_t, op2: svfloat64_t, op3: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svmmla_f64(op1, op2, op3) }
}
#[doc = "Matrix multiply-accumulate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmmla[_s32])"]
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(smmla))]
pub fn svmmla_s32(op1: svint32_t, op2: svint8_t, op3: svint8_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smmla.nxv4i32")]
        fn _svmmla_s32(op1: svint32_t, op2: svint8_t, op3: svint8_t) -> svint32_t;
    }
    unsafe { _svmmla_s32(op1, op2, op3) }
}
#[doc = "Matrix multiply-accumulate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmmla[_u32])"]
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(ummla))]
pub fn svmmla_u32(op1: svuint32_t, op2: svuint8_t, op3: svuint8_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ummla.nxv4i32")]
        fn _svmmla_u32(op1: svint32_t, op2: svint8_t, op3: svint8_t) -> svint32_t;
    }
    unsafe { _svmmla_u32(op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Move"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmov[_b]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mov))]
pub fn svmov_b_z(pg: svbool_t, op: svbool_t) -> svbool_t {
    svand_b_z(pg, op, op)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub fn svmsb_f32_m(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmsb.nxv4f32")]
        fn _svmsb_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
        ) -> svfloat32_t;
    }
    unsafe { _svmsb_f32_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub fn svmsb_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmsb_f32_m(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub fn svmsb_f32_x(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svmsb_f32_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub fn svmsb_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmsb_f32_x(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub fn svmsb_f32_z(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svmsb_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub fn svmsb_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svmsb_f32_z(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub fn svmsb_f64_m(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmsb.nxv2f64")]
        fn _svmsb_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
        ) -> svfloat64_t;
    }
    unsafe { _svmsb_f64_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub fn svmsb_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmsb_f64_m(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub fn svmsb_f64_x(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svmsb_f64_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub fn svmsb_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmsb_f64_x(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub fn svmsb_f64_z(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svmsb_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmsb))]
pub fn svmsb_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svmsb_f64_z(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.msb.nxv16i8")]
        fn _svmsb_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t;
    }
    unsafe { _svmsb_s8_m(pg, op1, op2, op3) }
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmsb_s8_m(pg, op1, op2, svdup_n_s8(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    svmsb_s8_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmsb_s8_x(pg, op1, op2, svdup_n_s8(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: svint8_t) -> svint8_t {
    svmsb_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t, op3: i8) -> svint8_t {
    svmsb_s8_z(pg, op1, op2, svdup_n_s8(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.msb.nxv8i16")]
        fn _svmsb_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t, op3: svint16_t)
            -> svint16_t;
    }
    unsafe { _svmsb_s16_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmsb_s16_m(pg, op1, op2, svdup_n_s16(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    svmsb_s16_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmsb_s16_x(pg, op1, op2, svdup_n_s16(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: svint16_t) -> svint16_t {
    svmsb_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t, op3: i16) -> svint16_t {
    svmsb_s16_z(pg, op1, op2, svdup_n_s16(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.msb.nxv4i32")]
        fn _svmsb_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t, op3: svint32_t)
            -> svint32_t;
    }
    unsafe { _svmsb_s32_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmsb_s32_m(pg, op1, op2, svdup_n_s32(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    svmsb_s32_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmsb_s32_x(pg, op1, op2, svdup_n_s32(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: svint32_t) -> svint32_t {
    svmsb_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t, op3: i32) -> svint32_t {
    svmsb_s32_z(pg, op1, op2, svdup_n_s32(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.msb.nxv2i64")]
        fn _svmsb_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t, op3: svint64_t)
            -> svint64_t;
    }
    unsafe { _svmsb_s64_m(pg.into(), op1, op2, op3) }
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmsb_s64_m(pg, op1, op2, svdup_n_s64(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    svmsb_s64_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmsb_s64_x(pg, op1, op2, svdup_n_s64(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: svint64_t) -> svint64_t {
    svmsb_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t, op3: i64) -> svint64_t {
    svmsb_s64_z(pg, op1, op2, svdup_n_s64(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    unsafe { svmsb_s8_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmsb_u8_m(pg, op1, op2, svdup_n_u8(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    svmsb_u8_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmsb_u8_x(pg, op1, op2, svdup_n_u8(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: svuint8_t) -> svuint8_t {
    svmsb_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t, op3: u8) -> svuint8_t {
    svmsb_u8_z(pg, op1, op2, svdup_n_u8(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    unsafe { svmsb_s16_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmsb_u16_m(pg, op1, op2, svdup_n_u16(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    svmsb_u16_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmsb_u16_x(pg, op1, op2, svdup_n_u16(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: svuint16_t) -> svuint16_t {
    svmsb_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t, op3: u16) -> svuint16_t {
    svmsb_u16_z(pg, op1, op2, svdup_n_u16(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    unsafe { svmsb_s32_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmsb_u32_m(pg, op1, op2, svdup_n_u32(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    svmsb_u32_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmsb_u32_x(pg, op1, op2, svdup_n_u32(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: svuint32_t) -> svuint32_t {
    svmsb_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t, op3: u32) -> svuint32_t {
    svmsb_u32_z(pg, op1, op2, svdup_n_u32(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    unsafe { svmsb_s64_m(pg, op1.as_signed(), op2.as_signed(), op3.as_signed()).as_unsigned() }
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmsb_u64_m(pg, op1, op2, svdup_n_u64(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    svmsb_u64_m(pg, op1, op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmsb_u64_x(pg, op1, op2, svdup_n_u64(op3))
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: svuint64_t) -> svuint64_t {
    svmsb_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2, op3)
}
#[doc = "Multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmsb[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(msb))]
pub fn svmsb_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t, op3: u64) -> svuint64_t {
    svmsb_u64_z(pg, op1, op2, svdup_n_u64(op3))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub fn svmul_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmul.nxv4f32")]
        fn _svmul_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svmul_f32_m(pg.into(), op1, op2) }
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub fn svmul_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmul_f32_m(pg, op1, svdup_n_f32(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub fn svmul_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmul_f32_m(pg, op1, op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub fn svmul_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmul_f32_x(pg, op1, svdup_n_f32(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub fn svmul_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmul_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub fn svmul_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmul_f32_z(pg, op1, svdup_n_f32(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub fn svmul_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmul.nxv2f64")]
        fn _svmul_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svmul_f64_m(pg.into(), op1, op2) }
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub fn svmul_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmul_f64_m(pg, op1, svdup_n_f64(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub fn svmul_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmul_f64_m(pg, op1, op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub fn svmul_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmul_f64_x(pg, op1, svdup_n_f64(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub fn svmul_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmul_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmul))]
pub fn svmul_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmul_f64_z(pg, op1, svdup_n_f64(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mul.nxv16i8")]
        fn _svmul_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svmul_s8_m(pg, op1, op2) }
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmul_s8_m(pg, op1, svdup_n_s8(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svmul_s8_m(pg, op1, op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmul_s8_x(pg, op1, svdup_n_s8(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svmul_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmul_s8_z(pg, op1, svdup_n_s8(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mul.nxv8i16")]
        fn _svmul_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svmul_s16_m(pg.into(), op1, op2) }
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmul_s16_m(pg, op1, svdup_n_s16(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svmul_s16_m(pg, op1, op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmul_s16_x(pg, op1, svdup_n_s16(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svmul_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmul_s16_z(pg, op1, svdup_n_s16(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mul.nxv4i32")]
        fn _svmul_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svmul_s32_m(pg.into(), op1, op2) }
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmul_s32_m(pg, op1, svdup_n_s32(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svmul_s32_m(pg, op1, op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmul_s32_x(pg, op1, svdup_n_s32(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svmul_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmul_s32_z(pg, op1, svdup_n_s32(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.mul.nxv2i64")]
        fn _svmul_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svmul_s64_m(pg.into(), op1, op2) }
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmul_s64_m(pg, op1, svdup_n_s64(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svmul_s64_m(pg, op1, op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmul_s64_x(pg, op1, svdup_n_s64(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svmul_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmul_s64_z(pg, op1, svdup_n_s64(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svmul_s8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmul_u8_m(pg, op1, svdup_n_u8(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svmul_u8_m(pg, op1, op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmul_u8_x(pg, op1, svdup_n_u8(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svmul_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmul_u8_z(pg, op1, svdup_n_u8(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svmul_s16_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmul_u16_m(pg, op1, svdup_n_u16(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svmul_u16_m(pg, op1, op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmul_u16_x(pg, op1, svdup_n_u16(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svmul_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmul_u16_z(pg, op1, svdup_n_u16(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svmul_s32_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmul_u32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svmul_u32_m(pg, op1, op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmul_u32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svmul_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmul_u32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svmul_s64_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmul_u64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svmul_u64_m(pg, op1, op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmul_u64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svmul_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[doc = "Multiply"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmul[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(mul))]
pub fn svmul_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmul_u64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smulh.nxv16i8")]
        fn _svmulh_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svmulh_s8_m(pg, op1, op2) }
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmulh_s8_m(pg, op1, svdup_n_s8(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svmulh_s8_m(pg, op1, op2)
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmulh_s8_x(pg, op1, svdup_n_s8(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svmulh_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svmulh_s8_z(pg, op1, svdup_n_s8(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smulh.nxv8i16")]
        fn _svmulh_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svmulh_s16_m(pg.into(), op1, op2) }
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmulh_s16_m(pg, op1, svdup_n_s16(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svmulh_s16_m(pg, op1, op2)
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmulh_s16_x(pg, op1, svdup_n_s16(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svmulh_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svmulh_s16_z(pg, op1, svdup_n_s16(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smulh.nxv4i32")]
        fn _svmulh_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svmulh_s32_m(pg.into(), op1, op2) }
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmulh_s32_m(pg, op1, svdup_n_s32(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svmulh_s32_m(pg, op1, op2)
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmulh_s32_x(pg, op1, svdup_n_s32(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svmulh_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svmulh_s32_z(pg, op1, svdup_n_s32(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.smulh.nxv2i64")]
        fn _svmulh_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svmulh_s64_m(pg.into(), op1, op2) }
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmulh_s64_m(pg, op1, svdup_n_s64(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svmulh_s64_m(pg, op1, op2)
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmulh_s64_x(pg, op1, svdup_n_s64(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svmulh_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(smulh))]
pub fn svmulh_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svmulh_s64_z(pg, op1, svdup_n_s64(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umulh.nxv16i8")]
        fn _svmulh_u8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svmulh_u8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmulh_u8_m(pg, op1, svdup_n_u8(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svmulh_u8_m(pg, op1, op2)
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmulh_u8_x(pg, op1, svdup_n_u8(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svmulh_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svmulh_u8_z(pg, op1, svdup_n_u8(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umulh.nxv8i16")]
        fn _svmulh_u16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svmulh_u16_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmulh_u16_m(pg, op1, svdup_n_u16(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svmulh_u16_m(pg, op1, op2)
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmulh_u16_x(pg, op1, svdup_n_u16(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svmulh_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svmulh_u16_z(pg, op1, svdup_n_u16(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umulh.nxv4i32")]
        fn _svmulh_u32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svmulh_u32_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmulh_u32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svmulh_u32_m(pg, op1, op2)
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmulh_u32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svmulh_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svmulh_u32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.umulh.nxv2i64")]
        fn _svmulh_u64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svmulh_u64_m(pg.into(), op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmulh_u64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svmulh_u64_m(pg, op1, op2)
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmulh_u64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svmulh_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[doc = "Multiply, returning high-half"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulh[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(umulh))]
pub fn svmulh_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svmulh_u64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Multiply extended (∞×0=2)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulx[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub fn svmulx_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmulx.nxv4f32")]
        fn _svmulx_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svmulx_f32_m(pg.into(), op1, op2) }
}
#[doc = "Multiply extended (∞×0=2)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulx[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub fn svmulx_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmulx_f32_m(pg, op1, svdup_n_f32(op2))
}
#[doc = "Multiply extended (∞×0=2)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulx[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub fn svmulx_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmulx_f32_m(pg, op1, op2)
}
#[doc = "Multiply extended (∞×0=2)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulx[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub fn svmulx_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmulx_f32_x(pg, op1, svdup_n_f32(op2))
}
#[doc = "Multiply extended (∞×0=2)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulx[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub fn svmulx_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svmulx_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[doc = "Multiply extended (∞×0=2)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulx[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub fn svmulx_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svmulx_f32_z(pg, op1, svdup_n_f32(op2))
}
#[doc = "Multiply extended (∞×0=2)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulx[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub fn svmulx_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fmulx.nxv2f64")]
        fn _svmulx_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svmulx_f64_m(pg.into(), op1, op2) }
}
#[doc = "Multiply extended (∞×0=2)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulx[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub fn svmulx_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmulx_f64_m(pg, op1, svdup_n_f64(op2))
}
#[doc = "Multiply extended (∞×0=2)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulx[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub fn svmulx_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmulx_f64_m(pg, op1, op2)
}
#[doc = "Multiply extended (∞×0=2)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulx[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub fn svmulx_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmulx_f64_x(pg, op1, svdup_n_f64(op2))
}
#[doc = "Multiply extended (∞×0=2)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulx[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub fn svmulx_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svmulx_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[doc = "Multiply extended (∞×0=2)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svmulx[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fmulx))]
pub fn svmulx_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svmulx_f64_z(pg, op1, svdup_n_f64(op2))
}
#[doc = "Bitwise NAND"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnand[_b]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(nand))]
pub fn svnand_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.nand.z.nxv16i1")]
        fn _svnand_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svnand_b_z(pg, op1, op2) }
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fneg))]
pub fn svneg_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fneg.nxv4f32")]
        fn _svneg_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svneg_f32_m(inactive, pg.into(), op) }
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fneg))]
pub fn svneg_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svneg_f32_m(op, pg, op)
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fneg))]
pub fn svneg_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svneg_f32_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fneg))]
pub fn svneg_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fneg.nxv2f64")]
        fn _svneg_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svneg_f64_m(inactive, pg.into(), op) }
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fneg))]
pub fn svneg_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svneg_f64_m(op, pg, op)
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fneg))]
pub fn svneg_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svneg_f64_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub fn svneg_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.neg.nxv16i8")]
        fn _svneg_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t;
    }
    unsafe { _svneg_s8_m(inactive, pg, op) }
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub fn svneg_s8_x(pg: svbool_t, op: svint8_t) -> svint8_t {
    svneg_s8_m(op, pg, op)
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub fn svneg_s8_z(pg: svbool_t, op: svint8_t) -> svint8_t {
    svneg_s8_m(svdup_n_s8(0), pg, op)
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub fn svneg_s16_m(inactive: svint16_t, pg: svbool_t, op: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.neg.nxv8i16")]
        fn _svneg_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svneg_s16_m(inactive, pg.into(), op) }
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub fn svneg_s16_x(pg: svbool_t, op: svint16_t) -> svint16_t {
    svneg_s16_m(op, pg, op)
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub fn svneg_s16_z(pg: svbool_t, op: svint16_t) -> svint16_t {
    svneg_s16_m(svdup_n_s16(0), pg, op)
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub fn svneg_s32_m(inactive: svint32_t, pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.neg.nxv4i32")]
        fn _svneg_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svneg_s32_m(inactive, pg.into(), op) }
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub fn svneg_s32_x(pg: svbool_t, op: svint32_t) -> svint32_t {
    svneg_s32_m(op, pg, op)
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub fn svneg_s32_z(pg: svbool_t, op: svint32_t) -> svint32_t {
    svneg_s32_m(svdup_n_s32(0), pg, op)
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub fn svneg_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.neg.nxv2i64")]
        fn _svneg_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svneg_s64_m(inactive, pg.into(), op) }
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub fn svneg_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svneg_s64_m(op, pg, op)
}
#[doc = "Negate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svneg[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(neg))]
pub fn svneg_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svneg_s64_m(svdup_n_s64(0), pg, op)
}
#[doc = "Negated multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmad[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub fn svnmad_f32_m(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fnmad.nxv4f32")]
        fn _svnmad_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
        ) -> svfloat32_t;
    }
    unsafe { _svnmad_f32_m(pg.into(), op1, op2, op3) }
}
#[doc = "Negated multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmad[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub fn svnmad_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmad_f32_m(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Negated multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmad[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub fn svnmad_f32_x(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svnmad_f32_m(pg, op1, op2, op3)
}
#[doc = "Negated multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmad[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub fn svnmad_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmad_f32_x(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Negated multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmad[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub fn svnmad_f32_z(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svnmad_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[doc = "Negated multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmad[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub fn svnmad_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmad_f32_z(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Negated multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmad[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub fn svnmad_f64_m(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fnmad.nxv2f64")]
        fn _svnmad_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
        ) -> svfloat64_t;
    }
    unsafe { _svnmad_f64_m(pg.into(), op1, op2, op3) }
}
#[doc = "Negated multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmad[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub fn svnmad_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmad_f64_m(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Negated multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmad[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub fn svnmad_f64_x(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svnmad_f64_m(pg, op1, op2, op3)
}
#[doc = "Negated multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmad[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub fn svnmad_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmad_f64_x(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Negated multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmad[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub fn svnmad_f64_z(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svnmad_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[doc = "Negated multiply-add, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmad[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmad))]
pub fn svnmad_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmad_f64_z(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Negated multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmla[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub fn svnmla_f32_m(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fnmla.nxv4f32")]
        fn _svnmla_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
        ) -> svfloat32_t;
    }
    unsafe { _svnmla_f32_m(pg.into(), op1, op2, op3) }
}
#[doc = "Negated multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmla[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub fn svnmla_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmla_f32_m(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Negated multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmla[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub fn svnmla_f32_x(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svnmla_f32_m(pg, op1, op2, op3)
}
#[doc = "Negated multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmla[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub fn svnmla_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmla_f32_x(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Negated multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmla[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub fn svnmla_f32_z(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svnmla_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[doc = "Negated multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmla[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub fn svnmla_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmla_f32_z(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Negated multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmla[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub fn svnmla_f64_m(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fnmla.nxv2f64")]
        fn _svnmla_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
        ) -> svfloat64_t;
    }
    unsafe { _svnmla_f64_m(pg.into(), op1, op2, op3) }
}
#[doc = "Negated multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmla[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub fn svnmla_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmla_f64_m(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Negated multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmla[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub fn svnmla_f64_x(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svnmla_f64_m(pg, op1, op2, op3)
}
#[doc = "Negated multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmla[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub fn svnmla_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmla_f64_x(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Negated multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmla[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub fn svnmla_f64_z(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svnmla_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[doc = "Negated multiply-add, addend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmla[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmla))]
pub fn svnmla_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmla_f64_z(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Negated multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmls[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub fn svnmls_f32_m(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fnmls.nxv4f32")]
        fn _svnmls_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
        ) -> svfloat32_t;
    }
    unsafe { _svnmls_f32_m(pg.into(), op1, op2, op3) }
}
#[doc = "Negated multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmls[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub fn svnmls_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmls_f32_m(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Negated multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmls[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub fn svnmls_f32_x(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svnmls_f32_m(pg, op1, op2, op3)
}
#[doc = "Negated multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmls[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub fn svnmls_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmls_f32_x(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Negated multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmls[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub fn svnmls_f32_z(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svnmls_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[doc = "Negated multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmls[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub fn svnmls_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmls_f32_z(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Negated multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmls[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub fn svnmls_f64_m(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fnmls.nxv2f64")]
        fn _svnmls_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
        ) -> svfloat64_t;
    }
    unsafe { _svnmls_f64_m(pg.into(), op1, op2, op3) }
}
#[doc = "Negated multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmls[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub fn svnmls_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmls_f64_m(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Negated multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmls[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub fn svnmls_f64_x(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svnmls_f64_m(pg, op1, op2, op3)
}
#[doc = "Negated multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmls[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub fn svnmls_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmls_f64_x(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Negated multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmls[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub fn svnmls_f64_z(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svnmls_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[doc = "Negated multiply-subtract, minuend first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmls[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmls))]
pub fn svnmls_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmls_f64_z(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Negated multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmsb[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub fn svnmsb_f32_m(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fnmsb.nxv4f32")]
        fn _svnmsb_f32_m(
            pg: svbool4_t,
            op1: svfloat32_t,
            op2: svfloat32_t,
            op3: svfloat32_t,
        ) -> svfloat32_t;
    }
    unsafe { _svnmsb_f32_m(pg.into(), op1, op2, op3) }
}
#[doc = "Negated multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmsb[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub fn svnmsb_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmsb_f32_m(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Negated multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmsb[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub fn svnmsb_f32_x(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svnmsb_f32_m(pg, op1, op2, op3)
}
#[doc = "Negated multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmsb[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub fn svnmsb_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmsb_f32_x(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Negated multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmsb[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub fn svnmsb_f32_z(
    pg: svbool_t,
    op1: svfloat32_t,
    op2: svfloat32_t,
    op3: svfloat32_t,
) -> svfloat32_t {
    svnmsb_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2, op3)
}
#[doc = "Negated multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmsb[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub fn svnmsb_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t, op3: f32) -> svfloat32_t {
    svnmsb_f32_z(pg, op1, op2, svdup_n_f32(op3))
}
#[doc = "Negated multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmsb[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub fn svnmsb_f64_m(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fnmsb.nxv2f64")]
        fn _svnmsb_f64_m(
            pg: svbool2_t,
            op1: svfloat64_t,
            op2: svfloat64_t,
            op3: svfloat64_t,
        ) -> svfloat64_t;
    }
    unsafe { _svnmsb_f64_m(pg.into(), op1, op2, op3) }
}
#[doc = "Negated multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmsb[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub fn svnmsb_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmsb_f64_m(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Negated multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmsb[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub fn svnmsb_f64_x(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svnmsb_f64_m(pg, op1, op2, op3)
}
#[doc = "Negated multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmsb[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub fn svnmsb_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmsb_f64_x(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Negated multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmsb[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub fn svnmsb_f64_z(
    pg: svbool_t,
    op1: svfloat64_t,
    op2: svfloat64_t,
    op3: svfloat64_t,
) -> svfloat64_t {
    svnmsb_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2, op3)
}
#[doc = "Negated multiply-subtract, multiplicand first"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnmsb[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fnmsb))]
pub fn svnmsb_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t, op3: f64) -> svfloat64_t {
    svnmsb_f64_z(pg, op1, op2, svdup_n_f64(op3))
}
#[doc = "Bitwise NOR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnor[_b]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(nor))]
pub fn svnor_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.nor.z.nxv16i1")]
        fn _svnor_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svnor_b_z(pg, op1, op2) }
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_b]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_b_z(pg: svbool_t, op: svbool_t) -> svbool_t {
    sveor_b_z(pg, op, pg)
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.not.nxv16i8")]
        fn _svnot_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t;
    }
    unsafe { _svnot_s8_m(inactive, pg, op) }
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_s8_x(pg: svbool_t, op: svint8_t) -> svint8_t {
    svnot_s8_m(op, pg, op)
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_s8_z(pg: svbool_t, op: svint8_t) -> svint8_t {
    svnot_s8_m(svdup_n_s8(0), pg, op)
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_s16_m(inactive: svint16_t, pg: svbool_t, op: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.not.nxv8i16")]
        fn _svnot_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svnot_s16_m(inactive, pg.into(), op) }
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_s16_x(pg: svbool_t, op: svint16_t) -> svint16_t {
    svnot_s16_m(op, pg, op)
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_s16_z(pg: svbool_t, op: svint16_t) -> svint16_t {
    svnot_s16_m(svdup_n_s16(0), pg, op)
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_s32_m(inactive: svint32_t, pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.not.nxv4i32")]
        fn _svnot_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svnot_s32_m(inactive, pg.into(), op) }
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_s32_x(pg: svbool_t, op: svint32_t) -> svint32_t {
    svnot_s32_m(op, pg, op)
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_s32_z(pg: svbool_t, op: svint32_t) -> svint32_t {
    svnot_s32_m(svdup_n_s32(0), pg, op)
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.not.nxv2i64")]
        fn _svnot_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svnot_s64_m(inactive, pg.into(), op) }
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svnot_s64_m(op, pg, op)
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svnot_s64_m(svdup_n_s64(0), pg, op)
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_u8_m(inactive: svuint8_t, pg: svbool_t, op: svuint8_t) -> svuint8_t {
    unsafe { svnot_s8_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_u8_x(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svnot_u8_m(op, pg, op)
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_u8_z(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svnot_u8_m(svdup_n_u8(0), pg, op)
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_u16_m(inactive: svuint16_t, pg: svbool_t, op: svuint16_t) -> svuint16_t {
    unsafe { svnot_s16_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_u16_x(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svnot_u16_m(op, pg, op)
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_u16_z(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svnot_u16_m(svdup_n_u16(0), pg, op)
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    unsafe { svnot_s32_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svnot_u32_m(op, pg, op)
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svnot_u32_m(svdup_n_u32(0), pg, op)
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svnot_s64_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svnot_u64_m(op, pg, op)
}
#[doc = "Bitwise invert"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svnot[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(not))]
pub fn svnot_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svnot_u64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Bitwise inclusive OR, inverting second argument"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorn[_b]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orn))]
pub fn svorn_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orn.z.nvx16i1")]
        fn _svorn_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svorn_b_z(pg, op1, op2) }
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_b]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orr.z.nvx16i1")]
        fn _svorr_b_z(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svorr_b_z(pg, op1, op2) }
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orr.nxv16i8")]
        fn _svorr_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svorr_s8_m(pg, op1, op2) }
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svorr_s8_m(pg, op1, svdup_n_s8(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svorr_s8_m(pg, op1, op2)
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svorr_s8_x(pg, op1, svdup_n_s8(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svorr_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svorr_s8_z(pg, op1, svdup_n_s8(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orr.nxv8i16")]
        fn _svorr_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svorr_s16_m(pg.into(), op1, op2) }
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svorr_s16_m(pg, op1, svdup_n_s16(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svorr_s16_m(pg, op1, op2)
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svorr_s16_x(pg, op1, svdup_n_s16(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svorr_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svorr_s16_z(pg, op1, svdup_n_s16(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orr.nxv4i32")]
        fn _svorr_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svorr_s32_m(pg.into(), op1, op2) }
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svorr_s32_m(pg, op1, svdup_n_s32(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svorr_s32_m(pg, op1, op2)
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svorr_s32_x(pg, op1, svdup_n_s32(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svorr_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svorr_s32_z(pg, op1, svdup_n_s32(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orr.nxv2i64")]
        fn _svorr_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svorr_s64_m(pg.into(), op1, op2) }
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svorr_s64_m(pg, op1, svdup_n_s64(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svorr_s64_m(pg, op1, op2)
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svorr_s64_x(pg, op1, svdup_n_s64(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svorr_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svorr_s64_z(pg, op1, svdup_n_s64(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svorr_s8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svorr_u8_m(pg, op1, svdup_n_u8(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svorr_u8_m(pg, op1, op2)
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svorr_u8_x(pg, op1, svdup_n_u8(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svorr_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svorr_u8_z(pg, op1, svdup_n_u8(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svorr_s16_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svorr_u16_m(pg, op1, svdup_n_u16(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svorr_u16_m(pg, op1, op2)
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svorr_u16_x(pg, op1, svdup_n_u16(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svorr_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svorr_u16_z(pg, op1, svdup_n_u16(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svorr_s32_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svorr_u32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svorr_u32_m(pg, op1, op2)
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svorr_u32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svorr_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svorr_u32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svorr_s64_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svorr_u64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svorr_u64_m(pg, op1, op2)
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svorr_u64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svorr_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[doc = "Bitwise inclusive OR"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorr[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orr))]
pub fn svorr_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svorr_u64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Bitwise inclusive OR reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorv[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orv))]
pub fn svorv_s8(pg: svbool_t, op: svint8_t) -> i8 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orv.nxv16i8")]
        fn _svorv_s8(pg: svbool_t, op: svint8_t) -> i8;
    }
    unsafe { _svorv_s8(pg, op) }
}
#[doc = "Bitwise inclusive OR reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorv[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orv))]
pub fn svorv_s16(pg: svbool_t, op: svint16_t) -> i16 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orv.nxv8i16")]
        fn _svorv_s16(pg: svbool8_t, op: svint16_t) -> i16;
    }
    unsafe { _svorv_s16(pg.into(), op) }
}
#[doc = "Bitwise inclusive OR reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorv[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orv))]
pub fn svorv_s32(pg: svbool_t, op: svint32_t) -> i32 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orv.nxv4i32")]
        fn _svorv_s32(pg: svbool4_t, op: svint32_t) -> i32;
    }
    unsafe { _svorv_s32(pg.into(), op) }
}
#[doc = "Bitwise inclusive OR reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorv[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orv))]
pub fn svorv_s64(pg: svbool_t, op: svint64_t) -> i64 {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.orv.nxv2i64")]
        fn _svorv_s64(pg: svbool2_t, op: svint64_t) -> i64;
    }
    unsafe { _svorv_s64(pg.into(), op) }
}
#[doc = "Bitwise inclusive OR reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorv[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orv))]
pub fn svorv_u8(pg: svbool_t, op: svuint8_t) -> u8 {
    unsafe { svorv_s8(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Bitwise inclusive OR reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorv[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orv))]
pub fn svorv_u16(pg: svbool_t, op: svuint16_t) -> u16 {
    unsafe { svorv_s16(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Bitwise inclusive OR reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorv[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orv))]
pub fn svorv_u32(pg: svbool_t, op: svuint32_t) -> u32 {
    unsafe { svorv_s32(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Bitwise inclusive OR reduction to scalar"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svorv[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(orv))]
pub fn svorv_u64(pg: svbool_t, op: svuint64_t) -> u64 {
    unsafe { svorv_s64(pg, op.as_signed()).as_unsigned() }
}
#[doc = "Set all predicate elements to false"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svpfalse[_b])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(pfalse))]
pub fn svpfalse_b() -> svbool_t {
    svdupq_n_b8(
        false, false, false, false, false, false, false, false, false, false, false, false, false,
        false, false, false,
    )
}
#[doc = "Set the first active predicate element to true"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svpfirst[_b])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(pfirst))]
pub fn svpfirst_b(pg: svbool_t, op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.pfirst.nxv16i1")]
        fn _svpfirst_b(pg: svbool_t, op: svbool_t) -> svbool_t;
    }
    unsafe { _svpfirst_b(pg, op) }
}
#[doc = "Find next active predicate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svpnext_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(pnext))]
pub fn svpnext_b8(pg: svbool_t, op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.pnext.nxv16i1")]
        fn _svpnext_b8(pg: svbool_t, op: svbool_t) -> svbool_t;
    }
    unsafe { _svpnext_b8(pg, op) }
}
#[doc = "Find next active predicate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svpnext_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(pnext))]
pub fn svpnext_b16(pg: svbool_t, op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.pnext.nxv8i1")]
        fn _svpnext_b16(pg: svbool8_t, op: svbool8_t) -> svbool8_t;
    }
    unsafe { _svpnext_b16(pg.into(), op.into()).into() }
}
#[doc = "Find next active predicate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svpnext_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(pnext))]
pub fn svpnext_b32(pg: svbool_t, op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.pnext.nxv4i1")]
        fn _svpnext_b32(pg: svbool4_t, op: svbool4_t) -> svbool4_t;
    }
    unsafe { _svpnext_b32(pg.into(), op.into()).into() }
}
#[doc = "Find next active predicate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svpnext_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(pnext))]
pub fn svpnext_b64(pg: svbool_t, op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.pnext.nxv2i1")]
        fn _svpnext_b64(pg: svbool2_t, op: svbool2_t) -> svbool2_t;
    }
    unsafe { _svpnext_b64(pg.into(), op.into()).into() }
}
#[doc = "Prefetch bytes"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfb)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfb<const OP: svprfop, T>(pg: svbool_t, base: *const T) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.prf.nxv16i1")]
        fn _svprfb(pg: svbool_t, base: *const crate::ffi::c_void, op: svprfop);
    }
    _svprfb(pg, base as *const crate::ffi::c_void, OP)
}
#[doc = "Prefetch halfwords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfh)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfh , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfh<const OP: svprfop, T>(pg: svbool_t, base: *const T) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.prf.nxv8i1")]
        fn _svprfh(pg: svbool8_t, base: *const crate::ffi::c_void, op: svprfop);
    }
    _svprfh(pg.into(), base as *const crate::ffi::c_void, OP)
}
#[doc = "Prefetch words"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfw)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfw , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfw<const OP: svprfop, T>(pg: svbool_t, base: *const T) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.prf.nxv4i1")]
        fn _svprfw(pg: svbool4_t, base: *const crate::ffi::c_void, op: svprfop);
    }
    _svprfw(pg.into(), base as *const crate::ffi::c_void, OP)
}
#[doc = "Prefetch doublewords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfd)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfd , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfd<const OP: svprfop, T>(pg: svbool_t, base: *const T) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.prf.nxv2i1")]
        fn _svprfd(pg: svbool2_t, base: *const crate::ffi::c_void, op: svprfop);
    }
    _svprfd(pg.into(), base as *const crate::ffi::c_void, OP)
}
#[doc = "Prefetch bytes"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfb_gather_[s32]offset)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfb_gather_s32offset<const OP: svprfop, T>(
    pg: svbool_t,
    base: *const T,
    offsets: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfb.gather.sxtw.index.nxv4i32"
        )]
        fn _svprfb_gather_s32offset(
            pg: svbool4_t,
            base: *const crate::ffi::c_void,
            offsets: svint32_t,
            op: svprfop,
        );
    }
    _svprfb_gather_s32offset(pg.into(), base as *const crate::ffi::c_void, offsets, OP)
}
#[doc = "Prefetch halfwords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfh_gather_[s32]index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfh , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfh_gather_s32index<const OP: svprfop, T>(
    pg: svbool_t,
    base: *const T,
    indices: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfh.gather.sxtw.index.nxv4i32"
        )]
        fn _svprfh_gather_s32index(
            pg: svbool4_t,
            base: *const crate::ffi::c_void,
            indices: svint32_t,
            op: svprfop,
        );
    }
    _svprfh_gather_s32index(pg.into(), base as *const crate::ffi::c_void, indices, OP)
}
#[doc = "Prefetch words"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfw_gather_[s32]index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfw , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfw_gather_s32index<const OP: svprfop, T>(
    pg: svbool_t,
    base: *const T,
    indices: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfw.gather.sxtw.index.nxv4i32"
        )]
        fn _svprfw_gather_s32index(
            pg: svbool4_t,
            base: *const crate::ffi::c_void,
            indices: svint32_t,
            op: svprfop,
        );
    }
    _svprfw_gather_s32index(pg.into(), base as *const crate::ffi::c_void, indices, OP)
}
#[doc = "Prefetch doublewords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfd_gather_[s32]index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfd , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfd_gather_s32index<const OP: svprfop, T>(
    pg: svbool_t,
    base: *const T,
    indices: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfd.gather.sxtw.index.nxv4i32"
        )]
        fn _svprfd_gather_s32index(
            pg: svbool4_t,
            base: *const crate::ffi::c_void,
            indices: svint32_t,
            op: svprfop,
        );
    }
    _svprfd_gather_s32index(pg.into(), base as *const crate::ffi::c_void, indices, OP)
}
#[doc = "Prefetch bytes"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfb_gather_[s64]offset)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfb_gather_s64offset<const OP: svprfop, T>(
    pg: svbool_t,
    base: *const T,
    offsets: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfb.gather.index.nxv2i64"
        )]
        fn _svprfb_gather_s64offset(
            pg: svbool2_t,
            base: *const crate::ffi::c_void,
            offsets: svint64_t,
            op: svprfop,
        );
    }
    _svprfb_gather_s64offset(pg.into(), base as *const crate::ffi::c_void, offsets, OP)
}
#[doc = "Prefetch halfwords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfh_gather_[s64]index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfh , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfh_gather_s64index<const OP: svprfop, T>(
    pg: svbool_t,
    base: *const T,
    indices: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfh.gather.index.nxv2i64"
        )]
        fn _svprfh_gather_s64index(
            pg: svbool2_t,
            base: *const crate::ffi::c_void,
            indices: svint64_t,
            op: svprfop,
        );
    }
    _svprfh_gather_s64index(pg.into(), base as *const crate::ffi::c_void, indices, OP)
}
#[doc = "Prefetch words"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfw_gather_[s64]index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfw , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfw_gather_s64index<const OP: svprfop, T>(
    pg: svbool_t,
    base: *const T,
    indices: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfw.gather.index.nxv2i64"
        )]
        fn _svprfw_gather_s64index(
            pg: svbool2_t,
            base: *const crate::ffi::c_void,
            indices: svint64_t,
            op: svprfop,
        );
    }
    _svprfw_gather_s64index(pg.into(), base as *const crate::ffi::c_void, indices, OP)
}
#[doc = "Prefetch doublewords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfd_gather_[s64]index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfd , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfd_gather_s64index<const OP: svprfop, T>(
    pg: svbool_t,
    base: *const T,
    indices: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfd.gather.index.nxv2i64"
        )]
        fn _svprfd_gather_s64index(
            pg: svbool2_t,
            base: *const crate::ffi::c_void,
            indices: svint64_t,
            op: svprfop,
        );
    }
    _svprfd_gather_s64index(pg.into(), base as *const crate::ffi::c_void, indices, OP)
}
#[doc = "Prefetch bytes"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfb_gather_[u32]offset)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfb_gather_u32offset<const OP: svprfop, T>(
    pg: svbool_t,
    base: *const T,
    offsets: svuint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfb.gather.uxtw.index.nxv4i32"
        )]
        fn _svprfb_gather_u32offset(
            pg: svbool4_t,
            base: *const crate::ffi::c_void,
            offsets: svint32_t,
            op: svprfop,
        );
    }
    _svprfb_gather_u32offset(
        pg.into(),
        base as *const crate::ffi::c_void,
        offsets.as_signed(),
        OP,
    )
}
#[doc = "Prefetch halfwords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfh_gather_[u32]index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfh , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfh_gather_u32index<const OP: svprfop, T>(
    pg: svbool_t,
    base: *const T,
    indices: svuint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfh.gather.uxtw.index.nxv4i32"
        )]
        fn _svprfh_gather_u32index(
            pg: svbool4_t,
            base: *const crate::ffi::c_void,
            indices: svint32_t,
            op: svprfop,
        );
    }
    _svprfh_gather_u32index(
        pg.into(),
        base as *const crate::ffi::c_void,
        indices.as_signed(),
        OP,
    )
}
#[doc = "Prefetch words"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfw_gather_[u32]index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfw , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfw_gather_u32index<const OP: svprfop, T>(
    pg: svbool_t,
    base: *const T,
    indices: svuint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfw.gather.uxtw.index.nxv4i32"
        )]
        fn _svprfw_gather_u32index(
            pg: svbool4_t,
            base: *const crate::ffi::c_void,
            indices: svint32_t,
            op: svprfop,
        );
    }
    _svprfw_gather_u32index(
        pg.into(),
        base as *const crate::ffi::c_void,
        indices.as_signed(),
        OP,
    )
}
#[doc = "Prefetch doublewords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfd_gather_[u32]index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfd , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfd_gather_u32index<const OP: svprfop, T>(
    pg: svbool_t,
    base: *const T,
    indices: svuint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfd.gather.uxtw.index.nxv4i32"
        )]
        fn _svprfd_gather_u32index(
            pg: svbool4_t,
            base: *const crate::ffi::c_void,
            indices: svint32_t,
            op: svprfop,
        );
    }
    _svprfd_gather_u32index(
        pg.into(),
        base as *const crate::ffi::c_void,
        indices.as_signed(),
        OP,
    )
}
#[doc = "Prefetch bytes"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfb_gather_[u64]offset)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfb_gather_u64offset<const OP: svprfop, T>(
    pg: svbool_t,
    base: *const T,
    offsets: svuint64_t,
) {
    svprfb_gather_s64offset::<OP, T>(pg, base, offsets.as_signed())
}
#[doc = "Prefetch halfwords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfh_gather_[u64]index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfh , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfh_gather_u64index<const OP: svprfop, T>(
    pg: svbool_t,
    base: *const T,
    indices: svuint64_t,
) {
    svprfh_gather_s64index::<OP, T>(pg, base, indices.as_signed())
}
#[doc = "Prefetch words"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfw_gather_[u64]index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfw , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfw_gather_u64index<const OP: svprfop, T>(
    pg: svbool_t,
    base: *const T,
    indices: svuint64_t,
) {
    svprfw_gather_s64index::<OP, T>(pg, base, indices.as_signed())
}
#[doc = "Prefetch doublewords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfd_gather_[u64]index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfd , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfd_gather_u64index<const OP: svprfop, T>(
    pg: svbool_t,
    base: *const T,
    indices: svuint64_t,
) {
    svprfd_gather_s64index::<OP, T>(pg, base, indices.as_signed())
}
#[doc = "Prefetch bytes"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfb_gather[_u32base])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfb_gather_u32base<const OP: svprfop>(pg: svbool_t, bases: svuint32_t) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfb.gather.scalar.offset.nxv4i32"
        )]
        fn _svprfb_gather_u32base(pg: svbool4_t, bases: svint32_t, index: i64, op: svprfop);
    }
    _svprfb_gather_u32base(pg.into(), bases.as_signed(), 0, OP)
}
#[doc = "Prefetch halfwords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfh_gather[_u32base])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfh , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfh_gather_u32base<const OP: svprfop>(pg: svbool_t, bases: svuint32_t) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfh.gather.scalar.offset.nxv4i32"
        )]
        fn _svprfh_gather_u32base(pg: svbool4_t, bases: svint32_t, index: i64, op: svprfop);
    }
    _svprfh_gather_u32base(pg.into(), bases.as_signed(), 0, OP)
}
#[doc = "Prefetch words"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfw_gather[_u32base])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfw , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfw_gather_u32base<const OP: svprfop>(pg: svbool_t, bases: svuint32_t) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfw.gather.scalar.offset.nxv4i32"
        )]
        fn _svprfw_gather_u32base(pg: svbool4_t, bases: svint32_t, index: i64, op: svprfop);
    }
    _svprfw_gather_u32base(pg.into(), bases.as_signed(), 0, OP)
}
#[doc = "Prefetch doublewords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfd_gather[_u32base])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfd , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfd_gather_u32base<const OP: svprfop>(pg: svbool_t, bases: svuint32_t) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfd.gather.scalar.offset.nxv4i32"
        )]
        fn _svprfd_gather_u32base(pg: svbool4_t, bases: svint32_t, index: i64, op: svprfop);
    }
    _svprfd_gather_u32base(pg.into(), bases.as_signed(), 0, OP)
}
#[doc = "Prefetch bytes"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfb_gather[_u64base])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfb_gather_u64base<const OP: svprfop>(pg: svbool_t, bases: svuint64_t) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfb.gather.scalar.offset.nxv2i64"
        )]
        fn _svprfb_gather_u64base(pg: svbool2_t, bases: svint64_t, index: i64, op: svprfop);
    }
    _svprfb_gather_u64base(pg.into(), bases.as_signed(), 0, OP)
}
#[doc = "Prefetch halfwords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfh_gather[_u64base])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfh , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfh_gather_u64base<const OP: svprfop>(pg: svbool_t, bases: svuint64_t) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfh.gather.scalar.offset.nxv2i64"
        )]
        fn _svprfh_gather_u64base(pg: svbool2_t, bases: svint64_t, index: i64, op: svprfop);
    }
    _svprfh_gather_u64base(pg.into(), bases.as_signed(), 0, OP)
}
#[doc = "Prefetch words"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfw_gather[_u64base])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfw , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfw_gather_u64base<const OP: svprfop>(pg: svbool_t, bases: svuint64_t) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfw.gather.scalar.offset.nxv2i64"
        )]
        fn _svprfw_gather_u64base(pg: svbool2_t, bases: svint64_t, index: i64, op: svprfop);
    }
    _svprfw_gather_u64base(pg.into(), bases.as_signed(), 0, OP)
}
#[doc = "Prefetch doublewords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfd_gather[_u64base])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfd , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfd_gather_u64base<const OP: svprfop>(pg: svbool_t, bases: svuint64_t) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfd.gather.scalar.offset.nxv2i64"
        )]
        fn _svprfd_gather_u64base(pg: svbool2_t, bases: svint64_t, index: i64, op: svprfop);
    }
    _svprfd_gather_u64base(pg.into(), bases.as_signed(), 0, OP)
}
#[doc = "Prefetch bytes"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfb_gather[_u32base]_offset)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfb_gather_u32base_offset<const OP: svprfop>(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfb.gather.scalar.offset.nxv4i32"
        )]
        fn _svprfb_gather_u32base_offset(pg: svbool4_t, bases: svint32_t, offset: i64, op: svprfop);
    }
    _svprfb_gather_u32base_offset(pg.into(), bases.as_signed(), offset, OP)
}
#[doc = "Prefetch halfwords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfh_gather[_u32base]_index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfh_gather_u32base_index<const OP: svprfop>(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfh.gather.scalar.offset.nxv4i32"
        )]
        fn _svprfh_gather_u32base_index(pg: svbool4_t, bases: svint32_t, index: i64, op: svprfop);
    }
    _svprfh_gather_u32base_index(pg.into(), bases.as_signed(), index.unchecked_shl(1), OP)
}
#[doc = "Prefetch words"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfw_gather[_u32base]_index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfw_gather_u32base_index<const OP: svprfop>(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfw.gather.scalar.offset.nxv4i32"
        )]
        fn _svprfw_gather_u32base_index(pg: svbool4_t, bases: svint32_t, index: i64, op: svprfop);
    }
    _svprfw_gather_u32base_index(pg.into(), bases.as_signed(), index.unchecked_shl(2), OP)
}
#[doc = "Prefetch doublewords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfd_gather[_u32base]_index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfd_gather_u32base_index<const OP: svprfop>(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfd.gather.scalar.offset.nxv4i32"
        )]
        fn _svprfd_gather_u32base_index(pg: svbool4_t, bases: svint32_t, index: i64, op: svprfop);
    }
    _svprfd_gather_u32base_index(pg.into(), bases.as_signed(), index.unchecked_shl(3), OP)
}
#[doc = "Prefetch bytes"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfb_gather[_u64base]_offset)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfb_gather_u64base_offset<const OP: svprfop>(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfb.gather.scalar.offset.nxv2i64"
        )]
        fn _svprfb_gather_u64base_offset(pg: svbool2_t, bases: svint64_t, offset: i64, op: svprfop);
    }
    _svprfb_gather_u64base_offset(pg.into(), bases.as_signed(), offset, OP)
}
#[doc = "Prefetch halfwords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfh_gather[_u64base]_index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfh_gather_u64base_index<const OP: svprfop>(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfh.gather.scalar.offset.nxv2i64"
        )]
        fn _svprfh_gather_u64base_index(pg: svbool2_t, bases: svint64_t, index: i64, op: svprfop);
    }
    _svprfh_gather_u64base_index(pg.into(), bases.as_signed(), index.unchecked_shl(1), OP)
}
#[doc = "Prefetch words"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfw_gather[_u64base]_index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfw_gather_u64base_index<const OP: svprfop>(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfw.gather.scalar.offset.nxv2i64"
        )]
        fn _svprfw_gather_u64base_index(pg: svbool2_t, bases: svint64_t, index: i64, op: svprfop);
    }
    _svprfw_gather_u64base_index(pg.into(), bases.as_signed(), index.unchecked_shl(2), OP)
}
#[doc = "Prefetch doublewords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfd_gather[_u64base]_index)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP }))]
pub unsafe fn svprfd_gather_u64base_index<const OP: svprfop>(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.prfd.gather.scalar.offset.nxv2i64"
        )]
        fn _svprfd_gather_u64base_index(pg: svbool2_t, bases: svint64_t, index: i64, op: svprfop);
    }
    _svprfd_gather_u64base_index(pg.into(), bases.as_signed(), index.unchecked_shl(3), OP)
}
#[doc = "Prefetch bytes"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfb_vnum)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfb , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfb_vnum<const OP: svprfop, T>(pg: svbool_t, base: *const T, vnum: i64) {
    svprfb::<OP, _>(pg, base.offset(svcntb() as isize * vnum as isize))
}
#[doc = "Prefetch halfwords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfh_vnum)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfh , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfh_vnum<const OP: svprfop, T>(pg: svbool_t, base: *const T, vnum: i64) {
    svprfh::<OP, _>(pg, base.offset(svcnth() as isize * vnum as isize))
}
#[doc = "Prefetch words"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfw_vnum)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfw , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfw_vnum<const OP: svprfop, T>(pg: svbool_t, base: *const T, vnum: i64) {
    svprfw::<OP, _>(pg, base.offset(svcntw() as isize * vnum as isize))
}
#[doc = "Prefetch doublewords"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svprfd_vnum)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (prfd , OP = { svprfop :: SV_PLDL1KEEP } , T = i64))]
pub unsafe fn svprfd_vnum<const OP: svprfop, T>(pg: svbool_t, base: *const T, vnum: i64) {
    svprfd::<OP, _>(pg, base.offset(svcntd() as isize * vnum as isize))
}
#[doc = "Test whether any active element is true"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svptest_any)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ptest))]
pub fn svptest_any(pg: svbool_t, op: svbool_t) -> bool {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ptest.any.nxv16i1"
        )]
        fn _svptest_any(pg: svbool_t, op: svbool_t) -> bool;
    }
    unsafe { _svptest_any(pg, op) }
}
#[doc = "Test whether first active element is true"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svptest_first)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ptest))]
pub fn svptest_first(pg: svbool_t, op: svbool_t) -> bool {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ptest.first.nxv16i1"
        )]
        fn _svptest_first(pg: svbool_t, op: svbool_t) -> bool;
    }
    unsafe { _svptest_first(pg, op) }
}
#[doc = "Test whether last active element is true"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svptest_last)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ptest))]
pub fn svptest_last(pg: svbool_t, op: svbool_t) -> bool {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ptest.last.nxv16i1"
        )]
        fn _svptest_last(pg: svbool_t, op: svbool_t) -> bool;
    }
    unsafe { _svptest_last(pg, op) }
}
#[doc = "Set predicate elements to true"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svptrue_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ptrue))]
pub fn svptrue_b8() -> svbool_t {
    svptrue_pat_b8::<{ svpattern::SV_ALL }>()
}
#[doc = "Set predicate elements to true"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svptrue_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ptrue))]
pub fn svptrue_b16() -> svbool_t {
    svptrue_pat_b16::<{ svpattern::SV_ALL }>()
}
#[doc = "Set predicate elements to true"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svptrue_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ptrue))]
pub fn svptrue_b32() -> svbool_t {
    svptrue_pat_b32::<{ svpattern::SV_ALL }>()
}
#[doc = "Set predicate elements to true"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svptrue_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ptrue))]
pub fn svptrue_b64() -> svbool_t {
    svptrue_pat_b64::<{ svpattern::SV_ALL }>()
}
#[doc = "Set predicate elements to true"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svptrue_pat_b8)"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (ptrue , PATTERN = { svpattern :: SV_ALL }))]
pub fn svptrue_pat_b8<const PATTERN: svpattern>() -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ptrue.nxv16i1")]
        fn _svptrue_pat_b8(pattern: svpattern) -> svbool_t;
    }
    unsafe { _svptrue_pat_b8(PATTERN) }
}
#[doc = "Set predicate elements to true"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svptrue_pat_b16)"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (ptrue , PATTERN = { svpattern :: SV_ALL }))]
pub fn svptrue_pat_b16<const PATTERN: svpattern>() -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ptrue.nxv8i1")]
        fn _svptrue_pat_b16(pattern: svpattern) -> svbool8_t;
    }
    unsafe { _svptrue_pat_b16(PATTERN).into() }
}
#[doc = "Set predicate elements to true"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svptrue_pat_b32)"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (ptrue , PATTERN = { svpattern :: SV_ALL }))]
pub fn svptrue_pat_b32<const PATTERN: svpattern>() -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ptrue.nxv4i1")]
        fn _svptrue_pat_b32(pattern: svpattern) -> svbool4_t;
    }
    unsafe { _svptrue_pat_b32(PATTERN).into() }
}
#[doc = "Set predicate elements to true"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svptrue_pat_b64)"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (ptrue , PATTERN = { svpattern :: SV_ALL }))]
pub fn svptrue_pat_b64<const PATTERN: svpattern>() -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.ptrue.nxv2i1")]
        fn _svptrue_pat_b64(pattern: svpattern) -> svbool2_t;
    }
    unsafe { _svptrue_pat_b64(PATTERN).into() }
}
#[doc = "Saturating add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqadd[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqadd))]
pub fn svqadd_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqadd.x.nxv16i8"
        )]
        fn _svqadd_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svqadd_s8(op1, op2) }
}
#[doc = "Saturating add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqadd[_n_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqadd))]
pub fn svqadd_n_s8(op1: svint8_t, op2: i8) -> svint8_t {
    svqadd_s8(op1, svdup_n_s8(op2))
}
#[doc = "Saturating add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqadd[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqadd))]
pub fn svqadd_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqadd.x.nxv8i16"
        )]
        fn _svqadd_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svqadd_s16(op1, op2) }
}
#[doc = "Saturating add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqadd[_n_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqadd))]
pub fn svqadd_n_s16(op1: svint16_t, op2: i16) -> svint16_t {
    svqadd_s16(op1, svdup_n_s16(op2))
}
#[doc = "Saturating add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqadd[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqadd))]
pub fn svqadd_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqadd.x.nxv4i32"
        )]
        fn _svqadd_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svqadd_s32(op1, op2) }
}
#[doc = "Saturating add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqadd[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqadd))]
pub fn svqadd_n_s32(op1: svint32_t, op2: i32) -> svint32_t {
    svqadd_s32(op1, svdup_n_s32(op2))
}
#[doc = "Saturating add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqadd[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqadd))]
pub fn svqadd_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqadd.x.nxv2i64"
        )]
        fn _svqadd_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svqadd_s64(op1, op2) }
}
#[doc = "Saturating add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqadd[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqadd))]
pub fn svqadd_n_s64(op1: svint64_t, op2: i64) -> svint64_t {
    svqadd_s64(op1, svdup_n_s64(op2))
}
#[doc = "Saturating add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqadd[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqadd))]
pub fn svqadd_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqadd.x.nxv16i8"
        )]
        fn _svqadd_u8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svqadd_u8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Saturating add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqadd[_n_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqadd))]
pub fn svqadd_n_u8(op1: svuint8_t, op2: u8) -> svuint8_t {
    svqadd_u8(op1, svdup_n_u8(op2))
}
#[doc = "Saturating add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqadd[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqadd))]
pub fn svqadd_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqadd.x.nxv8i16"
        )]
        fn _svqadd_u16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svqadd_u16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Saturating add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqadd[_n_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqadd))]
pub fn svqadd_n_u16(op1: svuint16_t, op2: u16) -> svuint16_t {
    svqadd_u16(op1, svdup_n_u16(op2))
}
#[doc = "Saturating add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqadd[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqadd))]
pub fn svqadd_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqadd.x.nxv4i32"
        )]
        fn _svqadd_u32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svqadd_u32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Saturating add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqadd[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqadd))]
pub fn svqadd_n_u32(op1: svuint32_t, op2: u32) -> svuint32_t {
    svqadd_u32(op1, svdup_n_u32(op2))
}
#[doc = "Saturating add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqadd[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqadd))]
pub fn svqadd_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqadd.x.nxv2i64"
        )]
        fn _svqadd_u64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svqadd_u64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Saturating add"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqadd[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqadd))]
pub fn svqadd_n_u64(op1: svuint64_t, op2: u64) -> svuint64_t {
    svqadd_u64(op1, svdup_n_u64(op2))
}
#[doc = "Saturating decrement by number of byte elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecb[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecb, IMM_FACTOR = 1))]
pub fn svqdecb_n_s32<const IMM_FACTOR: i32>(op: i32) -> i32 {
    svqdecb_pat_n_s32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdech[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdech, IMM_FACTOR = 1))]
pub fn svqdech_n_s32<const IMM_FACTOR: i32>(op: i32) -> i32 {
    svqdech_pat_n_s32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecw[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecw, IMM_FACTOR = 1))]
pub fn svqdecw_n_s32<const IMM_FACTOR: i32>(op: i32) -> i32 {
    svqdecw_pat_n_s32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecd[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecd, IMM_FACTOR = 1))]
pub fn svqdecd_n_s32<const IMM_FACTOR: i32>(op: i32) -> i32 {
    svqdecd_pat_n_s32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of byte elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecb[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecb, IMM_FACTOR = 1))]
pub fn svqdecb_n_s64<const IMM_FACTOR: i32>(op: i64) -> i64 {
    svqdecb_pat_n_s64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdech[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdech, IMM_FACTOR = 1))]
pub fn svqdech_n_s64<const IMM_FACTOR: i32>(op: i64) -> i64 {
    svqdech_pat_n_s64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecw[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecw, IMM_FACTOR = 1))]
pub fn svqdecw_n_s64<const IMM_FACTOR: i32>(op: i64) -> i64 {
    svqdecw_pat_n_s64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecd[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecd, IMM_FACTOR = 1))]
pub fn svqdecd_n_s64<const IMM_FACTOR: i32>(op: i64) -> i64 {
    svqdecd_pat_n_s64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of byte elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecb[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecb, IMM_FACTOR = 1))]
pub fn svqdecb_n_u32<const IMM_FACTOR: i32>(op: u32) -> u32 {
    svqdecb_pat_n_u32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdech[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdech, IMM_FACTOR = 1))]
pub fn svqdech_n_u32<const IMM_FACTOR: i32>(op: u32) -> u32 {
    svqdech_pat_n_u32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecw[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecw, IMM_FACTOR = 1))]
pub fn svqdecw_n_u32<const IMM_FACTOR: i32>(op: u32) -> u32 {
    svqdecw_pat_n_u32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecd[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecd, IMM_FACTOR = 1))]
pub fn svqdecd_n_u32<const IMM_FACTOR: i32>(op: u32) -> u32 {
    svqdecd_pat_n_u32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of byte elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecb[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecb, IMM_FACTOR = 1))]
pub fn svqdecb_n_u64<const IMM_FACTOR: i32>(op: u64) -> u64 {
    svqdecb_pat_n_u64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdech[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdech, IMM_FACTOR = 1))]
pub fn svqdech_n_u64<const IMM_FACTOR: i32>(op: u64) -> u64 {
    svqdech_pat_n_u64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecw[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecw, IMM_FACTOR = 1))]
pub fn svqdecw_n_u64<const IMM_FACTOR: i32>(op: u64) -> u64 {
    svqdecw_pat_n_u64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecd[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecd, IMM_FACTOR = 1))]
pub fn svqdecd_n_u64<const IMM_FACTOR: i32>(op: u64) -> u64 {
    svqdecd_pat_n_u64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of byte elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecb_pat[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdecb , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdecb_pat_n_s32<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: i32) -> i32 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecb.n32")]
        fn _svqdecb_pat_n_s32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqdecb_pat_n_s32(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating decrement by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdech_pat[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdech , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdech_pat_n_s32<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: i32) -> i32 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdech.n32")]
        fn _svqdech_pat_n_s32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqdech_pat_n_s32(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating decrement by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecw_pat[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdecw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdecw_pat_n_s32<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: i32) -> i32 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecw.n32")]
        fn _svqdecw_pat_n_s32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqdecw_pat_n_s32(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating decrement by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecd_pat[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdecd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdecd_pat_n_s32<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: i32) -> i32 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecd.n32")]
        fn _svqdecd_pat_n_s32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqdecd_pat_n_s32(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating decrement by number of byte elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecb_pat[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdecb , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdecb_pat_n_s64<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: i64) -> i64 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecb.n64")]
        fn _svqdecb_pat_n_s64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqdecb_pat_n_s64(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating decrement by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdech_pat[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdech , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdech_pat_n_s64<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: i64) -> i64 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdech.n64")]
        fn _svqdech_pat_n_s64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqdech_pat_n_s64(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating decrement by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecw_pat[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdecw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdecw_pat_n_s64<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: i64) -> i64 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecw.n64")]
        fn _svqdecw_pat_n_s64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqdecw_pat_n_s64(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating decrement by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecd_pat[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdecd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdecd_pat_n_s64<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: i64) -> i64 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecd.n64")]
        fn _svqdecd_pat_n_s64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqdecd_pat_n_s64(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating decrement by number of byte elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecb_pat[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdecb , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdecb_pat_n_u32<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: u32) -> u32 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecb.n32")]
        fn _svqdecb_pat_n_u32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqdecb_pat_n_u32(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating decrement by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdech_pat[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdech , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdech_pat_n_u32<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: u32) -> u32 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdech.n32")]
        fn _svqdech_pat_n_u32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqdech_pat_n_u32(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating decrement by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecw_pat[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdecw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdecw_pat_n_u32<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: u32) -> u32 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecw.n32")]
        fn _svqdecw_pat_n_u32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqdecw_pat_n_u32(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating decrement by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecd_pat[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdecd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdecd_pat_n_u32<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: u32) -> u32 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecd.n32")]
        fn _svqdecd_pat_n_u32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqdecd_pat_n_u32(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating decrement by number of byte elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecb_pat[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdecb , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdecb_pat_n_u64<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: u64) -> u64 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecb.n64")]
        fn _svqdecb_pat_n_u64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqdecb_pat_n_u64(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating decrement by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdech_pat[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdech , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdech_pat_n_u64<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: u64) -> u64 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdech.n64")]
        fn _svqdech_pat_n_u64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqdech_pat_n_u64(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating decrement by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecw_pat[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdecw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdecw_pat_n_u64<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: u64) -> u64 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecw.n64")]
        fn _svqdecw_pat_n_u64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqdecw_pat_n_u64(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating decrement by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecd_pat[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdecd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdecd_pat_n_u64<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: u64) -> u64 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecd.n64")]
        fn _svqdecd_pat_n_u64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqdecd_pat_n_u64(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating decrement by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdech_pat[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdech , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdech_pat_s16<const PATTERN: svpattern, const IMM_FACTOR: i32>(
    op: svint16_t,
) -> svint16_t {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdech.nxv8i16")]
        fn _svqdech_pat_s16(op: svint16_t, pattern: svpattern, imm_factor: i32) -> svint16_t;
    }
    unsafe { _svqdech_pat_s16(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating decrement by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecw_pat[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdecw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdecw_pat_s32<const PATTERN: svpattern, const IMM_FACTOR: i32>(
    op: svint32_t,
) -> svint32_t {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecw.nxv4i32")]
        fn _svqdecw_pat_s32(op: svint32_t, pattern: svpattern, imm_factor: i32) -> svint32_t;
    }
    unsafe { _svqdecw_pat_s32(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating decrement by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecd_pat[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqdecd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdecd_pat_s64<const PATTERN: svpattern, const IMM_FACTOR: i32>(
    op: svint64_t,
) -> svint64_t {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecd.nxv2i64")]
        fn _svqdecd_pat_s64(op: svint64_t, pattern: svpattern, imm_factor: i32) -> svint64_t;
    }
    unsafe { _svqdecd_pat_s64(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating decrement by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdech_pat[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdech , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdech_pat_u16<const PATTERN: svpattern, const IMM_FACTOR: i32>(
    op: svuint16_t,
) -> svuint16_t {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdech.nxv8i16")]
        fn _svqdech_pat_u16(op: svint16_t, pattern: svpattern, imm_factor: i32) -> svint16_t;
    }
    unsafe { _svqdech_pat_u16(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating decrement by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecw_pat[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdecw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdecw_pat_u32<const PATTERN: svpattern, const IMM_FACTOR: i32>(
    op: svuint32_t,
) -> svuint32_t {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecw.nxv4i32")]
        fn _svqdecw_pat_u32(op: svint32_t, pattern: svpattern, imm_factor: i32) -> svint32_t;
    }
    unsafe { _svqdecw_pat_u32(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating decrement by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecd_pat[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqdecd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqdecd_pat_u64<const PATTERN: svpattern, const IMM_FACTOR: i32>(
    op: svuint64_t,
) -> svuint64_t {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecd.nxv2i64")]
        fn _svqdecd_pat_u64(op: svint64_t, pattern: svpattern, imm_factor: i32) -> svint64_t;
    }
    unsafe { _svqdecd_pat_u64(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating decrement by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdech[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdech, IMM_FACTOR = 1))]
pub fn svqdech_s16<const IMM_FACTOR: i32>(op: svint16_t) -> svint16_t {
    svqdech_pat_s16::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecw[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecw, IMM_FACTOR = 1))]
pub fn svqdecw_s32<const IMM_FACTOR: i32>(op: svint32_t) -> svint32_t {
    svqdecw_pat_s32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecd[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecd, IMM_FACTOR = 1))]
pub fn svqdecd_s64<const IMM_FACTOR: i32>(op: svint64_t) -> svint64_t {
    svqdecd_pat_s64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdech[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdech, IMM_FACTOR = 1))]
pub fn svqdech_u16<const IMM_FACTOR: i32>(op: svuint16_t) -> svuint16_t {
    svqdech_pat_u16::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecw[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecw, IMM_FACTOR = 1))]
pub fn svqdecw_u32<const IMM_FACTOR: i32>(op: svuint32_t) -> svuint32_t {
    svqdecw_pat_u32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecd[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecd, IMM_FACTOR = 1))]
pub fn svqdecd_u64<const IMM_FACTOR: i32>(op: svuint64_t) -> svuint64_t {
    svqdecd_pat_u64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_n_s32]_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub fn svqdecp_n_s32_b8(op: i32, pg: svbool_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqdecp.n32.nxv16i1"
        )]
        fn _svqdecp_n_s32_b8(op: i32, pg: svbool_t) -> i32;
    }
    unsafe { _svqdecp_n_s32_b8(op, pg) }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_n_s32]_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub fn svqdecp_n_s32_b16(op: i32, pg: svbool_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqdecp.n32.nxv8i1"
        )]
        fn _svqdecp_n_s32_b16(op: i32, pg: svbool8_t) -> i32;
    }
    unsafe { _svqdecp_n_s32_b16(op, pg.into()) }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_n_s32]_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub fn svqdecp_n_s32_b32(op: i32, pg: svbool_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqdecp.n32.nxv4i1"
        )]
        fn _svqdecp_n_s32_b32(op: i32, pg: svbool4_t) -> i32;
    }
    unsafe { _svqdecp_n_s32_b32(op, pg.into()) }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_n_s32]_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub fn svqdecp_n_s32_b64(op: i32, pg: svbool_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqdecp.n32.nxv2i1"
        )]
        fn _svqdecp_n_s32_b64(op: i32, pg: svbool2_t) -> i32;
    }
    unsafe { _svqdecp_n_s32_b64(op, pg.into()) }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_n_s64]_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub fn svqdecp_n_s64_b8(op: i64, pg: svbool_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqdecp.n64.nxv16i1"
        )]
        fn _svqdecp_n_s64_b8(op: i64, pg: svbool_t) -> i64;
    }
    unsafe { _svqdecp_n_s64_b8(op, pg) }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_n_s64]_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub fn svqdecp_n_s64_b16(op: i64, pg: svbool_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqdecp.n64.nxv8i1"
        )]
        fn _svqdecp_n_s64_b16(op: i64, pg: svbool8_t) -> i64;
    }
    unsafe { _svqdecp_n_s64_b16(op, pg.into()) }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_n_s64]_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub fn svqdecp_n_s64_b32(op: i64, pg: svbool_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqdecp.n64.nxv4i1"
        )]
        fn _svqdecp_n_s64_b32(op: i64, pg: svbool4_t) -> i64;
    }
    unsafe { _svqdecp_n_s64_b32(op, pg.into()) }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_n_s64]_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub fn svqdecp_n_s64_b64(op: i64, pg: svbool_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqdecp.n64.nxv2i1"
        )]
        fn _svqdecp_n_s64_b64(op: i64, pg: svbool2_t) -> i64;
    }
    unsafe { _svqdecp_n_s64_b64(op, pg.into()) }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_n_u32]_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub fn svqdecp_n_u32_b8(op: u32, pg: svbool_t) -> u32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqdecp.n32.nxv16i1"
        )]
        fn _svqdecp_n_u32_b8(op: i32, pg: svbool_t) -> i32;
    }
    unsafe { _svqdecp_n_u32_b8(op.as_signed(), pg).as_unsigned() }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_n_u32]_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub fn svqdecp_n_u32_b16(op: u32, pg: svbool_t) -> u32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqdecp.n32.nxv8i1"
        )]
        fn _svqdecp_n_u32_b16(op: i32, pg: svbool8_t) -> i32;
    }
    unsafe { _svqdecp_n_u32_b16(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_n_u32]_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub fn svqdecp_n_u32_b32(op: u32, pg: svbool_t) -> u32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqdecp.n32.nxv4i1"
        )]
        fn _svqdecp_n_u32_b32(op: i32, pg: svbool4_t) -> i32;
    }
    unsafe { _svqdecp_n_u32_b32(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_n_u32]_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub fn svqdecp_n_u32_b64(op: u32, pg: svbool_t) -> u32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqdecp.n32.nxv2i1"
        )]
        fn _svqdecp_n_u32_b64(op: i32, pg: svbool2_t) -> i32;
    }
    unsafe { _svqdecp_n_u32_b64(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_n_u64]_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub fn svqdecp_n_u64_b8(op: u64, pg: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqdecp.n64.nxv16i1"
        )]
        fn _svqdecp_n_u64_b8(op: i64, pg: svbool_t) -> i64;
    }
    unsafe { _svqdecp_n_u64_b8(op.as_signed(), pg).as_unsigned() }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_n_u64]_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub fn svqdecp_n_u64_b16(op: u64, pg: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqdecp.n64.nxv8i1"
        )]
        fn _svqdecp_n_u64_b16(op: i64, pg: svbool8_t) -> i64;
    }
    unsafe { _svqdecp_n_u64_b16(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_n_u64]_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub fn svqdecp_n_u64_b32(op: u64, pg: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqdecp.n64.nxv4i1"
        )]
        fn _svqdecp_n_u64_b32(op: i64, pg: svbool4_t) -> i64;
    }
    unsafe { _svqdecp_n_u64_b32(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_n_u64]_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub fn svqdecp_n_u64_b64(op: u64, pg: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqdecp.n64.nxv2i1"
        )]
        fn _svqdecp_n_u64_b64(op: i64, pg: svbool2_t) -> i64;
    }
    unsafe { _svqdecp_n_u64_b64(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub fn svqdecp_s16(op: svint16_t, pg: svbool_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecp.nxv8i16")]
        fn _svqdecp_s16(op: svint16_t, pg: svbool8_t) -> svint16_t;
    }
    unsafe { _svqdecp_s16(op, pg.into()) }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub fn svqdecp_s32(op: svint32_t, pg: svbool_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecp.nxv4i32")]
        fn _svqdecp_s32(op: svint32_t, pg: svbool4_t) -> svint32_t;
    }
    unsafe { _svqdecp_s32(op, pg.into()) }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqdecp))]
pub fn svqdecp_s64(op: svint64_t, pg: svbool_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqdecp.nxv2i64")]
        fn _svqdecp_s64(op: svint64_t, pg: svbool2_t) -> svint64_t;
    }
    unsafe { _svqdecp_s64(op, pg.into()) }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub fn svqdecp_u16(op: svuint16_t, pg: svbool_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecp.nxv8i16")]
        fn _svqdecp_u16(op: svint16_t, pg: svbool8_t) -> svint16_t;
    }
    unsafe { _svqdecp_u16(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub fn svqdecp_u32(op: svuint32_t, pg: svbool_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecp.nxv4i32")]
        fn _svqdecp_u32(op: svint32_t, pg: svbool4_t) -> svint32_t;
    }
    unsafe { _svqdecp_u32(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating decrement by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqdecp[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqdecp))]
pub fn svqdecp_u64(op: svuint64_t, pg: svbool_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqdecp.nxv2i64")]
        fn _svqdecp_u64(op: svint64_t, pg: svbool2_t) -> svint64_t;
    }
    unsafe { _svqdecp_u64(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating increment by number of byte elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincb[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincb, IMM_FACTOR = 1))]
pub fn svqincb_n_s32<const IMM_FACTOR: i32>(op: i32) -> i32 {
    svqincb_pat_n_s32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqinch[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqinch, IMM_FACTOR = 1))]
pub fn svqinch_n_s32<const IMM_FACTOR: i32>(op: i32) -> i32 {
    svqinch_pat_n_s32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincw[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincw, IMM_FACTOR = 1))]
pub fn svqincw_n_s32<const IMM_FACTOR: i32>(op: i32) -> i32 {
    svqincw_pat_n_s32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincd[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincd, IMM_FACTOR = 1))]
pub fn svqincd_n_s32<const IMM_FACTOR: i32>(op: i32) -> i32 {
    svqincd_pat_n_s32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of byte elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincb[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincb, IMM_FACTOR = 1))]
pub fn svqincb_n_s64<const IMM_FACTOR: i32>(op: i64) -> i64 {
    svqincb_pat_n_s64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqinch[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqinch, IMM_FACTOR = 1))]
pub fn svqinch_n_s64<const IMM_FACTOR: i32>(op: i64) -> i64 {
    svqinch_pat_n_s64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincw[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincw, IMM_FACTOR = 1))]
pub fn svqincw_n_s64<const IMM_FACTOR: i32>(op: i64) -> i64 {
    svqincw_pat_n_s64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincd[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincd, IMM_FACTOR = 1))]
pub fn svqincd_n_s64<const IMM_FACTOR: i32>(op: i64) -> i64 {
    svqincd_pat_n_s64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of byte elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincb[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincb, IMM_FACTOR = 1))]
pub fn svqincb_n_u32<const IMM_FACTOR: i32>(op: u32) -> u32 {
    svqincb_pat_n_u32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqinch[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqinch, IMM_FACTOR = 1))]
pub fn svqinch_n_u32<const IMM_FACTOR: i32>(op: u32) -> u32 {
    svqinch_pat_n_u32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincw[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincw, IMM_FACTOR = 1))]
pub fn svqincw_n_u32<const IMM_FACTOR: i32>(op: u32) -> u32 {
    svqincw_pat_n_u32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincd[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincd, IMM_FACTOR = 1))]
pub fn svqincd_n_u32<const IMM_FACTOR: i32>(op: u32) -> u32 {
    svqincd_pat_n_u32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of byte elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincb[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincb, IMM_FACTOR = 1))]
pub fn svqincb_n_u64<const IMM_FACTOR: i32>(op: u64) -> u64 {
    svqincb_pat_n_u64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqinch[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqinch, IMM_FACTOR = 1))]
pub fn svqinch_n_u64<const IMM_FACTOR: i32>(op: u64) -> u64 {
    svqinch_pat_n_u64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincw[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincw, IMM_FACTOR = 1))]
pub fn svqincw_n_u64<const IMM_FACTOR: i32>(op: u64) -> u64 {
    svqincw_pat_n_u64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincd[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincd, IMM_FACTOR = 1))]
pub fn svqincd_n_u64<const IMM_FACTOR: i32>(op: u64) -> u64 {
    svqincd_pat_n_u64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of byte elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincb_pat[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqincb , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqincb_pat_n_s32<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: i32) -> i32 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincb.n32")]
        fn _svqincb_pat_n_s32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqincb_pat_n_s32(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating increment by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqinch_pat[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqinch , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqinch_pat_n_s32<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: i32) -> i32 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqinch.n32")]
        fn _svqinch_pat_n_s32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqinch_pat_n_s32(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating increment by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincw_pat[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqincw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqincw_pat_n_s32<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: i32) -> i32 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincw.n32")]
        fn _svqincw_pat_n_s32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqincw_pat_n_s32(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating increment by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincd_pat[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqincd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqincd_pat_n_s32<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: i32) -> i32 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincd.n32")]
        fn _svqincd_pat_n_s32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqincd_pat_n_s32(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating increment by number of byte elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincb_pat[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqincb , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqincb_pat_n_s64<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: i64) -> i64 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincb.n64")]
        fn _svqincb_pat_n_s64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqincb_pat_n_s64(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating increment by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqinch_pat[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqinch , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqinch_pat_n_s64<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: i64) -> i64 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqinch.n64")]
        fn _svqinch_pat_n_s64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqinch_pat_n_s64(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating increment by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincw_pat[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqincw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqincw_pat_n_s64<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: i64) -> i64 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincw.n64")]
        fn _svqincw_pat_n_s64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqincw_pat_n_s64(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating increment by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincd_pat[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqincd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqincd_pat_n_s64<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: i64) -> i64 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincd.n64")]
        fn _svqincd_pat_n_s64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqincd_pat_n_s64(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating increment by number of byte elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincb_pat[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqincb , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqincb_pat_n_u32<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: u32) -> u32 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincb.n32")]
        fn _svqincb_pat_n_u32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqincb_pat_n_u32(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating increment by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqinch_pat[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqinch , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqinch_pat_n_u32<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: u32) -> u32 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqinch.n32")]
        fn _svqinch_pat_n_u32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqinch_pat_n_u32(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating increment by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincw_pat[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqincw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqincw_pat_n_u32<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: u32) -> u32 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincw.n32")]
        fn _svqincw_pat_n_u32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqincw_pat_n_u32(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating increment by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincd_pat[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqincd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqincd_pat_n_u32<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: u32) -> u32 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincd.n32")]
        fn _svqincd_pat_n_u32(op: i32, pattern: svpattern, imm_factor: i32) -> i32;
    }
    unsafe { _svqincd_pat_n_u32(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating increment by number of byte elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincb_pat[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqincb , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqincb_pat_n_u64<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: u64) -> u64 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincb.n64")]
        fn _svqincb_pat_n_u64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqincb_pat_n_u64(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating increment by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqinch_pat[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqinch , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqinch_pat_n_u64<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: u64) -> u64 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqinch.n64")]
        fn _svqinch_pat_n_u64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqinch_pat_n_u64(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating increment by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincw_pat[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqincw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqincw_pat_n_u64<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: u64) -> u64 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincw.n64")]
        fn _svqincw_pat_n_u64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqincw_pat_n_u64(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating increment by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincd_pat[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqincd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqincd_pat_n_u64<const PATTERN: svpattern, const IMM_FACTOR: i32>(op: u64) -> u64 {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincd.n64")]
        fn _svqincd_pat_n_u64(op: i64, pattern: svpattern, imm_factor: i32) -> i64;
    }
    unsafe { _svqincd_pat_n_u64(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating increment by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqinch_pat[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqinch , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqinch_pat_s16<const PATTERN: svpattern, const IMM_FACTOR: i32>(
    op: svint16_t,
) -> svint16_t {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqinch.nxv8i16")]
        fn _svqinch_pat_s16(op: svint16_t, pattern: svpattern, imm_factor: i32) -> svint16_t;
    }
    unsafe { _svqinch_pat_s16(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating increment by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincw_pat[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqincw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqincw_pat_s32<const PATTERN: svpattern, const IMM_FACTOR: i32>(
    op: svint32_t,
) -> svint32_t {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincw.nxv4i32")]
        fn _svqincw_pat_s32(op: svint32_t, pattern: svpattern, imm_factor: i32) -> svint32_t;
    }
    unsafe { _svqincw_pat_s32(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating increment by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincd_pat[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (sqincd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqincd_pat_s64<const PATTERN: svpattern, const IMM_FACTOR: i32>(
    op: svint64_t,
) -> svint64_t {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincd.nxv2i64")]
        fn _svqincd_pat_s64(op: svint64_t, pattern: svpattern, imm_factor: i32) -> svint64_t;
    }
    unsafe { _svqincd_pat_s64(op, PATTERN, IMM_FACTOR) }
}
#[doc = "Saturating increment by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqinch_pat[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqinch , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqinch_pat_u16<const PATTERN: svpattern, const IMM_FACTOR: i32>(
    op: svuint16_t,
) -> svuint16_t {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqinch.nxv8i16")]
        fn _svqinch_pat_u16(op: svint16_t, pattern: svpattern, imm_factor: i32) -> svint16_t;
    }
    unsafe { _svqinch_pat_u16(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating increment by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincw_pat[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqincw , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqincw_pat_u32<const PATTERN: svpattern, const IMM_FACTOR: i32>(
    op: svuint32_t,
) -> svuint32_t {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincw.nxv4i32")]
        fn _svqincw_pat_u32(op: svint32_t, pattern: svpattern, imm_factor: i32) -> svint32_t;
    }
    unsafe { _svqincw_pat_u32(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating increment by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincd_pat[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
# [cfg_attr (test , assert_instr (uqincd , PATTERN = { svpattern :: SV_ALL } , IMM_FACTOR = 1))]
pub fn svqincd_pat_u64<const PATTERN: svpattern, const IMM_FACTOR: i32>(
    op: svuint64_t,
) -> svuint64_t {
    static_assert_range!(IMM_FACTOR, 1, 16);
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincd.nxv2i64")]
        fn _svqincd_pat_u64(op: svint64_t, pattern: svpattern, imm_factor: i32) -> svint64_t;
    }
    unsafe { _svqincd_pat_u64(op.as_signed(), PATTERN, IMM_FACTOR).as_unsigned() }
}
#[doc = "Saturating increment by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqinch[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqinch, IMM_FACTOR = 1))]
pub fn svqinch_s16<const IMM_FACTOR: i32>(op: svint16_t) -> svint16_t {
    svqinch_pat_s16::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincw[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincw, IMM_FACTOR = 1))]
pub fn svqincw_s32<const IMM_FACTOR: i32>(op: svint32_t) -> svint32_t {
    svqincw_pat_s32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincd[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincd, IMM_FACTOR = 1))]
pub fn svqincd_s64<const IMM_FACTOR: i32>(op: svint64_t) -> svint64_t {
    svqincd_pat_s64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of halfword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqinch[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqinch, IMM_FACTOR = 1))]
pub fn svqinch_u16<const IMM_FACTOR: i32>(op: svuint16_t) -> svuint16_t {
    svqinch_pat_u16::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of word elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincw[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincw, IMM_FACTOR = 1))]
pub fn svqincw_u32<const IMM_FACTOR: i32>(op: svuint32_t) -> svuint32_t {
    svqincw_pat_u32::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by number of doubleword elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincd[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincd, IMM_FACTOR = 1))]
pub fn svqincd_u64<const IMM_FACTOR: i32>(op: svuint64_t) -> svuint64_t {
    svqincd_pat_u64::<{ svpattern::SV_ALL }, IMM_FACTOR>(op)
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_n_s32]_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub fn svqincp_n_s32_b8(op: i32, pg: svbool_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqincp.n32.nxv16i1"
        )]
        fn _svqincp_n_s32_b8(op: i32, pg: svbool_t) -> i32;
    }
    unsafe { _svqincp_n_s32_b8(op, pg) }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_n_s32]_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub fn svqincp_n_s32_b16(op: i32, pg: svbool_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqincp.n32.nxv8i1"
        )]
        fn _svqincp_n_s32_b16(op: i32, pg: svbool8_t) -> i32;
    }
    unsafe { _svqincp_n_s32_b16(op, pg.into()) }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_n_s32]_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub fn svqincp_n_s32_b32(op: i32, pg: svbool_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqincp.n32.nxv4i1"
        )]
        fn _svqincp_n_s32_b32(op: i32, pg: svbool4_t) -> i32;
    }
    unsafe { _svqincp_n_s32_b32(op, pg.into()) }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_n_s32]_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub fn svqincp_n_s32_b64(op: i32, pg: svbool_t) -> i32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqincp.n32.nxv2i1"
        )]
        fn _svqincp_n_s32_b64(op: i32, pg: svbool2_t) -> i32;
    }
    unsafe { _svqincp_n_s32_b64(op, pg.into()) }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_n_s64]_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub fn svqincp_n_s64_b8(op: i64, pg: svbool_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqincp.n64.nxv16i1"
        )]
        fn _svqincp_n_s64_b8(op: i64, pg: svbool_t) -> i64;
    }
    unsafe { _svqincp_n_s64_b8(op, pg) }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_n_s64]_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub fn svqincp_n_s64_b16(op: i64, pg: svbool_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqincp.n64.nxv8i1"
        )]
        fn _svqincp_n_s64_b16(op: i64, pg: svbool8_t) -> i64;
    }
    unsafe { _svqincp_n_s64_b16(op, pg.into()) }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_n_s64]_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub fn svqincp_n_s64_b32(op: i64, pg: svbool_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqincp.n64.nxv4i1"
        )]
        fn _svqincp_n_s64_b32(op: i64, pg: svbool4_t) -> i64;
    }
    unsafe { _svqincp_n_s64_b32(op, pg.into()) }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_n_s64]_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub fn svqincp_n_s64_b64(op: i64, pg: svbool_t) -> i64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqincp.n64.nxv2i1"
        )]
        fn _svqincp_n_s64_b64(op: i64, pg: svbool2_t) -> i64;
    }
    unsafe { _svqincp_n_s64_b64(op, pg.into()) }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_n_u32]_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub fn svqincp_n_u32_b8(op: u32, pg: svbool_t) -> u32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqincp.n32.nxv16i1"
        )]
        fn _svqincp_n_u32_b8(op: i32, pg: svbool_t) -> i32;
    }
    unsafe { _svqincp_n_u32_b8(op.as_signed(), pg).as_unsigned() }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_n_u32]_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub fn svqincp_n_u32_b16(op: u32, pg: svbool_t) -> u32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqincp.n32.nxv8i1"
        )]
        fn _svqincp_n_u32_b16(op: i32, pg: svbool8_t) -> i32;
    }
    unsafe { _svqincp_n_u32_b16(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_n_u32]_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub fn svqincp_n_u32_b32(op: u32, pg: svbool_t) -> u32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqincp.n32.nxv4i1"
        )]
        fn _svqincp_n_u32_b32(op: i32, pg: svbool4_t) -> i32;
    }
    unsafe { _svqincp_n_u32_b32(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_n_u32]_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub fn svqincp_n_u32_b64(op: u32, pg: svbool_t) -> u32 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqincp.n32.nxv2i1"
        )]
        fn _svqincp_n_u32_b64(op: i32, pg: svbool2_t) -> i32;
    }
    unsafe { _svqincp_n_u32_b64(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_n_u64]_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub fn svqincp_n_u64_b8(op: u64, pg: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqincp.n64.nxv16i1"
        )]
        fn _svqincp_n_u64_b8(op: i64, pg: svbool_t) -> i64;
    }
    unsafe { _svqincp_n_u64_b8(op.as_signed(), pg).as_unsigned() }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_n_u64]_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub fn svqincp_n_u64_b16(op: u64, pg: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqincp.n64.nxv8i1"
        )]
        fn _svqincp_n_u64_b16(op: i64, pg: svbool8_t) -> i64;
    }
    unsafe { _svqincp_n_u64_b16(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_n_u64]_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub fn svqincp_n_u64_b32(op: u64, pg: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqincp.n64.nxv4i1"
        )]
        fn _svqincp_n_u64_b32(op: i64, pg: svbool4_t) -> i64;
    }
    unsafe { _svqincp_n_u64_b32(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_n_u64]_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub fn svqincp_n_u64_b64(op: u64, pg: svbool_t) -> u64 {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqincp.n64.nxv2i1"
        )]
        fn _svqincp_n_u64_b64(op: i64, pg: svbool2_t) -> i64;
    }
    unsafe { _svqincp_n_u64_b64(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub fn svqincp_s16(op: svint16_t, pg: svbool_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincp.nxv8i16")]
        fn _svqincp_s16(op: svint16_t, pg: svbool8_t) -> svint16_t;
    }
    unsafe { _svqincp_s16(op, pg.into()) }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub fn svqincp_s32(op: svint32_t, pg: svbool_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincp.nxv4i32")]
        fn _svqincp_s32(op: svint32_t, pg: svbool4_t) -> svint32_t;
    }
    unsafe { _svqincp_s32(op, pg.into()) }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqincp))]
pub fn svqincp_s64(op: svint64_t, pg: svbool_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sqincp.nxv2i64")]
        fn _svqincp_s64(op: svint64_t, pg: svbool2_t) -> svint64_t;
    }
    unsafe { _svqincp_s64(op, pg.into()) }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub fn svqincp_u16(op: svuint16_t, pg: svbool_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincp.nxv8i16")]
        fn _svqincp_u16(op: svint16_t, pg: svbool8_t) -> svint16_t;
    }
    unsafe { _svqincp_u16(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub fn svqincp_u32(op: svuint32_t, pg: svbool_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincp.nxv4i32")]
        fn _svqincp_u32(op: svint32_t, pg: svbool4_t) -> svint32_t;
    }
    unsafe { _svqincp_u32(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating increment by active element count"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqincp[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqincp))]
pub fn svqincp_u64(op: svuint64_t, pg: svbool_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uqincp.nxv2i64")]
        fn _svqincp_u64(op: svint64_t, pg: svbool2_t) -> svint64_t;
    }
    unsafe { _svqincp_u64(op.as_signed(), pg.into()).as_unsigned() }
}
#[doc = "Saturating subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqsub[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqsub))]
pub fn svqsub_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqsub.x.nxv16i8"
        )]
        fn _svqsub_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svqsub_s8(op1, op2) }
}
#[doc = "Saturating subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqsub[_n_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqsub))]
pub fn svqsub_n_s8(op1: svint8_t, op2: i8) -> svint8_t {
    svqsub_s8(op1, svdup_n_s8(op2))
}
#[doc = "Saturating subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqsub[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqsub))]
pub fn svqsub_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqsub.x.nxv8i16"
        )]
        fn _svqsub_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svqsub_s16(op1, op2) }
}
#[doc = "Saturating subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqsub[_n_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqsub))]
pub fn svqsub_n_s16(op1: svint16_t, op2: i16) -> svint16_t {
    svqsub_s16(op1, svdup_n_s16(op2))
}
#[doc = "Saturating subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqsub[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqsub))]
pub fn svqsub_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqsub.x.nxv4i32"
        )]
        fn _svqsub_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svqsub_s32(op1, op2) }
}
#[doc = "Saturating subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqsub[_n_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqsub))]
pub fn svqsub_n_s32(op1: svint32_t, op2: i32) -> svint32_t {
    svqsub_s32(op1, svdup_n_s32(op2))
}
#[doc = "Saturating subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqsub[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqsub))]
pub fn svqsub_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sqsub.x.nxv2i64"
        )]
        fn _svqsub_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svqsub_s64(op1, op2) }
}
#[doc = "Saturating subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqsub[_n_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sqsub))]
pub fn svqsub_n_s64(op1: svint64_t, op2: i64) -> svint64_t {
    svqsub_s64(op1, svdup_n_s64(op2))
}
#[doc = "Saturating subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqsub[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqsub))]
pub fn svqsub_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqsub.x.nxv16i8"
        )]
        fn _svqsub_u8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svqsub_u8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Saturating subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqsub[_n_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqsub))]
pub fn svqsub_n_u8(op1: svuint8_t, op2: u8) -> svuint8_t {
    svqsub_u8(op1, svdup_n_u8(op2))
}
#[doc = "Saturating subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqsub[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqsub))]
pub fn svqsub_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqsub.x.nxv8i16"
        )]
        fn _svqsub_u16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svqsub_u16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Saturating subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqsub[_n_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqsub))]
pub fn svqsub_n_u16(op1: svuint16_t, op2: u16) -> svuint16_t {
    svqsub_u16(op1, svdup_n_u16(op2))
}
#[doc = "Saturating subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqsub[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqsub))]
pub fn svqsub_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqsub.x.nxv4i32"
        )]
        fn _svqsub_u32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svqsub_u32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Saturating subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqsub[_n_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqsub))]
pub fn svqsub_n_u32(op1: svuint32_t, op2: u32) -> svuint32_t {
    svqsub_u32(op1, svdup_n_u32(op2))
}
#[doc = "Saturating subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqsub[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqsub))]
pub fn svqsub_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.uqsub.x.nxv2i64"
        )]
        fn _svqsub_u64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svqsub_u64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Saturating subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svqsub[_n_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uqsub))]
pub fn svqsub_n_u64(op1: svuint64_t, op2: u64) -> svuint64_t {
    svqsub_u64(op1, svdup_n_u64(op2))
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rbit.nxv16i8")]
        fn _svrbit_s8_m(inactive: svint8_t, pg: svbool_t, op: svint8_t) -> svint8_t;
    }
    unsafe { _svrbit_s8_m(inactive, pg, op) }
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_s8_x(pg: svbool_t, op: svint8_t) -> svint8_t {
    svrbit_s8_m(op, pg, op)
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_s8_z(pg: svbool_t, op: svint8_t) -> svint8_t {
    svrbit_s8_m(svdup_n_s8(0), pg, op)
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_s16_m(inactive: svint16_t, pg: svbool_t, op: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rbit.nxv8i16")]
        fn _svrbit_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svrbit_s16_m(inactive, pg.into(), op) }
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_s16_x(pg: svbool_t, op: svint16_t) -> svint16_t {
    svrbit_s16_m(op, pg, op)
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_s16_z(pg: svbool_t, op: svint16_t) -> svint16_t {
    svrbit_s16_m(svdup_n_s16(0), pg, op)
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_s32_m(inactive: svint32_t, pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rbit.nxv4i32")]
        fn _svrbit_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svrbit_s32_m(inactive, pg.into(), op) }
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_s32_x(pg: svbool_t, op: svint32_t) -> svint32_t {
    svrbit_s32_m(op, pg, op)
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_s32_z(pg: svbool_t, op: svint32_t) -> svint32_t {
    svrbit_s32_m(svdup_n_s32(0), pg, op)
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rbit.nxv2i64")]
        fn _svrbit_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svrbit_s64_m(inactive, pg.into(), op) }
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svrbit_s64_m(op, pg, op)
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svrbit_s64_m(svdup_n_s64(0), pg, op)
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_u8_m(inactive: svuint8_t, pg: svbool_t, op: svuint8_t) -> svuint8_t {
    unsafe { svrbit_s8_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_u8_x(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svrbit_u8_m(op, pg, op)
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_u8_z(pg: svbool_t, op: svuint8_t) -> svuint8_t {
    svrbit_u8_m(svdup_n_u8(0), pg, op)
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_u16_m(inactive: svuint16_t, pg: svbool_t, op: svuint16_t) -> svuint16_t {
    unsafe { svrbit_s16_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_u16_x(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svrbit_u16_m(op, pg, op)
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_u16_z(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svrbit_u16_m(svdup_n_u16(0), pg, op)
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    unsafe { svrbit_s32_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svrbit_u32_m(op, pg, op)
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svrbit_u32_m(svdup_n_u32(0), pg, op)
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svrbit_s64_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svrbit_u64_m(op, pg, op)
}
#[doc = "Reverse bits"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrbit[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rbit))]
pub fn svrbit_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svrbit_u64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Read FFR, returning predicate of succesfully loaded elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrdffr)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rdffr))]
pub fn svrdffr() -> svbool_t {
    svrdffr_z(svptrue_b8())
}
#[doc = "Read FFR, returning predicate of succesfully loaded elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrdffr_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rdffr))]
pub fn svrdffr_z(pg: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rdffr.z")]
        fn _svrdffr_z(pg: svbool_t) -> svbool_t;
    }
    unsafe { _svrdffr_z(pg) }
}
#[doc = "Reciprocal estimate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrecpe[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecpe))]
pub fn svrecpe_f32(op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frecpe.x.nxv4f32"
        )]
        fn _svrecpe_f32(op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrecpe_f32(op) }
}
#[doc = "Reciprocal estimate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrecpe[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecpe))]
pub fn svrecpe_f64(op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frecpe.x.nxv2f64"
        )]
        fn _svrecpe_f64(op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrecpe_f64(op) }
}
#[doc = "Reciprocal step"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrecps[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecps))]
pub fn svrecps_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frecps.x.nxv4f32"
        )]
        fn _svrecps_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrecps_f32(op1, op2) }
}
#[doc = "Reciprocal step"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrecps[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecps))]
pub fn svrecps_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frecps.x.nxv2f64"
        )]
        fn _svrecps_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrecps_f64(op1, op2) }
}
#[doc = "Reciprocal exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrecpx[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecpx))]
pub fn svrecpx_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frecpx.x.nxv4f32"
        )]
        fn _svrecpx_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrecpx_f32_m(inactive, pg.into(), op) }
}
#[doc = "Reciprocal exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrecpx[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecpx))]
pub fn svrecpx_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrecpx_f32_m(op, pg, op)
}
#[doc = "Reciprocal exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrecpx[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecpx))]
pub fn svrecpx_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrecpx_f32_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Reciprocal exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrecpx[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecpx))]
pub fn svrecpx_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frecpx.x.nxv2f64"
        )]
        fn _svrecpx_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrecpx_f64_m(inactive, pg.into(), op) }
}
#[doc = "Reciprocal exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrecpx[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecpx))]
pub fn svrecpx_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrecpx_f64_m(op, pg, op)
}
#[doc = "Reciprocal exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrecpx[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frecpx))]
pub fn svrecpx_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrecpx_f64_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f32[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f32_f32(op: svfloat32_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f32[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f32_f64(op: svfloat64_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f32[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f32_s8(op: svint8_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f32[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f32_s16(op: svint16_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f32[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f32_s32(op: svint32_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f32[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f32_s64(op: svint64_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f32[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f32_u8(op: svuint8_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f32[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f32_u16(op: svuint16_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f32[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f32_u32(op: svuint32_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f32[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f32_u64(op: svuint64_t) -> svfloat32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f64[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f64_f32(op: svfloat32_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f64[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f64_f64(op: svfloat64_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f64[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f64_s8(op: svint8_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f64[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f64_s16(op: svint16_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f64[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f64_s32(op: svint32_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f64[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f64_s64(op: svint64_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f64[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f64_u8(op: svuint8_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f64[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f64_u16(op: svuint16_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f64[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f64_u32(op: svuint32_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_f64[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_f64_u64(op: svuint64_t) -> svfloat64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s8[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s8_f32(op: svfloat32_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s8[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s8_f64(op: svfloat64_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s8[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s8_s8(op: svint8_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s8[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s8_s16(op: svint16_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s8[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s8_s32(op: svint32_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s8[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s8_s64(op: svint64_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s8[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s8_u8(op: svuint8_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s8[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s8_u16(op: svuint16_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s8[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s8_u32(op: svuint32_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s8[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s8_u64(op: svuint64_t) -> svint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s16[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s16_f32(op: svfloat32_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s16[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s16_f64(op: svfloat64_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s16[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s16_s8(op: svint8_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s16[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s16_s16(op: svint16_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s16[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s16_s32(op: svint32_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s16[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s16_s64(op: svint64_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s16[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s16_u8(op: svuint8_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s16[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s16_u16(op: svuint16_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s16[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s16_u32(op: svuint32_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s16[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s16_u64(op: svuint64_t) -> svint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s32[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s32_f32(op: svfloat32_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s32[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s32_f64(op: svfloat64_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s32[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s32_s8(op: svint8_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s32[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s32_s16(op: svint16_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s32[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s32_s32(op: svint32_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s32[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s32_s64(op: svint64_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s32[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s32_u8(op: svuint8_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s32[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s32_u16(op: svuint16_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s32[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s32_u32(op: svuint32_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s32[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s32_u64(op: svuint64_t) -> svint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s64[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s64_f32(op: svfloat32_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s64[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s64_f64(op: svfloat64_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s64[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s64_s8(op: svint8_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s64[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s64_s16(op: svint16_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s64[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s64_s32(op: svint32_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s64[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s64_s64(op: svint64_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s64[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s64_u8(op: svuint8_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s64[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s64_u16(op: svuint16_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s64[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s64_u32(op: svuint32_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_s64[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_s64_u64(op: svuint64_t) -> svint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u8[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u8_f32(op: svfloat32_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u8[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u8_f64(op: svfloat64_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u8[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u8_s8(op: svint8_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u8[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u8_s16(op: svint16_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u8[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u8_s32(op: svint32_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u8[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u8_s64(op: svint64_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u8[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u8_u8(op: svuint8_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u8[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u8_u16(op: svuint16_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u8[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u8_u32(op: svuint32_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u8[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u8_u64(op: svuint64_t) -> svuint8_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u16[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u16_f32(op: svfloat32_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u16[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u16_f64(op: svfloat64_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u16[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u16_s8(op: svint8_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u16[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u16_s16(op: svint16_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u16[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u16_s32(op: svint32_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u16[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u16_s64(op: svint64_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u16[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u16_u8(op: svuint8_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u16[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u16_u16(op: svuint16_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u16[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u16_u32(op: svuint32_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u16[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u16_u64(op: svuint64_t) -> svuint16_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u32[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u32_f32(op: svfloat32_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u32[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u32_f64(op: svfloat64_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u32[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u32_s8(op: svint8_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u32[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u32_s16(op: svint16_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u32[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u32_s32(op: svint32_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u32[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u32_s64(op: svint64_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u32[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u32_u8(op: svuint8_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u32[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u32_u16(op: svuint16_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u32[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u32_u32(op: svuint32_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u32[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u32_u64(op: svuint64_t) -> svuint32_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u64[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u64_f32(op: svfloat32_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u64[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u64_f64(op: svfloat64_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u64[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u64_s8(op: svint8_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u64[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u64_s16(op: svint16_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u64[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u64_s32(op: svint32_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u64[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u64_s64(op: svint64_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u64[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u64_u8(op: svuint8_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u64[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u64_u16(op: svuint16_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u64[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u64_u32(op: svuint32_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reinterpret vector contents"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svreinterpret_u64[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svreinterpret_u64_u64(op: svuint64_t) -> svuint64_t {
    unsafe { simd_reinterpret(op) }
}
#[doc = "Reverse all elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrev_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub fn svrev_b8(op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv16i1")]
        fn _svrev_b8(op: svbool_t) -> svbool_t;
    }
    unsafe { _svrev_b8(op) }
}
#[doc = "Reverse all elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrev_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub fn svrev_b16(op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv8i1")]
        fn _svrev_b16(op: svbool8_t) -> svbool8_t;
    }
    unsafe { _svrev_b16(op.into()).into() }
}
#[doc = "Reverse all elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrev_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub fn svrev_b32(op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv4i1")]
        fn _svrev_b32(op: svbool4_t) -> svbool4_t;
    }
    unsafe { _svrev_b32(op.into()).into() }
}
#[doc = "Reverse all elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrev_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub fn svrev_b64(op: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv2i1")]
        fn _svrev_b64(op: svbool2_t) -> svbool2_t;
    }
    unsafe { _svrev_b64(op.into()).into() }
}
#[doc = "Reverse all elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrev[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub fn svrev_f32(op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv4f32")]
        fn _svrev_f32(op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrev_f32(op) }
}
#[doc = "Reverse all elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrev[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub fn svrev_f64(op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv2f64")]
        fn _svrev_f64(op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrev_f64(op) }
}
#[doc = "Reverse all elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrev[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub fn svrev_s8(op: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv16i8")]
        fn _svrev_s8(op: svint8_t) -> svint8_t;
    }
    unsafe { _svrev_s8(op) }
}
#[doc = "Reverse all elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrev[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub fn svrev_s16(op: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv8i16")]
        fn _svrev_s16(op: svint16_t) -> svint16_t;
    }
    unsafe { _svrev_s16(op) }
}
#[doc = "Reverse all elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrev[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub fn svrev_s32(op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv4i32")]
        fn _svrev_s32(op: svint32_t) -> svint32_t;
    }
    unsafe { _svrev_s32(op) }
}
#[doc = "Reverse all elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrev[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub fn svrev_s64(op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.rev.nxv2i64")]
        fn _svrev_s64(op: svint64_t) -> svint64_t;
    }
    unsafe { _svrev_s64(op) }
}
#[doc = "Reverse all elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrev[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub fn svrev_u8(op: svuint8_t) -> svuint8_t {
    unsafe { svrev_s8(op.as_signed()).as_unsigned() }
}
#[doc = "Reverse all elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrev[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub fn svrev_u16(op: svuint16_t) -> svuint16_t {
    unsafe { svrev_s16(op.as_signed()).as_unsigned() }
}
#[doc = "Reverse all elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrev[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub fn svrev_u32(op: svuint32_t) -> svuint32_t {
    unsafe { svrev_s32(op.as_signed()).as_unsigned() }
}
#[doc = "Reverse all elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrev[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(rev))]
pub fn svrev_u64(op: svuint64_t) -> svuint64_t {
    unsafe { svrev_s64(op.as_signed()).as_unsigned() }
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_s16_m(inactive: svint16_t, pg: svbool_t, op: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.revb.nxv8i16")]
        fn _svrevb_s16_m(inactive: svint16_t, pg: svbool8_t, op: svint16_t) -> svint16_t;
    }
    unsafe { _svrevb_s16_m(inactive, pg.into(), op) }
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_s16_x(pg: svbool_t, op: svint16_t) -> svint16_t {
    svrevb_s16_m(op, pg, op)
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_s16_z(pg: svbool_t, op: svint16_t) -> svint16_t {
    svrevb_s16_m(svdup_n_s16(0), pg, op)
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_s32_m(inactive: svint32_t, pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.revb.nxv4i32")]
        fn _svrevb_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svrevb_s32_m(inactive, pg.into(), op) }
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_s32_x(pg: svbool_t, op: svint32_t) -> svint32_t {
    svrevb_s32_m(op, pg, op)
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_s32_z(pg: svbool_t, op: svint32_t) -> svint32_t {
    svrevb_s32_m(svdup_n_s32(0), pg, op)
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.revb.nxv2i64")]
        fn _svrevb_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svrevb_s64_m(inactive, pg.into(), op) }
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svrevb_s64_m(op, pg, op)
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svrevb_s64_m(svdup_n_s64(0), pg, op)
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_u16_m(inactive: svuint16_t, pg: svbool_t, op: svuint16_t) -> svuint16_t {
    unsafe { svrevb_s16_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_u16_x(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svrevb_u16_m(op, pg, op)
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_u16_z(pg: svbool_t, op: svuint16_t) -> svuint16_t {
    svrevb_u16_m(svdup_n_u16(0), pg, op)
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    unsafe { svrevb_s32_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svrevb_u32_m(op, pg, op)
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svrevb_u32_m(svdup_n_u32(0), pg, op)
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svrevb_s64_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svrevb_u64_m(op, pg, op)
}
#[doc = "Reverse bytes within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevb[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revb))]
pub fn svrevb_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svrevb_u64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Reverse halfwords within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevh[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub fn svrevh_s32_m(inactive: svint32_t, pg: svbool_t, op: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.revh.nxv4i32")]
        fn _svrevh_s32_m(inactive: svint32_t, pg: svbool4_t, op: svint32_t) -> svint32_t;
    }
    unsafe { _svrevh_s32_m(inactive, pg.into(), op) }
}
#[doc = "Reverse halfwords within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevh[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub fn svrevh_s32_x(pg: svbool_t, op: svint32_t) -> svint32_t {
    svrevh_s32_m(op, pg, op)
}
#[doc = "Reverse halfwords within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevh[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub fn svrevh_s32_z(pg: svbool_t, op: svint32_t) -> svint32_t {
    svrevh_s32_m(svdup_n_s32(0), pg, op)
}
#[doc = "Reverse halfwords within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevh[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub fn svrevh_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.revh.nxv2i64")]
        fn _svrevh_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svrevh_s64_m(inactive, pg.into(), op) }
}
#[doc = "Reverse halfwords within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevh[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub fn svrevh_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svrevh_s64_m(op, pg, op)
}
#[doc = "Reverse halfwords within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevh[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub fn svrevh_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svrevh_s64_m(svdup_n_s64(0), pg, op)
}
#[doc = "Reverse halfwords within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevh[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub fn svrevh_u32_m(inactive: svuint32_t, pg: svbool_t, op: svuint32_t) -> svuint32_t {
    unsafe { svrevh_s32_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Reverse halfwords within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevh[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub fn svrevh_u32_x(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svrevh_u32_m(op, pg, op)
}
#[doc = "Reverse halfwords within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevh[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub fn svrevh_u32_z(pg: svbool_t, op: svuint32_t) -> svuint32_t {
    svrevh_u32_m(svdup_n_u32(0), pg, op)
}
#[doc = "Reverse halfwords within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevh[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub fn svrevh_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svrevh_s64_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Reverse halfwords within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevh[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub fn svrevh_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svrevh_u64_m(op, pg, op)
}
#[doc = "Reverse halfwords within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevh[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revh))]
pub fn svrevh_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svrevh_u64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Reverse words within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevw[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revw))]
pub fn svrevw_s64_m(inactive: svint64_t, pg: svbool_t, op: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.revw.nxv2i64")]
        fn _svrevw_s64_m(inactive: svint64_t, pg: svbool2_t, op: svint64_t) -> svint64_t;
    }
    unsafe { _svrevw_s64_m(inactive, pg.into(), op) }
}
#[doc = "Reverse words within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevw[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revw))]
pub fn svrevw_s64_x(pg: svbool_t, op: svint64_t) -> svint64_t {
    svrevw_s64_m(op, pg, op)
}
#[doc = "Reverse words within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevw[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revw))]
pub fn svrevw_s64_z(pg: svbool_t, op: svint64_t) -> svint64_t {
    svrevw_s64_m(svdup_n_s64(0), pg, op)
}
#[doc = "Reverse words within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevw[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revw))]
pub fn svrevw_u64_m(inactive: svuint64_t, pg: svbool_t, op: svuint64_t) -> svuint64_t {
    unsafe { svrevw_s64_m(inactive.as_signed(), pg, op.as_signed()).as_unsigned() }
}
#[doc = "Reverse words within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevw[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revw))]
pub fn svrevw_u64_x(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svrevw_u64_m(op, pg, op)
}
#[doc = "Reverse words within elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrevw[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(revw))]
pub fn svrevw_u64_z(pg: svbool_t, op: svuint64_t) -> svuint64_t {
    svrevw_u64_m(svdup_n_u64(0), pg, op)
}
#[doc = "Round to nearest, ties away from zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrinta[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinta))]
pub fn svrinta_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frinta.nxv4f32")]
        fn _svrinta_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrinta_f32_m(inactive, pg.into(), op) }
}
#[doc = "Round to nearest, ties away from zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrinta[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinta))]
pub fn svrinta_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrinta_f32_m(op, pg, op)
}
#[doc = "Round to nearest, ties away from zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrinta[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinta))]
pub fn svrinta_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrinta_f32_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Round to nearest, ties away from zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrinta[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinta))]
pub fn svrinta_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frinta.nxv2f64")]
        fn _svrinta_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrinta_f64_m(inactive, pg.into(), op) }
}
#[doc = "Round to nearest, ties away from zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrinta[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinta))]
pub fn svrinta_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrinta_f64_m(op, pg, op)
}
#[doc = "Round to nearest, ties away from zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrinta[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinta))]
pub fn svrinta_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrinta_f64_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Round using current rounding mode (inexact)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrinti[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinti))]
pub fn svrinti_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frinti.nxv4f32")]
        fn _svrinti_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrinti_f32_m(inactive, pg.into(), op) }
}
#[doc = "Round using current rounding mode (inexact)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrinti[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinti))]
pub fn svrinti_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrinti_f32_m(op, pg, op)
}
#[doc = "Round using current rounding mode (inexact)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrinti[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinti))]
pub fn svrinti_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrinti_f32_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Round using current rounding mode (inexact)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrinti[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinti))]
pub fn svrinti_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frinti.nxv2f64")]
        fn _svrinti_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrinti_f64_m(inactive, pg.into(), op) }
}
#[doc = "Round using current rounding mode (inexact)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrinti[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinti))]
pub fn svrinti_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrinti_f64_m(op, pg, op)
}
#[doc = "Round using current rounding mode (inexact)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrinti[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frinti))]
pub fn svrinti_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrinti_f64_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Round towards -∞"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintm[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintm))]
pub fn svrintm_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintm.nxv4f32")]
        fn _svrintm_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrintm_f32_m(inactive, pg.into(), op) }
}
#[doc = "Round towards -∞"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintm[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintm))]
pub fn svrintm_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintm_f32_m(op, pg, op)
}
#[doc = "Round towards -∞"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintm[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintm))]
pub fn svrintm_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintm_f32_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Round towards -∞"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintm[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintm))]
pub fn svrintm_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintm.nxv2f64")]
        fn _svrintm_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrintm_f64_m(inactive, pg.into(), op) }
}
#[doc = "Round towards -∞"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintm[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintm))]
pub fn svrintm_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintm_f64_m(op, pg, op)
}
#[doc = "Round towards -∞"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintm[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintm))]
pub fn svrintm_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintm_f64_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Round to nearest, ties to even"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintn[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintn))]
pub fn svrintn_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintn.nxv4f32")]
        fn _svrintn_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrintn_f32_m(inactive, pg.into(), op) }
}
#[doc = "Round to nearest, ties to even"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintn[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintn))]
pub fn svrintn_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintn_f32_m(op, pg, op)
}
#[doc = "Round to nearest, ties to even"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintn[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintn))]
pub fn svrintn_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintn_f32_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Round to nearest, ties to even"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintn[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintn))]
pub fn svrintn_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintn.nxv2f64")]
        fn _svrintn_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrintn_f64_m(inactive, pg.into(), op) }
}
#[doc = "Round to nearest, ties to even"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintn[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintn))]
pub fn svrintn_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintn_f64_m(op, pg, op)
}
#[doc = "Round to nearest, ties to even"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintn[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintn))]
pub fn svrintn_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintn_f64_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Round towards +∞"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintp[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintp))]
pub fn svrintp_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintp.nxv4f32")]
        fn _svrintp_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrintp_f32_m(inactive, pg.into(), op) }
}
#[doc = "Round towards +∞"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintp[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintp))]
pub fn svrintp_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintp_f32_m(op, pg, op)
}
#[doc = "Round towards +∞"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintp[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintp))]
pub fn svrintp_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintp_f32_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Round towards +∞"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintp[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintp))]
pub fn svrintp_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintp.nxv2f64")]
        fn _svrintp_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrintp_f64_m(inactive, pg.into(), op) }
}
#[doc = "Round towards +∞"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintp[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintp))]
pub fn svrintp_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintp_f64_m(op, pg, op)
}
#[doc = "Round towards +∞"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintp[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintp))]
pub fn svrintp_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintp_f64_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Round using current rounding mode (exact)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintx[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintx))]
pub fn svrintx_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintx.nxv4f32")]
        fn _svrintx_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrintx_f32_m(inactive, pg.into(), op) }
}
#[doc = "Round using current rounding mode (exact)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintx[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintx))]
pub fn svrintx_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintx_f32_m(op, pg, op)
}
#[doc = "Round using current rounding mode (exact)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintx[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintx))]
pub fn svrintx_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintx_f32_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Round using current rounding mode (exact)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintx[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintx))]
pub fn svrintx_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintx.nxv2f64")]
        fn _svrintx_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrintx_f64_m(inactive, pg.into(), op) }
}
#[doc = "Round using current rounding mode (exact)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintx[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintx))]
pub fn svrintx_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintx_f64_m(op, pg, op)
}
#[doc = "Round using current rounding mode (exact)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintx[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintx))]
pub fn svrintx_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintx_f64_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Round towards zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintz[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintz))]
pub fn svrintz_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintz.nxv4f32")]
        fn _svrintz_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrintz_f32_m(inactive, pg.into(), op) }
}
#[doc = "Round towards zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintz[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintz))]
pub fn svrintz_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintz_f32_m(op, pg, op)
}
#[doc = "Round towards zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintz[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintz))]
pub fn svrintz_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svrintz_f32_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Round towards zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintz[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintz))]
pub fn svrintz_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.frintz.nxv2f64")]
        fn _svrintz_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrintz_f64_m(inactive, pg.into(), op) }
}
#[doc = "Round towards zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintz[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintz))]
pub fn svrintz_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintz_f64_m(op, pg, op)
}
#[doc = "Round towards zero"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrintz[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frintz))]
pub fn svrintz_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svrintz_f64_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Reciprocal square root estimate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrsqrte[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frsqrte))]
pub fn svrsqrte_f32(op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frsqrte.x.nxv4f32"
        )]
        fn _svrsqrte_f32(op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrsqrte_f32(op) }
}
#[doc = "Reciprocal square root estimate"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrsqrte[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frsqrte))]
pub fn svrsqrte_f64(op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frsqrte.x.nxv2f64"
        )]
        fn _svrsqrte_f64(op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrsqrte_f64(op) }
}
#[doc = "Reciprocal square root step"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrsqrts[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frsqrts))]
pub fn svrsqrts_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frsqrts.x.nxv4f32"
        )]
        fn _svrsqrts_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svrsqrts_f32(op1, op2) }
}
#[doc = "Reciprocal square root step"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svrsqrts[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(frsqrts))]
pub fn svrsqrts_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.frsqrts.x.nxv2f64"
        )]
        fn _svrsqrts_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svrsqrts_f64(op1, op2) }
}
#[doc = "Adjust exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svscale[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub fn svscale_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svint32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fscale.nxv4f32")]
        fn _svscale_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svint32_t) -> svfloat32_t;
    }
    unsafe { _svscale_f32_m(pg.into(), op1, op2) }
}
#[doc = "Adjust exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svscale[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub fn svscale_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: i32) -> svfloat32_t {
    svscale_f32_m(pg, op1, svdup_n_s32(op2))
}
#[doc = "Adjust exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svscale[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub fn svscale_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svint32_t) -> svfloat32_t {
    svscale_f32_m(pg, op1, op2)
}
#[doc = "Adjust exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svscale[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub fn svscale_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: i32) -> svfloat32_t {
    svscale_f32_x(pg, op1, svdup_n_s32(op2))
}
#[doc = "Adjust exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svscale[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub fn svscale_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svint32_t) -> svfloat32_t {
    svscale_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[doc = "Adjust exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svscale[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub fn svscale_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: i32) -> svfloat32_t {
    svscale_f32_z(pg, op1, svdup_n_s32(op2))
}
#[doc = "Adjust exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svscale[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub fn svscale_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svint64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fscale.nxv2f64")]
        fn _svscale_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svint64_t) -> svfloat64_t;
    }
    unsafe { _svscale_f64_m(pg.into(), op1, op2) }
}
#[doc = "Adjust exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svscale[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub fn svscale_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: i64) -> svfloat64_t {
    svscale_f64_m(pg, op1, svdup_n_s64(op2))
}
#[doc = "Adjust exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svscale[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub fn svscale_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svint64_t) -> svfloat64_t {
    svscale_f64_m(pg, op1, op2)
}
#[doc = "Adjust exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svscale[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub fn svscale_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: i64) -> svfloat64_t {
    svscale_f64_x(pg, op1, svdup_n_s64(op2))
}
#[doc = "Adjust exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svscale[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub fn svscale_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svint64_t) -> svfloat64_t {
    svscale_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[doc = "Adjust exponent"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svscale[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fscale))]
pub fn svscale_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: i64) -> svfloat64_t {
    svscale_f64_z(pg, op1, svdup_n_s64(op2))
}
#[doc = "Conditionally select elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsel[_b])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub fn svsel_b(pg: svbool_t, op1: svbool_t, op2: svbool_t) -> svbool_t {
    unsafe { simd_select(pg, op1, op2) }
}
#[doc = "Conditionally select elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsel[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub fn svsel_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    unsafe { simd_select::<svbool4_t, _>(pg.into(), op1, op2) }
}
#[doc = "Conditionally select elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsel[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub fn svsel_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    unsafe { simd_select::<svbool2_t, _>(pg.into(), op1, op2) }
}
#[doc = "Conditionally select elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsel[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub fn svsel_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    unsafe { simd_select::<svbool_t, _>(pg, op1, op2) }
}
#[doc = "Conditionally select elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsel[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub fn svsel_s16(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    unsafe { simd_select::<svbool8_t, _>(pg.into(), op1, op2) }
}
#[doc = "Conditionally select elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsel[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub fn svsel_s32(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    unsafe { simd_select::<svbool4_t, _>(pg.into(), op1, op2) }
}
#[doc = "Conditionally select elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsel[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub fn svsel_s64(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    unsafe { simd_select::<svbool2_t, _>(pg.into(), op1, op2) }
}
#[doc = "Conditionally select elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsel[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub fn svsel_u8(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { simd_select::<svbool_t, _>(pg, op1, op2) }
}
#[doc = "Conditionally select elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsel[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub fn svsel_u16(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { simd_select::<svbool8_t, _>(pg.into(), op1, op2) }
}
#[doc = "Conditionally select elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsel[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub fn svsel_u32(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { simd_select::<svbool4_t, _>(pg.into(), op1, op2) }
}
#[doc = "Conditionally select elements"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsel[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sel))]
pub fn svsel_u64(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { simd_select::<svbool2_t, _>(pg.into(), op1, op2) }
}
#[doc = "Change one vector in a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset2[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset2_f32<const IMM_INDEX: i32>(tuple: svfloat32x2_t, x: svfloat32_t) -> svfloat32x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv8f32.nxv4f32"
        )]
        fn _svset2_f32(tuple: svfloat32x2_t, imm_index: i32, x: svfloat32_t) -> svfloat32x2_t;
    }
    unsafe { _svset2_f32(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset2[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset2_f64<const IMM_INDEX: i32>(tuple: svfloat64x2_t, x: svfloat64_t) -> svfloat64x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv4f64.nxv2f64"
        )]
        fn _svset2_f64(tuple: svfloat64x2_t, imm_index: i32, x: svfloat64_t) -> svfloat64x2_t;
    }
    unsafe { _svset2_f64(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset2[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset2_s8<const IMM_INDEX: i32>(tuple: svint8x2_t, x: svint8_t) -> svint8x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv32i8.nxv16i8"
        )]
        fn _svset2_s8(tuple: svint8x2_t, imm_index: i32, x: svint8_t) -> svint8x2_t;
    }
    unsafe { _svset2_s8(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset2[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset2_s16<const IMM_INDEX: i32>(tuple: svint16x2_t, x: svint16_t) -> svint16x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv16i16.nxv8i16"
        )]
        fn _svset2_s16(tuple: svint16x2_t, imm_index: i32, x: svint16_t) -> svint16x2_t;
    }
    unsafe { _svset2_s16(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset2[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset2_s32<const IMM_INDEX: i32>(tuple: svint32x2_t, x: svint32_t) -> svint32x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv8i32.nxv4i32"
        )]
        fn _svset2_s32(tuple: svint32x2_t, imm_index: i32, x: svint32_t) -> svint32x2_t;
    }
    unsafe { _svset2_s32(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset2[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset2_s64<const IMM_INDEX: i32>(tuple: svint64x2_t, x: svint64_t) -> svint64x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv4i64.nxv2i64"
        )]
        fn _svset2_s64(tuple: svint64x2_t, imm_index: i32, x: svint64_t) -> svint64x2_t;
    }
    unsafe { _svset2_s64(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset2[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset2_u8<const IMM_INDEX: i32>(tuple: svuint8x2_t, x: svuint8_t) -> svuint8x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    unsafe { svset2_s8::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[doc = "Change one vector in a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset2[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset2_u16<const IMM_INDEX: i32>(tuple: svuint16x2_t, x: svuint16_t) -> svuint16x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    unsafe { svset2_s16::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[doc = "Change one vector in a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset2[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset2_u32<const IMM_INDEX: i32>(tuple: svuint32x2_t, x: svuint32_t) -> svuint32x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    unsafe { svset2_s32::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[doc = "Change one vector in a tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset2[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset2_u64<const IMM_INDEX: i32>(tuple: svuint64x2_t, x: svuint64_t) -> svuint64x2_t {
    static_assert_range!(IMM_INDEX, 0, 1);
    unsafe { svset2_s64::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[doc = "Change one vector in a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset3[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset3_f32<const IMM_INDEX: i32>(tuple: svfloat32x3_t, x: svfloat32_t) -> svfloat32x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv12f32.nxv4f32"
        )]
        fn _svset3_f32(tuple: svfloat32x3_t, imm_index: i32, x: svfloat32_t) -> svfloat32x3_t;
    }
    unsafe { _svset3_f32(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset3[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset3_f64<const IMM_INDEX: i32>(tuple: svfloat64x3_t, x: svfloat64_t) -> svfloat64x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv6f64.nxv2f64"
        )]
        fn _svset3_f64(tuple: svfloat64x3_t, imm_index: i32, x: svfloat64_t) -> svfloat64x3_t;
    }
    unsafe { _svset3_f64(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset3[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset3_s8<const IMM_INDEX: i32>(tuple: svint8x3_t, x: svint8_t) -> svint8x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv48i8.nxv16i8"
        )]
        fn _svset3_s8(tuple: svint8x3_t, imm_index: i32, x: svint8_t) -> svint8x3_t;
    }
    unsafe { _svset3_s8(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset3[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset3_s16<const IMM_INDEX: i32>(tuple: svint16x3_t, x: svint16_t) -> svint16x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv24i16.nxv8i16"
        )]
        fn _svset3_s16(tuple: svint16x3_t, imm_index: i32, x: svint16_t) -> svint16x3_t;
    }
    unsafe { _svset3_s16(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset3[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset3_s32<const IMM_INDEX: i32>(tuple: svint32x3_t, x: svint32_t) -> svint32x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv12i32.nxv4i32"
        )]
        fn _svset3_s32(tuple: svint32x3_t, imm_index: i32, x: svint32_t) -> svint32x3_t;
    }
    unsafe { _svset3_s32(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset3[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset3_s64<const IMM_INDEX: i32>(tuple: svint64x3_t, x: svint64_t) -> svint64x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv6i64.nxv2i64"
        )]
        fn _svset3_s64(tuple: svint64x3_t, imm_index: i32, x: svint64_t) -> svint64x3_t;
    }
    unsafe { _svset3_s64(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset3[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset3_u8<const IMM_INDEX: i32>(tuple: svuint8x3_t, x: svuint8_t) -> svuint8x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    unsafe { svset3_s8::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[doc = "Change one vector in a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset3[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset3_u16<const IMM_INDEX: i32>(tuple: svuint16x3_t, x: svuint16_t) -> svuint16x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    unsafe { svset3_s16::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[doc = "Change one vector in a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset3[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset3_u32<const IMM_INDEX: i32>(tuple: svuint32x3_t, x: svuint32_t) -> svuint32x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    unsafe { svset3_s32::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[doc = "Change one vector in a tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset3[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset3_u64<const IMM_INDEX: i32>(tuple: svuint64x3_t, x: svuint64_t) -> svuint64x3_t {
    static_assert_range!(IMM_INDEX, 0, 2);
    unsafe { svset3_s64::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[doc = "Change one vector in a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset4[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset4_f32<const IMM_INDEX: i32>(tuple: svfloat32x4_t, x: svfloat32_t) -> svfloat32x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv16f32.nxv4f32"
        )]
        fn _svset4_f32(tuple: svfloat32x4_t, imm_index: i32, x: svfloat32_t) -> svfloat32x4_t;
    }
    unsafe { _svset4_f32(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset4[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset4_f64<const IMM_INDEX: i32>(tuple: svfloat64x4_t, x: svfloat64_t) -> svfloat64x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv8f64.nxv2f64"
        )]
        fn _svset4_f64(tuple: svfloat64x4_t, imm_index: i32, x: svfloat64_t) -> svfloat64x4_t;
    }
    unsafe { _svset4_f64(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset4[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset4_s8<const IMM_INDEX: i32>(tuple: svint8x4_t, x: svint8_t) -> svint8x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv64i8.nxv16i8"
        )]
        fn _svset4_s8(tuple: svint8x4_t, imm_index: i32, x: svint8_t) -> svint8x4_t;
    }
    unsafe { _svset4_s8(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset4[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset4_s16<const IMM_INDEX: i32>(tuple: svint16x4_t, x: svint16_t) -> svint16x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv32i16.nxv8i16"
        )]
        fn _svset4_s16(tuple: svint16x4_t, imm_index: i32, x: svint16_t) -> svint16x4_t;
    }
    unsafe { _svset4_s16(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset4[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset4_s32<const IMM_INDEX: i32>(tuple: svint32x4_t, x: svint32_t) -> svint32x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv16i32.nxv4i32"
        )]
        fn _svset4_s32(tuple: svint32x4_t, imm_index: i32, x: svint32_t) -> svint32x4_t;
    }
    unsafe { _svset4_s32(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset4[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset4_s64<const IMM_INDEX: i32>(tuple: svint64x4_t, x: svint64_t) -> svint64x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.tuple.set.nxv8i64.nxv2i64"
        )]
        fn _svset4_s64(tuple: svint64x4_t, imm_index: i32, x: svint64_t) -> svint64x4_t;
    }
    unsafe { _svset4_s64(tuple, IMM_INDEX, x) }
}
#[doc = "Change one vector in a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset4[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset4_u8<const IMM_INDEX: i32>(tuple: svuint8x4_t, x: svuint8_t) -> svuint8x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    unsafe { svset4_s8::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[doc = "Change one vector in a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset4[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset4_u16<const IMM_INDEX: i32>(tuple: svuint16x4_t, x: svuint16_t) -> svuint16x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    unsafe { svset4_s16::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[doc = "Change one vector in a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset4[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset4_u32<const IMM_INDEX: i32>(tuple: svuint32x4_t, x: svuint32_t) -> svuint32x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    unsafe { svset4_s32::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[doc = "Change one vector in a tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svset4[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
pub fn svset4_u64<const IMM_INDEX: i32>(tuple: svuint64x4_t, x: svuint64_t) -> svuint64x4_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    unsafe { svset4_s64::<IMM_INDEX>(tuple.as_signed(), x.as_signed()).as_unsigned() }
}
#[doc = "Initialize the first-fault register to all-true"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsetffr)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(setffr))]
pub fn svsetffr() {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.setffr")]
        fn _svsetffr();
    }
    unsafe { _svsetffr() }
}
#[doc = "Splice two vectors under predicate control"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsplice[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub fn svsplice_f32(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.splice.nxv4f32")]
        fn _svsplice_f32(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svsplice_f32(pg.into(), op1, op2) }
}
#[doc = "Splice two vectors under predicate control"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsplice[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub fn svsplice_f64(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.splice.nxv2f64")]
        fn _svsplice_f64(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svsplice_f64(pg.into(), op1, op2) }
}
#[doc = "Splice two vectors under predicate control"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsplice[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub fn svsplice_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.splice.nxv16i8")]
        fn _svsplice_s8(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svsplice_s8(pg, op1, op2) }
}
#[doc = "Splice two vectors under predicate control"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsplice[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub fn svsplice_s16(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.splice.nxv8i16")]
        fn _svsplice_s16(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svsplice_s16(pg.into(), op1, op2) }
}
#[doc = "Splice two vectors under predicate control"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsplice[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub fn svsplice_s32(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.splice.nxv4i32")]
        fn _svsplice_s32(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svsplice_s32(pg.into(), op1, op2) }
}
#[doc = "Splice two vectors under predicate control"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsplice[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub fn svsplice_s64(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.splice.nxv2i64")]
        fn _svsplice_s64(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svsplice_s64(pg.into(), op1, op2) }
}
#[doc = "Splice two vectors under predicate control"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsplice[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub fn svsplice_u8(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svsplice_s8(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Splice two vectors under predicate control"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsplice[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub fn svsplice_u16(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svsplice_s16(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Splice two vectors under predicate control"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsplice[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub fn svsplice_u32(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svsplice_s32(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Splice two vectors under predicate control"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsplice[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(splice))]
pub fn svsplice_u64(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svsplice_s64(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Square root"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsqrt[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsqrt))]
pub fn svsqrt_f32_m(inactive: svfloat32_t, pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fsqrt.nxv4f32")]
        fn _svsqrt_f32_m(inactive: svfloat32_t, pg: svbool4_t, op: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svsqrt_f32_m(inactive, pg.into(), op) }
}
#[doc = "Square root"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsqrt[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsqrt))]
pub fn svsqrt_f32_x(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svsqrt_f32_m(op, pg, op)
}
#[doc = "Square root"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsqrt[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsqrt))]
pub fn svsqrt_f32_z(pg: svbool_t, op: svfloat32_t) -> svfloat32_t {
    svsqrt_f32_m(svdup_n_f32(0.0), pg, op)
}
#[doc = "Square root"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsqrt[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsqrt))]
pub fn svsqrt_f64_m(inactive: svfloat64_t, pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fsqrt.nxv2f64")]
        fn _svsqrt_f64_m(inactive: svfloat64_t, pg: svbool2_t, op: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svsqrt_f64_m(inactive, pg.into(), op) }
}
#[doc = "Square root"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsqrt[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsqrt))]
pub fn svsqrt_f64_x(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svsqrt_f64_m(op, pg, op)
}
#[doc = "Square root"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsqrt[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsqrt))]
pub fn svsqrt_f64_z(pg: svbool_t, op: svfloat64_t) -> svfloat64_t {
    svsqrt_f64_m(svdup_n_f64(0.0), pg, op)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_f32(pg: svbool_t, base: *mut f32, data: svfloat32_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv4f32")]
        fn _svst1_f32(data: svfloat32_t, pg: svbool4_t, ptr: *mut f32);
    }
    _svst1_f32(data, pg.into(), base)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_f64(pg: svbool_t, base: *mut f64, data: svfloat64_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv2f64")]
        fn _svst1_f64(data: svfloat64_t, pg: svbool2_t, ptr: *mut f64);
    }
    _svst1_f64(data, pg.into(), base)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1_s8(pg: svbool_t, base: *mut i8, data: svint8_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv16i8")]
        fn _svst1_s8(data: svint8_t, pg: svbool_t, ptr: *mut i8);
    }
    _svst1_s8(data, pg, base)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1_s16(pg: svbool_t, base: *mut i16, data: svint16_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv8i16")]
        fn _svst1_s16(data: svint16_t, pg: svbool8_t, ptr: *mut i16);
    }
    _svst1_s16(data, pg.into(), base)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_s32(pg: svbool_t, base: *mut i32, data: svint32_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv4i32")]
        fn _svst1_s32(data: svint32_t, pg: svbool4_t, ptr: *mut i32);
    }
    _svst1_s32(data, pg.into(), base)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_s64(pg: svbool_t, base: *mut i64, data: svint64_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv2i64")]
        fn _svst1_s64(data: svint64_t, pg: svbool2_t, ptr: *mut i64);
    }
    _svst1_s64(data, pg.into(), base)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1_u8(pg: svbool_t, base: *mut u8, data: svuint8_t) {
    svst1_s8(pg, base.as_signed(), data.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1_u16(pg: svbool_t, base: *mut u16, data: svuint16_t) {
    svst1_s16(pg, base.as_signed(), data.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_u32(pg: svbool_t, base: *mut u32, data: svuint32_t) {
    svst1_s32(pg, base.as_signed(), data.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_u64(pg: svbool_t, base: *mut u64, data: svuint64_t) {
    svst1_s64(pg, base.as_signed(), data.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[s32]index[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_s32index_f32(
    pg: svbool_t,
    base: *mut f32,
    indices: svint32_t,
    data: svfloat32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.sxtw.index.nxv4f32"
        )]
        fn _svst1_scatter_s32index_f32(
            data: svfloat32_t,
            pg: svbool4_t,
            base: *mut f32,
            indices: svint32_t,
        );
    }
    _svst1_scatter_s32index_f32(data, pg.into(), base, indices)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[s32]index[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_s32index_s32(
    pg: svbool_t,
    base: *mut i32,
    indices: svint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.sxtw.index.nxv4i32"
        )]
        fn _svst1_scatter_s32index_s32(
            data: svint32_t,
            pg: svbool4_t,
            base: *mut i32,
            indices: svint32_t,
        );
    }
    _svst1_scatter_s32index_s32(data, pg.into(), base, indices)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[s32]index[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_s32index_u32(
    pg: svbool_t,
    base: *mut u32,
    indices: svint32_t,
    data: svuint32_t,
) {
    svst1_scatter_s32index_s32(pg, base.as_signed(), indices, data.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[s64]index[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_s64index_f64(
    pg: svbool_t,
    base: *mut f64,
    indices: svint64_t,
    data: svfloat64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.index.nxv2f64"
        )]
        fn _svst1_scatter_s64index_f64(
            data: svfloat64_t,
            pg: svbool2_t,
            base: *mut f64,
            indices: svint64_t,
        );
    }
    _svst1_scatter_s64index_f64(data, pg.into(), base, indices)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[s64]index[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_s64index_s64(
    pg: svbool_t,
    base: *mut i64,
    indices: svint64_t,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.index.nxv2i64"
        )]
        fn _svst1_scatter_s64index_s64(
            data: svint64_t,
            pg: svbool2_t,
            base: *mut i64,
            indices: svint64_t,
        );
    }
    _svst1_scatter_s64index_s64(data, pg.into(), base, indices)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[s64]index[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_s64index_u64(
    pg: svbool_t,
    base: *mut u64,
    indices: svint64_t,
    data: svuint64_t,
) {
    svst1_scatter_s64index_s64(pg, base.as_signed(), indices, data.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[u32]index[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32index_f32(
    pg: svbool_t,
    base: *mut f32,
    indices: svuint32_t,
    data: svfloat32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.uxtw.index.nxv4f32"
        )]
        fn _svst1_scatter_u32index_f32(
            data: svfloat32_t,
            pg: svbool4_t,
            base: *mut f32,
            indices: svint32_t,
        );
    }
    _svst1_scatter_u32index_f32(data, pg.into(), base, indices.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[u32]index[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32index_s32(
    pg: svbool_t,
    base: *mut i32,
    indices: svuint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.uxtw.index.nxv4i32"
        )]
        fn _svst1_scatter_u32index_s32(
            data: svint32_t,
            pg: svbool4_t,
            base: *mut i32,
            indices: svint32_t,
        );
    }
    _svst1_scatter_u32index_s32(data, pg.into(), base, indices.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[u32]index[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32index_u32(
    pg: svbool_t,
    base: *mut u32,
    indices: svuint32_t,
    data: svuint32_t,
) {
    svst1_scatter_u32index_s32(pg, base.as_signed(), indices, data.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[u64]index[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64index_f64(
    pg: svbool_t,
    base: *mut f64,
    indices: svuint64_t,
    data: svfloat64_t,
) {
    svst1_scatter_s64index_f64(pg, base, indices.as_signed(), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[u64]index[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64index_s64(
    pg: svbool_t,
    base: *mut i64,
    indices: svuint64_t,
    data: svint64_t,
) {
    svst1_scatter_s64index_s64(pg, base, indices.as_signed(), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[u64]index[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64index_u64(
    pg: svbool_t,
    base: *mut u64,
    indices: svuint64_t,
    data: svuint64_t,
) {
    svst1_scatter_s64index_s64(pg, base.as_signed(), indices.as_signed(), data.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[s32]offset[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_s32offset_f32(
    pg: svbool_t,
    base: *mut f32,
    offsets: svint32_t,
    data: svfloat32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.sxtw.nxv4f32"
        )]
        fn _svst1_scatter_s32offset_f32(
            data: svfloat32_t,
            pg: svbool4_t,
            base: *mut f32,
            offsets: svint32_t,
        );
    }
    _svst1_scatter_s32offset_f32(data, pg.into(), base, offsets)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[s32]offset[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_s32offset_s32(
    pg: svbool_t,
    base: *mut i32,
    offsets: svint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.sxtw.nxv4i32"
        )]
        fn _svst1_scatter_s32offset_s32(
            data: svint32_t,
            pg: svbool4_t,
            base: *mut i32,
            offsets: svint32_t,
        );
    }
    _svst1_scatter_s32offset_s32(data, pg.into(), base, offsets)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[s32]offset[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_s32offset_u32(
    pg: svbool_t,
    base: *mut u32,
    offsets: svint32_t,
    data: svuint32_t,
) {
    svst1_scatter_s32offset_s32(pg, base.as_signed(), offsets, data.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[s64]offset[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_s64offset_f64(
    pg: svbool_t,
    base: *mut f64,
    offsets: svint64_t,
    data: svfloat64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.nxv2f64"
        )]
        fn _svst1_scatter_s64offset_f64(
            data: svfloat64_t,
            pg: svbool2_t,
            base: *mut f64,
            offsets: svint64_t,
        );
    }
    _svst1_scatter_s64offset_f64(data, pg.into(), base, offsets)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[s64]offset[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_s64offset_s64(
    pg: svbool_t,
    base: *mut i64,
    offsets: svint64_t,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.nxv2i64"
        )]
        fn _svst1_scatter_s64offset_s64(
            data: svint64_t,
            pg: svbool2_t,
            base: *mut i64,
            offsets: svint64_t,
        );
    }
    _svst1_scatter_s64offset_s64(data, pg.into(), base, offsets)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[s64]offset[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_s64offset_u64(
    pg: svbool_t,
    base: *mut u64,
    offsets: svint64_t,
    data: svuint64_t,
) {
    svst1_scatter_s64offset_s64(pg, base.as_signed(), offsets, data.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[u32]offset[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32offset_f32(
    pg: svbool_t,
    base: *mut f32,
    offsets: svuint32_t,
    data: svfloat32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.uxtw.nxv4f32"
        )]
        fn _svst1_scatter_u32offset_f32(
            data: svfloat32_t,
            pg: svbool4_t,
            base: *mut f32,
            offsets: svint32_t,
        );
    }
    _svst1_scatter_u32offset_f32(data, pg.into(), base, offsets.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[u32]offset[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32offset_s32(
    pg: svbool_t,
    base: *mut i32,
    offsets: svuint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.uxtw.nxv4i32"
        )]
        fn _svst1_scatter_u32offset_s32(
            data: svint32_t,
            pg: svbool4_t,
            base: *mut i32,
            offsets: svint32_t,
        );
    }
    _svst1_scatter_u32offset_s32(data, pg.into(), base, offsets.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[u32]offset[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32offset_u32(
    pg: svbool_t,
    base: *mut u32,
    offsets: svuint32_t,
    data: svuint32_t,
) {
    svst1_scatter_u32offset_s32(pg, base.as_signed(), offsets, data.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[u64]offset[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64offset_f64(
    pg: svbool_t,
    base: *mut f64,
    offsets: svuint64_t,
    data: svfloat64_t,
) {
    svst1_scatter_s64offset_f64(pg, base, offsets.as_signed(), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[u64]offset[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64offset_s64(
    pg: svbool_t,
    base: *mut i64,
    offsets: svuint64_t,
    data: svint64_t,
) {
    svst1_scatter_s64offset_s64(pg, base, offsets.as_signed(), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter_[u64]offset[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64offset_u64(
    pg: svbool_t,
    base: *mut u64,
    offsets: svuint64_t,
    data: svuint64_t,
) {
    svst1_scatter_s64offset_s64(pg, base.as_signed(), offsets.as_signed(), data.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u32base_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_f32(pg: svbool_t, bases: svuint32_t, data: svfloat32_t) {
    svst1_scatter_u32base_offset_f32(pg, bases, 0, data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u32base_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_s32(pg: svbool_t, bases: svuint32_t, data: svint32_t) {
    svst1_scatter_u32base_offset_s32(pg, bases, 0, data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u32base_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_u32(pg: svbool_t, bases: svuint32_t, data: svuint32_t) {
    svst1_scatter_u32base_offset_u32(pg, bases, 0, data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u64base_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_f64(pg: svbool_t, bases: svuint64_t, data: svfloat64_t) {
    svst1_scatter_u64base_offset_f64(pg, bases, 0, data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u64base_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_s64(pg: svbool_t, bases: svuint64_t, data: svint64_t) {
    svst1_scatter_u64base_offset_s64(pg, bases, 0, data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u64base_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_u64(pg: svbool_t, bases: svuint64_t, data: svuint64_t) {
    svst1_scatter_u64base_offset_u64(pg, bases, 0, data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u32base]_index[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_index_f32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
    data: svfloat32_t,
) {
    svst1_scatter_u32base_offset_f32(pg, bases, index.unchecked_shl(2), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u32base]_index[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_index_s32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
    data: svint32_t,
) {
    svst1_scatter_u32base_offset_s32(pg, bases, index.unchecked_shl(2), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u32base]_index[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_index_u32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
    data: svuint32_t,
) {
    svst1_scatter_u32base_offset_u32(pg, bases, index.unchecked_shl(2), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u64base]_index[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_index_f64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
    data: svfloat64_t,
) {
    svst1_scatter_u64base_offset_f64(pg, bases, index.unchecked_shl(3), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u64base]_index[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
    data: svint64_t,
) {
    svst1_scatter_u64base_offset_s64(pg, bases, index.unchecked_shl(3), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u64base]_index[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
    data: svuint64_t,
) {
    svst1_scatter_u64base_offset_u64(pg, bases, index.unchecked_shl(3), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u32base]_offset[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_offset_f32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
    data: svfloat32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv4f32.nxv4i32"
        )]
        fn _svst1_scatter_u32base_offset_f32(
            data: svfloat32_t,
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        );
    }
    _svst1_scatter_u32base_offset_f32(data, pg.into(), bases.as_signed(), offset)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u32base]_offset[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv4i32.nxv4i32"
        )]
        fn _svst1_scatter_u32base_offset_s32(
            data: svint32_t,
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        );
    }
    _svst1_scatter_u32base_offset_s32(data, pg.into(), bases.as_signed(), offset)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u32base]_offset[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_scatter_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
    data: svuint32_t,
) {
    svst1_scatter_u32base_offset_s32(pg, bases, offset, data.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u64base]_offset[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_offset_f64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svfloat64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv2f64.nxv2i64"
        )]
        fn _svst1_scatter_u64base_offset_f64(
            data: svfloat64_t,
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        );
    }
    _svst1_scatter_u64base_offset_f64(data, pg.into(), bases.as_signed(), offset)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u64base]_offset[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv2i64.nxv2i64"
        )]
        fn _svst1_scatter_u64base_offset_s64(
            data: svint64_t,
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        );
    }
    _svst1_scatter_u64base_offset_s64(data, pg.into(), bases.as_signed(), offset)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_scatter[_u64base]_offset[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_scatter_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svuint64_t,
) {
    svst1_scatter_u64base_offset_s64(pg, bases, offset, data.as_signed())
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_vnum[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_vnum_f32(pg: svbool_t, base: *mut f32, vnum: i64, data: svfloat32_t) {
    svst1_f32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_vnum[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_vnum_f64(pg: svbool_t, base: *mut f64, vnum: i64, data: svfloat64_t) {
    svst1_f64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_vnum[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1_vnum_s8(pg: svbool_t, base: *mut i8, vnum: i64, data: svint8_t) {
    svst1_s8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_vnum[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1_vnum_s16(pg: svbool_t, base: *mut i16, vnum: i64, data: svint16_t) {
    svst1_s16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_vnum[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_vnum_s32(pg: svbool_t, base: *mut i32, vnum: i64, data: svint32_t) {
    svst1_s32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_vnum[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_vnum_s64(pg: svbool_t, base: *mut i64, vnum: i64, data: svint64_t) {
    svst1_s64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_vnum[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1_vnum_u8(pg: svbool_t, base: *mut u8, vnum: i64, data: svuint8_t) {
    svst1_u8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_vnum[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1_vnum_u16(pg: svbool_t, base: *mut u16, vnum: i64, data: svuint16_t) {
    svst1_u16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_vnum[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1_vnum_u32(pg: svbool_t, base: *mut u32, vnum: i64, data: svuint32_t) {
    svst1_u32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1_vnum[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1d))]
pub unsafe fn svst1_vnum_u64(pg: svbool_t, base: *mut u64, vnum: i64, data: svuint64_t) {
    svst1_u64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_s16(pg: svbool_t, base: *mut i8, data: svint16_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv8i8")]
        fn _svst1b_s16(data: nxv8i8, pg: svbool8_t, ptr: *mut i8);
    }
    _svst1b_s16(simd_cast(data), pg.into(), base)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_s32(pg: svbool_t, base: *mut i8, data: svint32_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv4i8")]
        fn _svst1b_s32(data: nxv4i8, pg: svbool4_t, ptr: *mut i8);
    }
    _svst1b_s32(simd_cast(data), pg.into(), base)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_s32(pg: svbool_t, base: *mut i16, data: svint32_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv4i16")]
        fn _svst1h_s32(data: nxv4i16, pg: svbool4_t, ptr: *mut i16);
    }
    _svst1h_s32(simd_cast(data), pg.into(), base)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_s64(pg: svbool_t, base: *mut i8, data: svint64_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv2i8")]
        fn _svst1b_s64(data: nxv2i8, pg: svbool2_t, ptr: *mut i8);
    }
    _svst1b_s64(simd_cast(data), pg.into(), base)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_s64(pg: svbool_t, base: *mut i16, data: svint64_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv2i16")]
        fn _svst1h_s64(data: nxv2i16, pg: svbool2_t, ptr: *mut i16);
    }
    _svst1h_s64(simd_cast(data), pg.into(), base)
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_s64(pg: svbool_t, base: *mut i32, data: svint64_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st1.nxv2i32")]
        fn _svst1w_s64(data: nxv2i32, pg: svbool2_t, ptr: *mut i32);
    }
    _svst1w_s64(simd_cast(data), pg.into(), base)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_u16(pg: svbool_t, base: *mut u8, data: svuint16_t) {
    svst1b_s16(pg, base.as_signed(), data.as_signed())
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_u32(pg: svbool_t, base: *mut u8, data: svuint32_t) {
    svst1b_s32(pg, base.as_signed(), data.as_signed())
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_u32(pg: svbool_t, base: *mut u16, data: svuint32_t) {
    svst1h_s32(pg, base.as_signed(), data.as_signed())
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_u64(pg: svbool_t, base: *mut u8, data: svuint64_t) {
    svst1b_s64(pg, base.as_signed(), data.as_signed())
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_u64(pg: svbool_t, base: *mut u16, data: svuint64_t) {
    svst1h_s64(pg, base.as_signed(), data.as_signed())
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_u64(pg: svbool_t, base: *mut u32, data: svuint64_t) {
    svst1w_s64(pg, base.as_signed(), data.as_signed())
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_scatter_[s32]offset[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_s32offset_s32(
    pg: svbool_t,
    base: *mut i8,
    offsets: svint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.sxtw.nxv4i8"
        )]
        fn _svst1b_scatter_s32offset_s32(
            data: nxv4i8,
            pg: svbool4_t,
            base: *mut i8,
            offsets: svint32_t,
        );
    }
    _svst1b_scatter_s32offset_s32(simd_cast(data), pg.into(), base, offsets)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter_[s32]offset[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_s32offset_s32(
    pg: svbool_t,
    base: *mut i16,
    offsets: svint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.sxtw.nxv4i16"
        )]
        fn _svst1h_scatter_s32offset_s32(
            data: nxv4i16,
            pg: svbool4_t,
            base: *mut i16,
            offsets: svint32_t,
        );
    }
    _svst1h_scatter_s32offset_s32(simd_cast(data), pg.into(), base, offsets)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_scatter_[s32]offset[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_s32offset_u32(
    pg: svbool_t,
    base: *mut u8,
    offsets: svint32_t,
    data: svuint32_t,
) {
    svst1b_scatter_s32offset_s32(pg, base.as_signed(), offsets, data.as_signed())
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter_[s32]offset[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_s32offset_u32(
    pg: svbool_t,
    base: *mut u16,
    offsets: svint32_t,
    data: svuint32_t,
) {
    svst1h_scatter_s32offset_s32(pg, base.as_signed(), offsets, data.as_signed())
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_scatter_[s64]offset[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_s64offset_s64(
    pg: svbool_t,
    base: *mut i8,
    offsets: svint64_t,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.nxv2i8"
        )]
        fn _svst1b_scatter_s64offset_s64(
            data: nxv2i8,
            pg: svbool2_t,
            base: *mut i8,
            offsets: svint64_t,
        );
    }
    _svst1b_scatter_s64offset_s64(simd_cast(data), pg.into(), base, offsets)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter_[s64]offset[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_s64offset_s64(
    pg: svbool_t,
    base: *mut i16,
    offsets: svint64_t,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.nxv2i16"
        )]
        fn _svst1h_scatter_s64offset_s64(
            data: nxv2i16,
            pg: svbool2_t,
            base: *mut i16,
            offsets: svint64_t,
        );
    }
    _svst1h_scatter_s64offset_s64(simd_cast(data), pg.into(), base, offsets)
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w_scatter_[s64]offset[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_s64offset_s64(
    pg: svbool_t,
    base: *mut i32,
    offsets: svint64_t,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.nxv2i32"
        )]
        fn _svst1w_scatter_s64offset_s64(
            data: nxv2i32,
            pg: svbool2_t,
            base: *mut i32,
            offsets: svint64_t,
        );
    }
    _svst1w_scatter_s64offset_s64(simd_cast(data), pg.into(), base, offsets)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_scatter_[s64]offset[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_s64offset_u64(
    pg: svbool_t,
    base: *mut u8,
    offsets: svint64_t,
    data: svuint64_t,
) {
    svst1b_scatter_s64offset_s64(pg, base.as_signed(), offsets, data.as_signed())
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter_[s64]offset[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_s64offset_u64(
    pg: svbool_t,
    base: *mut u16,
    offsets: svint64_t,
    data: svuint64_t,
) {
    svst1h_scatter_s64offset_s64(pg, base.as_signed(), offsets, data.as_signed())
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w_scatter_[s64]offset[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_s64offset_u64(
    pg: svbool_t,
    base: *mut u32,
    offsets: svint64_t,
    data: svuint64_t,
) {
    svst1w_scatter_s64offset_s64(pg, base.as_signed(), offsets, data.as_signed())
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_scatter_[u32]offset[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u32offset_s32(
    pg: svbool_t,
    base: *mut i8,
    offsets: svuint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.uxtw.nxv4i8"
        )]
        fn _svst1b_scatter_u32offset_s32(
            data: nxv4i8,
            pg: svbool4_t,
            base: *mut i8,
            offsets: svint32_t,
        );
    }
    _svst1b_scatter_u32offset_s32(simd_cast(data), pg.into(), base, offsets.as_signed())
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter_[u32]offset[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32offset_s32(
    pg: svbool_t,
    base: *mut i16,
    offsets: svuint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.uxtw.nxv4i16"
        )]
        fn _svst1h_scatter_u32offset_s32(
            data: nxv4i16,
            pg: svbool4_t,
            base: *mut i16,
            offsets: svint32_t,
        );
    }
    _svst1h_scatter_u32offset_s32(simd_cast(data), pg.into(), base, offsets.as_signed())
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_scatter_[u32]offset[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u32offset_u32(
    pg: svbool_t,
    base: *mut u8,
    offsets: svuint32_t,
    data: svuint32_t,
) {
    svst1b_scatter_u32offset_s32(pg, base.as_signed(), offsets, data.as_signed())
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter_[u32]offset[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32offset_u32(
    pg: svbool_t,
    base: *mut u16,
    offsets: svuint32_t,
    data: svuint32_t,
) {
    svst1h_scatter_u32offset_s32(pg, base.as_signed(), offsets, data.as_signed())
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_scatter_[u64]offset[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u64offset_s64(
    pg: svbool_t,
    base: *mut i8,
    offsets: svuint64_t,
    data: svint64_t,
) {
    svst1b_scatter_s64offset_s64(pg, base, offsets.as_signed(), data)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter_[u64]offset[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64offset_s64(
    pg: svbool_t,
    base: *mut i16,
    offsets: svuint64_t,
    data: svint64_t,
) {
    svst1h_scatter_s64offset_s64(pg, base, offsets.as_signed(), data)
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w_scatter_[u64]offset[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64offset_s64(
    pg: svbool_t,
    base: *mut i32,
    offsets: svuint64_t,
    data: svint64_t,
) {
    svst1w_scatter_s64offset_s64(pg, base, offsets.as_signed(), data)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_scatter_[u64]offset[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u64offset_u64(
    pg: svbool_t,
    base: *mut u8,
    offsets: svuint64_t,
    data: svuint64_t,
) {
    svst1b_scatter_s64offset_s64(pg, base.as_signed(), offsets.as_signed(), data.as_signed())
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter_[u64]offset[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64offset_u64(
    pg: svbool_t,
    base: *mut u16,
    offsets: svuint64_t,
    data: svuint64_t,
) {
    svst1h_scatter_s64offset_s64(pg, base.as_signed(), offsets.as_signed(), data.as_signed())
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w_scatter_[u64]offset[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64offset_u64(
    pg: svbool_t,
    base: *mut u32,
    offsets: svuint64_t,
    data: svuint64_t,
) {
    svst1w_scatter_s64offset_s64(pg, base.as_signed(), offsets.as_signed(), data.as_signed())
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_scatter[_u32base]_offset[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv4i8.nxv4i32"
        )]
        fn _svst1b_scatter_u32base_offset_s32(
            data: nxv4i8,
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        );
    }
    _svst1b_scatter_u32base_offset_s32(simd_cast(data), pg.into(), bases.as_signed(), offset)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter[_u32base]_offset[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32base_offset_s32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv4i16.nxv4i32"
        )]
        fn _svst1h_scatter_u32base_offset_s32(
            data: nxv4i16,
            pg: svbool4_t,
            bases: svint32_t,
            offset: i64,
        );
    }
    _svst1h_scatter_u32base_offset_s32(simd_cast(data), pg.into(), bases.as_signed(), offset)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_scatter[_u32base]_offset[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
    data: svuint32_t,
) {
    svst1b_scatter_u32base_offset_s32(pg, bases, offset, data.as_signed())
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter[_u32base]_offset[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32base_offset_u32(
    pg: svbool_t,
    bases: svuint32_t,
    offset: i64,
    data: svuint32_t,
) {
    svst1h_scatter_u32base_offset_s32(pg, bases, offset, data.as_signed())
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_scatter[_u64base]_offset[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv2i8.nxv2i64"
        )]
        fn _svst1b_scatter_u64base_offset_s64(
            data: nxv2i8,
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        );
    }
    _svst1b_scatter_u64base_offset_s64(simd_cast(data), pg.into(), bases.as_signed(), offset)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter[_u64base]_offset[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv2i16.nxv2i64"
        )]
        fn _svst1h_scatter_u64base_offset_s64(
            data: nxv2i16,
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        );
    }
    _svst1h_scatter_u64base_offset_s64(simd_cast(data), pg.into(), bases.as_signed(), offset)
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w_scatter[_u64base]_offset[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64base_offset_s64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.scalar.offset.nxv2i32.nxv2i64"
        )]
        fn _svst1w_scatter_u64base_offset_s64(
            data: nxv2i32,
            pg: svbool2_t,
            bases: svint64_t,
            offset: i64,
        );
    }
    _svst1w_scatter_u64base_offset_s64(simd_cast(data), pg.into(), bases.as_signed(), offset)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_scatter[_u64base]_offset[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svuint64_t,
) {
    svst1b_scatter_u64base_offset_s64(pg, bases, offset, data.as_signed())
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter[_u64base]_offset[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svuint64_t,
) {
    svst1h_scatter_u64base_offset_s64(pg, bases, offset, data.as_signed())
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w_scatter[_u64base]_offset[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64base_offset_u64(
    pg: svbool_t,
    bases: svuint64_t,
    offset: i64,
    data: svuint64_t,
) {
    svst1w_scatter_u64base_offset_s64(pg, bases, offset, data.as_signed())
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_scatter[_u32base_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u32base_s32(pg: svbool_t, bases: svuint32_t, data: svint32_t) {
    svst1b_scatter_u32base_offset_s32(pg, bases, 0, data)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter[_u32base_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32base_s32(pg: svbool_t, bases: svuint32_t, data: svint32_t) {
    svst1h_scatter_u32base_offset_s32(pg, bases, 0, data)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_scatter[_u32base_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u32base_u32(pg: svbool_t, bases: svuint32_t, data: svuint32_t) {
    svst1b_scatter_u32base_offset_u32(pg, bases, 0, data)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter[_u32base_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32base_u32(pg: svbool_t, bases: svuint32_t, data: svuint32_t) {
    svst1h_scatter_u32base_offset_u32(pg, bases, 0, data)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_scatter[_u64base_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u64base_s64(pg: svbool_t, bases: svuint64_t, data: svint64_t) {
    svst1b_scatter_u64base_offset_s64(pg, bases, 0, data)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter[_u64base_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64base_s64(pg: svbool_t, bases: svuint64_t, data: svint64_t) {
    svst1h_scatter_u64base_offset_s64(pg, bases, 0, data)
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w_scatter[_u64base_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64base_s64(pg: svbool_t, bases: svuint64_t, data: svint64_t) {
    svst1w_scatter_u64base_offset_s64(pg, bases, 0, data)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_scatter[_u64base_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_scatter_u64base_u64(pg: svbool_t, bases: svuint64_t, data: svuint64_t) {
    svst1b_scatter_u64base_offset_u64(pg, bases, 0, data)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter[_u64base_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64base_u64(pg: svbool_t, bases: svuint64_t, data: svuint64_t) {
    svst1h_scatter_u64base_offset_u64(pg, bases, 0, data)
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w_scatter[_u64base_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64base_u64(pg: svbool_t, bases: svuint64_t, data: svuint64_t) {
    svst1w_scatter_u64base_offset_u64(pg, bases, 0, data)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_vnum[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_vnum_s16(pg: svbool_t, base: *mut i8, vnum: i64, data: svint16_t) {
    svst1b_s16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_vnum[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_vnum_s32(pg: svbool_t, base: *mut i8, vnum: i64, data: svint32_t) {
    svst1b_s32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_vnum[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_vnum_s32(pg: svbool_t, base: *mut i16, vnum: i64, data: svint32_t) {
    svst1h_s32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_vnum[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_vnum_s64(pg: svbool_t, base: *mut i8, vnum: i64, data: svint64_t) {
    svst1b_s64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_vnum[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_vnum_s64(pg: svbool_t, base: *mut i16, vnum: i64, data: svint64_t) {
    svst1h_s64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w_vnum[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_vnum_s64(pg: svbool_t, base: *mut i32, vnum: i64, data: svint64_t) {
    svst1w_s64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_vnum[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_vnum_u16(pg: svbool_t, base: *mut u8, vnum: i64, data: svuint16_t) {
    svst1b_u16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_vnum[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_vnum_u32(pg: svbool_t, base: *mut u8, vnum: i64, data: svuint32_t) {
    svst1b_u32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_vnum[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_vnum_u32(pg: svbool_t, base: *mut u16, vnum: i64, data: svuint32_t) {
    svst1h_u32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Truncate to 8 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1b_vnum[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1b))]
pub unsafe fn svst1b_vnum_u64(pg: svbool_t, base: *mut u8, vnum: i64, data: svuint64_t) {
    svst1b_u64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_vnum[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_vnum_u64(pg: svbool_t, base: *mut u16, vnum: i64, data: svuint64_t) {
    svst1h_u64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w_vnum[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_vnum_u64(pg: svbool_t, base: *mut u32, vnum: i64, data: svuint64_t) {
    svst1w_u64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter_[s32]index[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_s32index_s32(
    pg: svbool_t,
    base: *mut i16,
    indices: svint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.sxtw.index.nxv4i16"
        )]
        fn _svst1h_scatter_s32index_s32(
            data: nxv4i16,
            pg: svbool4_t,
            base: *mut i16,
            indices: svint32_t,
        );
    }
    _svst1h_scatter_s32index_s32(simd_cast(data), pg.into(), base, indices)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter_[s32]index[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_s32index_u32(
    pg: svbool_t,
    base: *mut u16,
    indices: svint32_t,
    data: svuint32_t,
) {
    svst1h_scatter_s32index_s32(pg, base.as_signed(), indices, data.as_signed())
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter_[s64]index[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_s64index_s64(
    pg: svbool_t,
    base: *mut i16,
    indices: svint64_t,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.index.nxv2i16"
        )]
        fn _svst1h_scatter_s64index_s64(
            data: nxv2i16,
            pg: svbool2_t,
            base: *mut i16,
            indices: svint64_t,
        );
    }
    _svst1h_scatter_s64index_s64(simd_cast(data), pg.into(), base, indices)
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w_scatter_[s64]index[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_s64index_s64(
    pg: svbool_t,
    base: *mut i32,
    indices: svint64_t,
    data: svint64_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.index.nxv2i32"
        )]
        fn _svst1w_scatter_s64index_s64(
            data: nxv2i32,
            pg: svbool2_t,
            base: *mut i32,
            indices: svint64_t,
        );
    }
    _svst1w_scatter_s64index_s64(simd_cast(data), pg.into(), base, indices)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter_[s64]index[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_s64index_u64(
    pg: svbool_t,
    base: *mut u16,
    indices: svint64_t,
    data: svuint64_t,
) {
    svst1h_scatter_s64index_s64(pg, base.as_signed(), indices, data.as_signed())
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w_scatter_[s64]index[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_s64index_u64(
    pg: svbool_t,
    base: *mut u32,
    indices: svint64_t,
    data: svuint64_t,
) {
    svst1w_scatter_s64index_s64(pg, base.as_signed(), indices, data.as_signed())
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter_[u32]index[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32index_s32(
    pg: svbool_t,
    base: *mut i16,
    indices: svuint32_t,
    data: svint32_t,
) {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.st1.scatter.uxtw.index.nxv4i16"
        )]
        fn _svst1h_scatter_u32index_s32(
            data: nxv4i16,
            pg: svbool4_t,
            base: *mut i16,
            indices: svint32_t,
        );
    }
    _svst1h_scatter_u32index_s32(simd_cast(data), pg.into(), base, indices.as_signed())
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter_[u32]index[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32index_u32(
    pg: svbool_t,
    base: *mut u16,
    indices: svuint32_t,
    data: svuint32_t,
) {
    svst1h_scatter_u32index_s32(pg, base.as_signed(), indices, data.as_signed())
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter_[u64]index[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64index_s64(
    pg: svbool_t,
    base: *mut i16,
    indices: svuint64_t,
    data: svint64_t,
) {
    svst1h_scatter_s64index_s64(pg, base, indices.as_signed(), data)
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w_scatter_[u64]index[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64index_s64(
    pg: svbool_t,
    base: *mut i32,
    indices: svuint64_t,
    data: svint64_t,
) {
    svst1w_scatter_s64index_s64(pg, base, indices.as_signed(), data)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter_[u64]index[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64index_u64(
    pg: svbool_t,
    base: *mut u16,
    indices: svuint64_t,
    data: svuint64_t,
) {
    svst1h_scatter_s64index_s64(pg, base.as_signed(), indices.as_signed(), data.as_signed())
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w_scatter_[u64]index[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64index_u64(
    pg: svbool_t,
    base: *mut u32,
    indices: svuint64_t,
    data: svuint64_t,
) {
    svst1w_scatter_s64index_s64(pg, base.as_signed(), indices.as_signed(), data.as_signed())
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter[_u32base]_index[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32base_index_s32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
    data: svint32_t,
) {
    svst1h_scatter_u32base_offset_s32(pg, bases, index.unchecked_shl(1), data)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter[_u32base]_index[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u32base_index_u32(
    pg: svbool_t,
    bases: svuint32_t,
    index: i64,
    data: svuint32_t,
) {
    svst1h_scatter_u32base_offset_u32(pg, bases, index.unchecked_shl(1), data)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter[_u64base]_index[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
    data: svint64_t,
) {
    svst1h_scatter_u64base_offset_s64(pg, bases, index.unchecked_shl(1), data)
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w_scatter[_u64base]_index[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64base_index_s64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
    data: svint64_t,
) {
    svst1w_scatter_u64base_offset_s64(pg, bases, index.unchecked_shl(2), data)
}
#[doc = "Truncate to 16 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1h_scatter[_u64base]_index[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1h))]
pub unsafe fn svst1h_scatter_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
    data: svuint64_t,
) {
    svst1h_scatter_u64base_offset_u64(pg, bases, index.unchecked_shl(1), data)
}
#[doc = "Truncate to 32 bits and store"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst1w_scatter[_u64base]_index[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Addresses passed in `bases` lack provenance, so this is similar to using a `usize as ptr` cast (or [`core::ptr::from_exposed_addr`]) on each lane before using it."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st1w))]
pub unsafe fn svst1w_scatter_u64base_index_u64(
    pg: svbool_t,
    bases: svuint64_t,
    index: i64,
    data: svuint64_t,
) {
    svst1w_scatter_u64base_offset_u64(pg, bases, index.unchecked_shl(2), data)
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2w))]
pub unsafe fn svst2_f32(pg: svbool_t, base: *mut f32, data: svfloat32x2_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st2.nxv4f32")]
        fn _svst2_f32(data0: svfloat32_t, data1: svfloat32_t, pg: svbool4_t, ptr: *mut f32);
    }
    _svst2_f32(
        svget2_f32::<0>(data),
        svget2_f32::<1>(data),
        pg.into(),
        base,
    )
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2d))]
pub unsafe fn svst2_f64(pg: svbool_t, base: *mut f64, data: svfloat64x2_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st2.nxv2f64")]
        fn _svst2_f64(data0: svfloat64_t, data1: svfloat64_t, pg: svbool2_t, ptr: *mut f64);
    }
    _svst2_f64(
        svget2_f64::<0>(data),
        svget2_f64::<1>(data),
        pg.into(),
        base,
    )
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2b))]
pub unsafe fn svst2_s8(pg: svbool_t, base: *mut i8, data: svint8x2_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st2.nxv16i8")]
        fn _svst2_s8(data0: svint8_t, data1: svint8_t, pg: svbool_t, ptr: *mut i8);
    }
    _svst2_s8(svget2_s8::<0>(data), svget2_s8::<1>(data), pg, base)
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2h))]
pub unsafe fn svst2_s16(pg: svbool_t, base: *mut i16, data: svint16x2_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st2.nxv8i16")]
        fn _svst2_s16(data0: svint16_t, data1: svint16_t, pg: svbool8_t, ptr: *mut i16);
    }
    _svst2_s16(
        svget2_s16::<0>(data),
        svget2_s16::<1>(data),
        pg.into(),
        base,
    )
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2w))]
pub unsafe fn svst2_s32(pg: svbool_t, base: *mut i32, data: svint32x2_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st2.nxv4i32")]
        fn _svst2_s32(data0: svint32_t, data1: svint32_t, pg: svbool4_t, ptr: *mut i32);
    }
    _svst2_s32(
        svget2_s32::<0>(data),
        svget2_s32::<1>(data),
        pg.into(),
        base,
    )
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2d))]
pub unsafe fn svst2_s64(pg: svbool_t, base: *mut i64, data: svint64x2_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st2.nxv2i64")]
        fn _svst2_s64(data0: svint64_t, data1: svint64_t, pg: svbool2_t, ptr: *mut i64);
    }
    _svst2_s64(
        svget2_s64::<0>(data),
        svget2_s64::<1>(data),
        pg.into(),
        base,
    )
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2b))]
pub unsafe fn svst2_u8(pg: svbool_t, base: *mut u8, data: svuint8x2_t) {
    svst2_s8(pg, base.as_signed(), data.as_signed())
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2h))]
pub unsafe fn svst2_u16(pg: svbool_t, base: *mut u16, data: svuint16x2_t) {
    svst2_s16(pg, base.as_signed(), data.as_signed())
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2w))]
pub unsafe fn svst2_u32(pg: svbool_t, base: *mut u32, data: svuint32x2_t) {
    svst2_s32(pg, base.as_signed(), data.as_signed())
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2d))]
pub unsafe fn svst2_u64(pg: svbool_t, base: *mut u64, data: svuint64x2_t) {
    svst2_s64(pg, base.as_signed(), data.as_signed())
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2_vnum[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2w))]
pub unsafe fn svst2_vnum_f32(pg: svbool_t, base: *mut f32, vnum: i64, data: svfloat32x2_t) {
    svst2_f32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2_vnum[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2d))]
pub unsafe fn svst2_vnum_f64(pg: svbool_t, base: *mut f64, vnum: i64, data: svfloat64x2_t) {
    svst2_f64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2_vnum[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2b))]
pub unsafe fn svst2_vnum_s8(pg: svbool_t, base: *mut i8, vnum: i64, data: svint8x2_t) {
    svst2_s8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2_vnum[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2h))]
pub unsafe fn svst2_vnum_s16(pg: svbool_t, base: *mut i16, vnum: i64, data: svint16x2_t) {
    svst2_s16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2_vnum[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2w))]
pub unsafe fn svst2_vnum_s32(pg: svbool_t, base: *mut i32, vnum: i64, data: svint32x2_t) {
    svst2_s32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2_vnum[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2d))]
pub unsafe fn svst2_vnum_s64(pg: svbool_t, base: *mut i64, vnum: i64, data: svint64x2_t) {
    svst2_s64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2_vnum[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2b))]
pub unsafe fn svst2_vnum_u8(pg: svbool_t, base: *mut u8, vnum: i64, data: svuint8x2_t) {
    svst2_u8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2_vnum[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2h))]
pub unsafe fn svst2_vnum_u16(pg: svbool_t, base: *mut u16, vnum: i64, data: svuint16x2_t) {
    svst2_u16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2_vnum[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2w))]
pub unsafe fn svst2_vnum_u32(pg: svbool_t, base: *mut u32, vnum: i64, data: svuint32x2_t) {
    svst2_u32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Store two vectors into two-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst2_vnum[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st2d))]
pub unsafe fn svst2_vnum_u64(pg: svbool_t, base: *mut u64, vnum: i64, data: svuint64x2_t) {
    svst2_u64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3w))]
pub unsafe fn svst3_f32(pg: svbool_t, base: *mut f32, data: svfloat32x3_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st3.nxv4f32")]
        fn _svst3_f32(
            data0: svfloat32_t,
            data1: svfloat32_t,
            data2: svfloat32_t,
            pg: svbool4_t,
            ptr: *mut f32,
        );
    }
    _svst3_f32(
        svget3_f32::<0>(data),
        svget3_f32::<1>(data),
        svget3_f32::<2>(data),
        pg.into(),
        base,
    )
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3d))]
pub unsafe fn svst3_f64(pg: svbool_t, base: *mut f64, data: svfloat64x3_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st3.nxv2f64")]
        fn _svst3_f64(
            data0: svfloat64_t,
            data1: svfloat64_t,
            data2: svfloat64_t,
            pg: svbool2_t,
            ptr: *mut f64,
        );
    }
    _svst3_f64(
        svget3_f64::<0>(data),
        svget3_f64::<1>(data),
        svget3_f64::<2>(data),
        pg.into(),
        base,
    )
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3b))]
pub unsafe fn svst3_s8(pg: svbool_t, base: *mut i8, data: svint8x3_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st3.nxv16i8")]
        fn _svst3_s8(data0: svint8_t, data1: svint8_t, data2: svint8_t, pg: svbool_t, ptr: *mut i8);
    }
    _svst3_s8(
        svget3_s8::<0>(data),
        svget3_s8::<1>(data),
        svget3_s8::<2>(data),
        pg,
        base,
    )
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3h))]
pub unsafe fn svst3_s16(pg: svbool_t, base: *mut i16, data: svint16x3_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st3.nxv8i16")]
        fn _svst3_s16(
            data0: svint16_t,
            data1: svint16_t,
            data2: svint16_t,
            pg: svbool8_t,
            ptr: *mut i16,
        );
    }
    _svst3_s16(
        svget3_s16::<0>(data),
        svget3_s16::<1>(data),
        svget3_s16::<2>(data),
        pg.into(),
        base,
    )
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3w))]
pub unsafe fn svst3_s32(pg: svbool_t, base: *mut i32, data: svint32x3_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st3.nxv4i32")]
        fn _svst3_s32(
            data0: svint32_t,
            data1: svint32_t,
            data2: svint32_t,
            pg: svbool4_t,
            ptr: *mut i32,
        );
    }
    _svst3_s32(
        svget3_s32::<0>(data),
        svget3_s32::<1>(data),
        svget3_s32::<2>(data),
        pg.into(),
        base,
    )
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3d))]
pub unsafe fn svst3_s64(pg: svbool_t, base: *mut i64, data: svint64x3_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st3.nxv2i64")]
        fn _svst3_s64(
            data0: svint64_t,
            data1: svint64_t,
            data2: svint64_t,
            pg: svbool2_t,
            ptr: *mut i64,
        );
    }
    _svst3_s64(
        svget3_s64::<0>(data),
        svget3_s64::<1>(data),
        svget3_s64::<2>(data),
        pg.into(),
        base,
    )
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3b))]
pub unsafe fn svst3_u8(pg: svbool_t, base: *mut u8, data: svuint8x3_t) {
    svst3_s8(pg, base.as_signed(), data.as_signed())
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3h))]
pub unsafe fn svst3_u16(pg: svbool_t, base: *mut u16, data: svuint16x3_t) {
    svst3_s16(pg, base.as_signed(), data.as_signed())
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3w))]
pub unsafe fn svst3_u32(pg: svbool_t, base: *mut u32, data: svuint32x3_t) {
    svst3_s32(pg, base.as_signed(), data.as_signed())
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3d))]
pub unsafe fn svst3_u64(pg: svbool_t, base: *mut u64, data: svuint64x3_t) {
    svst3_s64(pg, base.as_signed(), data.as_signed())
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3_vnum[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3w))]
pub unsafe fn svst3_vnum_f32(pg: svbool_t, base: *mut f32, vnum: i64, data: svfloat32x3_t) {
    svst3_f32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3_vnum[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3d))]
pub unsafe fn svst3_vnum_f64(pg: svbool_t, base: *mut f64, vnum: i64, data: svfloat64x3_t) {
    svst3_f64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3_vnum[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3b))]
pub unsafe fn svst3_vnum_s8(pg: svbool_t, base: *mut i8, vnum: i64, data: svint8x3_t) {
    svst3_s8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3_vnum[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3h))]
pub unsafe fn svst3_vnum_s16(pg: svbool_t, base: *mut i16, vnum: i64, data: svint16x3_t) {
    svst3_s16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3_vnum[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3w))]
pub unsafe fn svst3_vnum_s32(pg: svbool_t, base: *mut i32, vnum: i64, data: svint32x3_t) {
    svst3_s32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3_vnum[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3d))]
pub unsafe fn svst3_vnum_s64(pg: svbool_t, base: *mut i64, vnum: i64, data: svint64x3_t) {
    svst3_s64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3_vnum[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3b))]
pub unsafe fn svst3_vnum_u8(pg: svbool_t, base: *mut u8, vnum: i64, data: svuint8x3_t) {
    svst3_u8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3_vnum[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3h))]
pub unsafe fn svst3_vnum_u16(pg: svbool_t, base: *mut u16, vnum: i64, data: svuint16x3_t) {
    svst3_u16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3_vnum[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3w))]
pub unsafe fn svst3_vnum_u32(pg: svbool_t, base: *mut u32, vnum: i64, data: svuint32x3_t) {
    svst3_u32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Store three vectors into three-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst3_vnum[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st3d))]
pub unsafe fn svst3_vnum_u64(pg: svbool_t, base: *mut u64, vnum: i64, data: svuint64x3_t) {
    svst3_u64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4w))]
pub unsafe fn svst4_f32(pg: svbool_t, base: *mut f32, data: svfloat32x4_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st4.nxv4f32")]
        fn _svst4_f32(
            data0: svfloat32_t,
            data1: svfloat32_t,
            data2: svfloat32_t,
            data3: svfloat32_t,
            pg: svbool4_t,
            ptr: *mut f32,
        );
    }
    _svst4_f32(
        svget4_f32::<0>(data),
        svget4_f32::<1>(data),
        svget4_f32::<2>(data),
        svget4_f32::<3>(data),
        pg.into(),
        base,
    )
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4d))]
pub unsafe fn svst4_f64(pg: svbool_t, base: *mut f64, data: svfloat64x4_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st4.nxv2f64")]
        fn _svst4_f64(
            data0: svfloat64_t,
            data1: svfloat64_t,
            data2: svfloat64_t,
            data3: svfloat64_t,
            pg: svbool2_t,
            ptr: *mut f64,
        );
    }
    _svst4_f64(
        svget4_f64::<0>(data),
        svget4_f64::<1>(data),
        svget4_f64::<2>(data),
        svget4_f64::<3>(data),
        pg.into(),
        base,
    )
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4b))]
pub unsafe fn svst4_s8(pg: svbool_t, base: *mut i8, data: svint8x4_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st4.nxv16i8")]
        fn _svst4_s8(
            data0: svint8_t,
            data1: svint8_t,
            data2: svint8_t,
            data3: svint8_t,
            pg: svbool_t,
            ptr: *mut i8,
        );
    }
    _svst4_s8(
        svget4_s8::<0>(data),
        svget4_s8::<1>(data),
        svget4_s8::<2>(data),
        svget4_s8::<3>(data),
        pg,
        base,
    )
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4h))]
pub unsafe fn svst4_s16(pg: svbool_t, base: *mut i16, data: svint16x4_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st4.nxv8i16")]
        fn _svst4_s16(
            data0: svint16_t,
            data1: svint16_t,
            data2: svint16_t,
            data3: svint16_t,
            pg: svbool8_t,
            ptr: *mut i16,
        );
    }
    _svst4_s16(
        svget4_s16::<0>(data),
        svget4_s16::<1>(data),
        svget4_s16::<2>(data),
        svget4_s16::<3>(data),
        pg.into(),
        base,
    )
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4w))]
pub unsafe fn svst4_s32(pg: svbool_t, base: *mut i32, data: svint32x4_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st4.nxv4i32")]
        fn _svst4_s32(
            data0: svint32_t,
            data1: svint32_t,
            data2: svint32_t,
            data3: svint32_t,
            pg: svbool4_t,
            ptr: *mut i32,
        );
    }
    _svst4_s32(
        svget4_s32::<0>(data),
        svget4_s32::<1>(data),
        svget4_s32::<2>(data),
        svget4_s32::<3>(data),
        pg.into(),
        base,
    )
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4d))]
pub unsafe fn svst4_s64(pg: svbool_t, base: *mut i64, data: svint64x4_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.st4.nxv2i64")]
        fn _svst4_s64(
            data0: svint64_t,
            data1: svint64_t,
            data2: svint64_t,
            data3: svint64_t,
            pg: svbool2_t,
            ptr: *mut i64,
        );
    }
    _svst4_s64(
        svget4_s64::<0>(data),
        svget4_s64::<1>(data),
        svget4_s64::<2>(data),
        svget4_s64::<3>(data),
        pg.into(),
        base,
    )
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4b))]
pub unsafe fn svst4_u8(pg: svbool_t, base: *mut u8, data: svuint8x4_t) {
    svst4_s8(pg, base.as_signed(), data.as_signed())
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4h))]
pub unsafe fn svst4_u16(pg: svbool_t, base: *mut u16, data: svuint16x4_t) {
    svst4_s16(pg, base.as_signed(), data.as_signed())
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4w))]
pub unsafe fn svst4_u32(pg: svbool_t, base: *mut u32, data: svuint32x4_t) {
    svst4_s32(pg, base.as_signed(), data.as_signed())
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4d))]
pub unsafe fn svst4_u64(pg: svbool_t, base: *mut u64, data: svuint64x4_t) {
    svst4_s64(pg, base.as_signed(), data.as_signed())
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4_vnum[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4w))]
pub unsafe fn svst4_vnum_f32(pg: svbool_t, base: *mut f32, vnum: i64, data: svfloat32x4_t) {
    svst4_f32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4_vnum[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4d))]
pub unsafe fn svst4_vnum_f64(pg: svbool_t, base: *mut f64, vnum: i64, data: svfloat64x4_t) {
    svst4_f64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4_vnum[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4b))]
pub unsafe fn svst4_vnum_s8(pg: svbool_t, base: *mut i8, vnum: i64, data: svint8x4_t) {
    svst4_s8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4_vnum[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4h))]
pub unsafe fn svst4_vnum_s16(pg: svbool_t, base: *mut i16, vnum: i64, data: svint16x4_t) {
    svst4_s16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4_vnum[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4w))]
pub unsafe fn svst4_vnum_s32(pg: svbool_t, base: *mut i32, vnum: i64, data: svint32x4_t) {
    svst4_s32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4_vnum[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4d))]
pub unsafe fn svst4_vnum_s64(pg: svbool_t, base: *mut i64, vnum: i64, data: svint64x4_t) {
    svst4_s64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4_vnum[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4b))]
pub unsafe fn svst4_vnum_u8(pg: svbool_t, base: *mut u8, vnum: i64, data: svuint8x4_t) {
    svst4_u8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4_vnum[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4h))]
pub unsafe fn svst4_vnum_u16(pg: svbool_t, base: *mut u16, vnum: i64, data: svuint16x4_t) {
    svst4_u16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4_vnum[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4w))]
pub unsafe fn svst4_vnum_u32(pg: svbool_t, base: *mut u32, vnum: i64, data: svuint32x4_t) {
    svst4_u32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Store four vectors into four-element tuples"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svst4_vnum[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`). In particular, note that `vnum` is scaled by the vector length, `VL`, which is not known at compile time."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(st4d))]
pub unsafe fn svst4_vnum_u64(pg: svbool_t, base: *mut u64, vnum: i64, data: svuint64x4_t) {
    svst4_u64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1w))]
pub unsafe fn svstnt1_f32(pg: svbool_t, base: *mut f32, data: svfloat32_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.stnt1.nxv4f32")]
        fn _svstnt1_f32(data: svfloat32_t, pg: svbool4_t, ptr: *mut f32);
    }
    _svstnt1_f32(data, pg.into(), base)
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1d))]
pub unsafe fn svstnt1_f64(pg: svbool_t, base: *mut f64, data: svfloat64_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.stnt1.nxv2f64")]
        fn _svstnt1_f64(data: svfloat64_t, pg: svbool2_t, ptr: *mut f64);
    }
    _svstnt1_f64(data, pg.into(), base)
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1b))]
pub unsafe fn svstnt1_s8(pg: svbool_t, base: *mut i8, data: svint8_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.stnt1.nxv16i8")]
        fn _svstnt1_s8(data: svint8_t, pg: svbool_t, ptr: *mut i8);
    }
    _svstnt1_s8(data, pg, base)
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1h))]
pub unsafe fn svstnt1_s16(pg: svbool_t, base: *mut i16, data: svint16_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.stnt1.nxv8i16")]
        fn _svstnt1_s16(data: svint16_t, pg: svbool8_t, ptr: *mut i16);
    }
    _svstnt1_s16(data, pg.into(), base)
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1w))]
pub unsafe fn svstnt1_s32(pg: svbool_t, base: *mut i32, data: svint32_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.stnt1.nxv4i32")]
        fn _svstnt1_s32(data: svint32_t, pg: svbool4_t, ptr: *mut i32);
    }
    _svstnt1_s32(data, pg.into(), base)
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1d))]
pub unsafe fn svstnt1_s64(pg: svbool_t, base: *mut i64, data: svint64_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.stnt1.nxv2i64")]
        fn _svstnt1_s64(data: svint64_t, pg: svbool2_t, ptr: *mut i64);
    }
    _svstnt1_s64(data, pg.into(), base)
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1b))]
pub unsafe fn svstnt1_u8(pg: svbool_t, base: *mut u8, data: svuint8_t) {
    svstnt1_s8(pg, base.as_signed(), data.as_signed())
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1h))]
pub unsafe fn svstnt1_u16(pg: svbool_t, base: *mut u16, data: svuint16_t) {
    svstnt1_s16(pg, base.as_signed(), data.as_signed())
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1w))]
pub unsafe fn svstnt1_u32(pg: svbool_t, base: *mut u32, data: svuint32_t) {
    svstnt1_s32(pg, base.as_signed(), data.as_signed())
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1d))]
pub unsafe fn svstnt1_u64(pg: svbool_t, base: *mut u64, data: svuint64_t) {
    svstnt1_s64(pg, base.as_signed(), data.as_signed())
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1_vnum[_f32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1w))]
pub unsafe fn svstnt1_vnum_f32(pg: svbool_t, base: *mut f32, vnum: i64, data: svfloat32_t) {
    svstnt1_f32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1_vnum[_f64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1d))]
pub unsafe fn svstnt1_vnum_f64(pg: svbool_t, base: *mut f64, vnum: i64, data: svfloat64_t) {
    svstnt1_f64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1_vnum[_s8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1b))]
pub unsafe fn svstnt1_vnum_s8(pg: svbool_t, base: *mut i8, vnum: i64, data: svint8_t) {
    svstnt1_s8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1_vnum[_s16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1h))]
pub unsafe fn svstnt1_vnum_s16(pg: svbool_t, base: *mut i16, vnum: i64, data: svint16_t) {
    svstnt1_s16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1_vnum[_s32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1w))]
pub unsafe fn svstnt1_vnum_s32(pg: svbool_t, base: *mut i32, vnum: i64, data: svint32_t) {
    svstnt1_s32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1_vnum[_s64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1d))]
pub unsafe fn svstnt1_vnum_s64(pg: svbool_t, base: *mut i64, vnum: i64, data: svint64_t) {
    svstnt1_s64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1_vnum[_u8])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1b))]
pub unsafe fn svstnt1_vnum_u8(pg: svbool_t, base: *mut u8, vnum: i64, data: svuint8_t) {
    svstnt1_u8(pg, base.offset(svcntb() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1_vnum[_u16])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1h))]
pub unsafe fn svstnt1_vnum_u16(pg: svbool_t, base: *mut u16, vnum: i64, data: svuint16_t) {
    svstnt1_u16(pg, base.offset(svcnth() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1_vnum[_u32])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1w))]
pub unsafe fn svstnt1_vnum_u32(pg: svbool_t, base: *mut u32, vnum: i64, data: svuint32_t) {
    svstnt1_u32(pg, base.offset(svcntw() as isize * vnum as isize), data)
}
#[doc = "Non-truncating store, non-temporal"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svstnt1_vnum[_u64])"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * [`pointer::offset`](pointer#method.offset) safety constraints must be met for the address calculation for each active element (governed by `pg`)."]
#[doc = "  * This dereferences and accesses the calculated address for each active element (governed by `pg`)."]
#[doc = "  * Non-temporal accesses have special memory ordering rules, and [explicit barriers may be required for some applications](https://developer.arm.com/documentation/den0024/a/Memory-Ordering/Barriers/Non-temporal-load-and-store-pair?lang=en)."]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(stnt1d))]
pub unsafe fn svstnt1_vnum_u64(pg: svbool_t, base: *mut u64, vnum: i64, data: svuint64_t) {
    svstnt1_u64(pg, base.offset(svcntd() as isize * vnum as isize), data)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub fn svsub_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fsub.nxv4f32")]
        fn _svsub_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svsub_f32_m(pg.into(), op1, op2) }
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub fn svsub_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svsub_f32_m(pg, op1, svdup_n_f32(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub fn svsub_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svsub_f32_m(pg, op1, op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub fn svsub_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svsub_f32_x(pg, op1, svdup_n_f32(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub fn svsub_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svsub_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub fn svsub_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svsub_f32_z(pg, op1, svdup_n_f32(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub fn svsub_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fsub.nxv2f64")]
        fn _svsub_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svsub_f64_m(pg.into(), op1, op2) }
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub fn svsub_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svsub_f64_m(pg, op1, svdup_n_f64(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub fn svsub_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svsub_f64_m(pg, op1, op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub fn svsub_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svsub_f64_x(pg, op1, svdup_n_f64(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub fn svsub_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svsub_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsub))]
pub fn svsub_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svsub_f64_z(pg, op1, svdup_n_f64(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sub.nxv16i8")]
        fn _svsub_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svsub_s8_m(pg, op1, op2) }
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svsub_s8_m(pg, op1, svdup_n_s8(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svsub_s8_m(pg, op1, op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svsub_s8_x(pg, op1, svdup_n_s8(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svsub_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svsub_s8_z(pg, op1, svdup_n_s8(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sub.nxv8i16")]
        fn _svsub_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svsub_s16_m(pg.into(), op1, op2) }
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svsub_s16_m(pg, op1, svdup_n_s16(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svsub_s16_m(pg, op1, op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svsub_s16_x(pg, op1, svdup_n_s16(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svsub_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svsub_s16_z(pg, op1, svdup_n_s16(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sub.nxv4i32")]
        fn _svsub_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svsub_s32_m(pg.into(), op1, op2) }
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svsub_s32_m(pg, op1, svdup_n_s32(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svsub_s32_m(pg, op1, op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svsub_s32_x(pg, op1, svdup_n_s32(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svsub_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svsub_s32_z(pg, op1, svdup_n_s32(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.sub.nxv2i64")]
        fn _svsub_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svsub_s64_m(pg.into(), op1, op2) }
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svsub_s64_m(pg, op1, svdup_n_s64(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svsub_s64_m(pg, op1, op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svsub_s64_x(pg, op1, svdup_n_s64(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svsub_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svsub_s64_z(pg, op1, svdup_n_s64(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svsub_s8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svsub_u8_m(pg, op1, svdup_n_u8(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svsub_u8_m(pg, op1, op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svsub_u8_x(pg, op1, svdup_n_u8(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svsub_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svsub_u8_z(pg, op1, svdup_n_u8(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svsub_s16_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svsub_u16_m(pg, op1, svdup_n_u16(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svsub_u16_m(pg, op1, op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svsub_u16_x(pg, op1, svdup_n_u16(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svsub_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svsub_u16_z(pg, op1, svdup_n_u16(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svsub_s32_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svsub_u32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svsub_u32_m(pg, op1, op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svsub_u32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svsub_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svsub_u32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svsub_s64_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svsub_u64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svsub_u64_m(pg, op1, op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svsub_u64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svsub_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[doc = "Subtract"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsub[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(sub))]
pub fn svsub_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svsub_u64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub fn svsubr_f32_m(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fsubr.nxv4f32")]
        fn _svsubr_f32_m(pg: svbool4_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svsubr_f32_m(pg.into(), op1, op2) }
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_f32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub fn svsubr_n_f32_m(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svsubr_f32_m(pg, op1, svdup_n_f32(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub fn svsubr_f32_x(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svsubr_f32_m(pg, op1, op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_f32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub fn svsubr_n_f32_x(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svsubr_f32_x(pg, op1, svdup_n_f32(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub fn svsubr_f32_z(pg: svbool_t, op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    svsubr_f32_m(pg, svsel_f32(pg, op1, svdup_n_f32(0.0)), op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_f32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub fn svsubr_n_f32_z(pg: svbool_t, op1: svfloat32_t, op2: f32) -> svfloat32_t {
    svsubr_f32_z(pg, op1, svdup_n_f32(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub fn svsubr_f64_m(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.fsubr.nxv2f64")]
        fn _svsubr_f64_m(pg: svbool2_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svsubr_f64_m(pg.into(), op1, op2) }
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_f64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub fn svsubr_n_f64_m(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svsubr_f64_m(pg, op1, svdup_n_f64(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub fn svsubr_f64_x(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svsubr_f64_m(pg, op1, op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_f64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub fn svsubr_n_f64_x(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svsubr_f64_x(pg, op1, svdup_n_f64(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub fn svsubr_f64_z(pg: svbool_t, op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    svsubr_f64_m(pg, svsel_f64(pg, op1, svdup_n_f64(0.0)), op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_f64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(fsubr))]
pub fn svsubr_n_f64_z(pg: svbool_t, op1: svfloat64_t, op2: f64) -> svfloat64_t {
    svsubr_f64_z(pg, op1, svdup_n_f64(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.subr.nxv16i8")]
        fn _svsubr_s8_m(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svsubr_s8_m(pg, op1, op2) }
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_s8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_s8_m(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svsubr_s8_m(pg, op1, svdup_n_s8(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_s8_x(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svsubr_s8_m(pg, op1, op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_s8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_s8_x(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svsubr_s8_x(pg, op1, svdup_n_s8(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_s8_z(pg: svbool_t, op1: svint8_t, op2: svint8_t) -> svint8_t {
    svsubr_s8_m(pg, svsel_s8(pg, op1, svdup_n_s8(0)), op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_s8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_s8_z(pg: svbool_t, op1: svint8_t, op2: i8) -> svint8_t {
    svsubr_s8_z(pg, op1, svdup_n_s8(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_s16_m(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.subr.nxv8i16")]
        fn _svsubr_s16_m(pg: svbool8_t, op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svsubr_s16_m(pg.into(), op1, op2) }
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_s16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_s16_m(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svsubr_s16_m(pg, op1, svdup_n_s16(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_s16_x(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svsubr_s16_m(pg, op1, op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_s16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_s16_x(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svsubr_s16_x(pg, op1, svdup_n_s16(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_s16_z(pg: svbool_t, op1: svint16_t, op2: svint16_t) -> svint16_t {
    svsubr_s16_m(pg, svsel_s16(pg, op1, svdup_n_s16(0)), op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_s16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_s16_z(pg: svbool_t, op1: svint16_t, op2: i16) -> svint16_t {
    svsubr_s16_z(pg, op1, svdup_n_s16(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_s32_m(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.subr.nxv4i32")]
        fn _svsubr_s32_m(pg: svbool4_t, op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svsubr_s32_m(pg.into(), op1, op2) }
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_s32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_s32_m(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svsubr_s32_m(pg, op1, svdup_n_s32(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_s32_x(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svsubr_s32_m(pg, op1, op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_s32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_s32_x(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svsubr_s32_x(pg, op1, svdup_n_s32(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_s32_z(pg: svbool_t, op1: svint32_t, op2: svint32_t) -> svint32_t {
    svsubr_s32_m(pg, svsel_s32(pg, op1, svdup_n_s32(0)), op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_s32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_s32_z(pg: svbool_t, op1: svint32_t, op2: i32) -> svint32_t {
    svsubr_s32_z(pg, op1, svdup_n_s32(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_s64_m(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.subr.nxv2i64")]
        fn _svsubr_s64_m(pg: svbool2_t, op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svsubr_s64_m(pg.into(), op1, op2) }
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_s64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_s64_m(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svsubr_s64_m(pg, op1, svdup_n_s64(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_s64_x(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svsubr_s64_m(pg, op1, op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_s64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_s64_x(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svsubr_s64_x(pg, op1, svdup_n_s64(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_s64_z(pg: svbool_t, op1: svint64_t, op2: svint64_t) -> svint64_t {
    svsubr_s64_m(pg, svsel_s64(pg, op1, svdup_n_s64(0)), op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_s64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_s64_z(pg: svbool_t, op1: svint64_t, op2: i64) -> svint64_t {
    svsubr_s64_z(pg, op1, svdup_n_s64(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_u8_m(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svsubr_s8_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_u8]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_u8_m(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svsubr_u8_m(pg, op1, svdup_n_u8(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_u8_x(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svsubr_u8_m(pg, op1, op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_u8]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_u8_x(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svsubr_u8_x(pg, op1, svdup_n_u8(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_u8_z(pg: svbool_t, op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    svsubr_u8_m(pg, svsel_u8(pg, op1, svdup_n_u8(0)), op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_u8]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_u8_z(pg: svbool_t, op1: svuint8_t, op2: u8) -> svuint8_t {
    svsubr_u8_z(pg, op1, svdup_n_u8(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_u16_m(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svsubr_s16_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_u16]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_u16_m(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svsubr_u16_m(pg, op1, svdup_n_u16(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_u16_x(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svsubr_u16_m(pg, op1, op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_u16]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_u16_x(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svsubr_u16_x(pg, op1, svdup_n_u16(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_u16_z(pg: svbool_t, op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    svsubr_u16_m(pg, svsel_u16(pg, op1, svdup_n_u16(0)), op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_u16]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_u16_z(pg: svbool_t, op1: svuint16_t, op2: u16) -> svuint16_t {
    svsubr_u16_z(pg, op1, svdup_n_u16(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_u32_m(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svsubr_s32_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_u32]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_u32_m(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svsubr_u32_m(pg, op1, svdup_n_u32(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_u32_x(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svsubr_u32_m(pg, op1, op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_u32]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_u32_x(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svsubr_u32_x(pg, op1, svdup_n_u32(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_u32_z(pg: svbool_t, op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    svsubr_u32_m(pg, svsel_u32(pg, op1, svdup_n_u32(0)), op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_u32]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_u32_z(pg: svbool_t, op1: svuint32_t, op2: u32) -> svuint32_t {
    svsubr_u32_z(pg, op1, svdup_n_u32(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_u64_m(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svsubr_s64_m(pg, op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_u64]_m)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_u64_m(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svsubr_u64_m(pg, op1, svdup_n_u64(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_u64_x(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svsubr_u64_m(pg, op1, op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_u64]_x)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_u64_x(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svsubr_u64_x(pg, op1, svdup_n_u64(op2))
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_u64_z(pg: svbool_t, op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    svsubr_u64_m(pg, svsel_u64(pg, op1, svdup_n_u64(0)), op2)
}
#[doc = "Subtract reversed"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsubr[_n_u64]_z)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(subr))]
pub fn svsubr_n_u64_z(pg: svbool_t, op1: svuint64_t, op2: u64) -> svuint64_t {
    svsubr_u64_z(pg, op1, svdup_n_u64(op2))
}
#[doc = "Dot product (signed × unsigned)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsudot_lane[_s32])"]
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(sudot, IMM_INDEX = 0))]
pub fn svsudot_lane_s32<const IMM_INDEX: i32>(
    op1: svint32_t,
    op2: svint8_t,
    op3: svuint8_t,
) -> svint32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.sudot.lane.nxv4i32"
        )]
        fn _svsudot_lane_s32(
            op1: svint32_t,
            op2: svint8_t,
            op3: svint8_t,
            imm_index: i32,
        ) -> svint32_t;
    }
    unsafe { _svsudot_lane_s32(op1, op2, op3.as_signed(), IMM_INDEX) }
}
#[doc = "Dot product (signed × unsigned)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsudot[_s32])"]
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(usdot))]
pub fn svsudot_s32(op1: svint32_t, op2: svint8_t, op3: svuint8_t) -> svint32_t {
    svusdot_s32(op1, op3, op2)
}
#[doc = "Dot product (signed × unsigned)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svsudot[_n_s32])"]
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(usdot))]
pub fn svsudot_n_s32(op1: svint32_t, op2: svint8_t, op3: u8) -> svint32_t {
    svsudot_s32(op1, op2, svdup_n_u8(op3))
}
#[doc = "Table lookup in single-vector table"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtbl[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svtbl_f32(data: svfloat32_t, indices: svuint32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.tbl.nxv4f32")]
        fn _svtbl_f32(data: svfloat32_t, indices: svint32_t) -> svfloat32_t;
    }
    unsafe { _svtbl_f32(data, indices.as_signed()) }
}
#[doc = "Table lookup in single-vector table"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtbl[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svtbl_f64(data: svfloat64_t, indices: svuint64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.tbl.nxv2f64")]
        fn _svtbl_f64(data: svfloat64_t, indices: svint64_t) -> svfloat64_t;
    }
    unsafe { _svtbl_f64(data, indices.as_signed()) }
}
#[doc = "Table lookup in single-vector table"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtbl[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svtbl_s8(data: svint8_t, indices: svuint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.tbl.nxv16i8")]
        fn _svtbl_s8(data: svint8_t, indices: svint8_t) -> svint8_t;
    }
    unsafe { _svtbl_s8(data, indices.as_signed()) }
}
#[doc = "Table lookup in single-vector table"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtbl[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svtbl_s16(data: svint16_t, indices: svuint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.tbl.nxv8i16")]
        fn _svtbl_s16(data: svint16_t, indices: svint16_t) -> svint16_t;
    }
    unsafe { _svtbl_s16(data, indices.as_signed()) }
}
#[doc = "Table lookup in single-vector table"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtbl[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svtbl_s32(data: svint32_t, indices: svuint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.tbl.nxv4i32")]
        fn _svtbl_s32(data: svint32_t, indices: svint32_t) -> svint32_t;
    }
    unsafe { _svtbl_s32(data, indices.as_signed()) }
}
#[doc = "Table lookup in single-vector table"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtbl[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svtbl_s64(data: svint64_t, indices: svuint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.tbl.nxv2i64")]
        fn _svtbl_s64(data: svint64_t, indices: svint64_t) -> svint64_t;
    }
    unsafe { _svtbl_s64(data, indices.as_signed()) }
}
#[doc = "Table lookup in single-vector table"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtbl[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svtbl_u8(data: svuint8_t, indices: svuint8_t) -> svuint8_t {
    unsafe { svtbl_s8(data.as_signed(), indices).as_unsigned() }
}
#[doc = "Table lookup in single-vector table"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtbl[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svtbl_u16(data: svuint16_t, indices: svuint16_t) -> svuint16_t {
    unsafe { svtbl_s16(data.as_signed(), indices).as_unsigned() }
}
#[doc = "Table lookup in single-vector table"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtbl[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svtbl_u32(data: svuint32_t, indices: svuint32_t) -> svuint32_t {
    unsafe { svtbl_s32(data.as_signed(), indices).as_unsigned() }
}
#[doc = "Table lookup in single-vector table"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtbl[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(tbl))]
pub fn svtbl_u64(data: svuint64_t, indices: svuint64_t) -> svuint64_t {
    unsafe { svtbl_s64(data.as_signed(), indices).as_unsigned() }
}
#[doc = "Trigonometric multiply-add coefficient"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtmad[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ftmad, IMM3 = 0))]
pub fn svtmad_f32<const IMM3: i32>(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    static_assert_range!(IMM3, 0, 7);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ftmad.x.nxv4f32"
        )]
        fn _svtmad_f32(op1: svfloat32_t, op2: svfloat32_t, imm3: i32) -> svfloat32_t;
    }
    unsafe { _svtmad_f32(op1, op2, IMM3) }
}
#[doc = "Trigonometric multiply-add coefficient"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtmad[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ftmad, IMM3 = 0))]
pub fn svtmad_f64<const IMM3: i32>(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    static_assert_range!(IMM3, 0, 7);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ftmad.x.nxv2f64"
        )]
        fn _svtmad_f64(op1: svfloat64_t, op2: svfloat64_t, imm3: i32) -> svfloat64_t;
    }
    unsafe { _svtmad_f64(op1, op2, IMM3) }
}
#[doc = "Interleave even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1_b8(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv16i1")]
        fn _svtrn1_b8(op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svtrn1_b8(op1, op2) }
}
#[doc = "Interleave even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1_b16(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv8i1")]
        fn _svtrn1_b16(op1: svbool8_t, op2: svbool8_t) -> svbool8_t;
    }
    unsafe { _svtrn1_b16(op1.into(), op2.into()).into() }
}
#[doc = "Interleave even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1_b32(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv4i1")]
        fn _svtrn1_b32(op1: svbool4_t, op2: svbool4_t) -> svbool4_t;
    }
    unsafe { _svtrn1_b32(op1.into(), op2.into()).into() }
}
#[doc = "Interleave even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1_b64(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv2i1")]
        fn _svtrn1_b64(op1: svbool2_t, op2: svbool2_t) -> svbool2_t;
    }
    unsafe { _svtrn1_b64(op1.into(), op2.into()).into() }
}
#[doc = "Interleave even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv4f32")]
        fn _svtrn1_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svtrn1_f32(op1, op2) }
}
#[doc = "Interleave even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv2f64")]
        fn _svtrn1_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svtrn1_f64(op1, op2) }
}
#[doc = "Interleave even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv16i8")]
        fn _svtrn1_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svtrn1_s8(op1, op2) }
}
#[doc = "Interleave even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv8i16")]
        fn _svtrn1_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svtrn1_s16(op1, op2) }
}
#[doc = "Interleave even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv4i32")]
        fn _svtrn1_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svtrn1_s32(op1, op2) }
}
#[doc = "Interleave even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1.nxv2i64")]
        fn _svtrn1_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svtrn1_s64(op1, op2) }
}
#[doc = "Interleave even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svtrn1_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svtrn1_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svtrn1_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svtrn1_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1q[_f32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1q.nxv4f32")]
        fn _svtrn1q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svtrn1q_f32(op1, op2) }
}
#[doc = "Interleave even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1q[_f64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1q.nxv2f64")]
        fn _svtrn1q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svtrn1q_f64(op1, op2) }
}
#[doc = "Interleave even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1q[_s8])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1q.nxv16i8")]
        fn _svtrn1q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svtrn1q_s8(op1, op2) }
}
#[doc = "Interleave even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1q[_s16])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1q.nxv8i16")]
        fn _svtrn1q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svtrn1q_s16(op1, op2) }
}
#[doc = "Interleave even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1q[_s32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1q.nxv4i32")]
        fn _svtrn1q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svtrn1q_s32(op1, op2) }
}
#[doc = "Interleave even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1q[_s64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn1q.nxv2i64")]
        fn _svtrn1q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svtrn1q_s64(op1, op2) }
}
#[doc = "Interleave even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1q[_u8])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1q_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svtrn1q_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1q[_u16])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1q_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svtrn1q_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1q[_u32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1q_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svtrn1q_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn1q[_u64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn1))]
pub fn svtrn1q_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svtrn1q_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2_b8(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv16i1")]
        fn _svtrn2_b8(op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svtrn2_b8(op1, op2) }
}
#[doc = "Interleave odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2_b16(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv8i1")]
        fn _svtrn2_b16(op1: svbool8_t, op2: svbool8_t) -> svbool8_t;
    }
    unsafe { _svtrn2_b16(op1.into(), op2.into()).into() }
}
#[doc = "Interleave odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2_b32(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv4i1")]
        fn _svtrn2_b32(op1: svbool4_t, op2: svbool4_t) -> svbool4_t;
    }
    unsafe { _svtrn2_b32(op1.into(), op2.into()).into() }
}
#[doc = "Interleave odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2_b64(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv2i1")]
        fn _svtrn2_b64(op1: svbool2_t, op2: svbool2_t) -> svbool2_t;
    }
    unsafe { _svtrn2_b64(op1.into(), op2.into()).into() }
}
#[doc = "Interleave odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv4f32")]
        fn _svtrn2_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svtrn2_f32(op1, op2) }
}
#[doc = "Interleave odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv2f64")]
        fn _svtrn2_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svtrn2_f64(op1, op2) }
}
#[doc = "Interleave odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv16i8")]
        fn _svtrn2_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svtrn2_s8(op1, op2) }
}
#[doc = "Interleave odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv8i16")]
        fn _svtrn2_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svtrn2_s16(op1, op2) }
}
#[doc = "Interleave odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv4i32")]
        fn _svtrn2_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svtrn2_s32(op1, op2) }
}
#[doc = "Interleave odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2.nxv2i64")]
        fn _svtrn2_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svtrn2_s64(op1, op2) }
}
#[doc = "Interleave odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svtrn2_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svtrn2_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svtrn2_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svtrn2_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2q[_f32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2q.nxv4f32")]
        fn _svtrn2q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svtrn2q_f32(op1, op2) }
}
#[doc = "Interleave odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2q[_f64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2q.nxv2f64")]
        fn _svtrn2q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svtrn2q_f64(op1, op2) }
}
#[doc = "Interleave odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2q[_s8])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2q.nxv16i8")]
        fn _svtrn2q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svtrn2q_s8(op1, op2) }
}
#[doc = "Interleave odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2q[_s16])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2q.nxv8i16")]
        fn _svtrn2q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svtrn2q_s16(op1, op2) }
}
#[doc = "Interleave odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2q[_s32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2q.nxv4i32")]
        fn _svtrn2q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svtrn2q_s32(op1, op2) }
}
#[doc = "Interleave odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2q[_s64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.trn2q.nxv2i64")]
        fn _svtrn2q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svtrn2q_s64(op1, op2) }
}
#[doc = "Interleave odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2q[_u8])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2q_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svtrn2q_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2q[_u16])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2q_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svtrn2q_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2q[_u32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2q_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svtrn2q_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtrn2q[_u64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(trn2))]
pub fn svtrn2q_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svtrn2q_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Trigonometric starting value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtsmul[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ftsmul))]
pub fn svtsmul_f32(op1: svfloat32_t, op2: svuint32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ftsmul.x.nxv4f32"
        )]
        fn _svtsmul_f32(op1: svfloat32_t, op2: svint32_t) -> svfloat32_t;
    }
    unsafe { _svtsmul_f32(op1, op2.as_signed()) }
}
#[doc = "Trigonometric starting value"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtsmul[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ftsmul))]
pub fn svtsmul_f64(op1: svfloat64_t, op2: svuint64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ftsmul.x.nxv2f64"
        )]
        fn _svtsmul_f64(op1: svfloat64_t, op2: svint64_t) -> svfloat64_t;
    }
    unsafe { _svtsmul_f64(op1, op2.as_signed()) }
}
#[doc = "Trigonometric select coefficient"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtssel[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ftssel))]
pub fn svtssel_f32(op1: svfloat32_t, op2: svuint32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ftssel.x.nxv4f32"
        )]
        fn _svtssel_f32(op1: svfloat32_t, op2: svint32_t) -> svfloat32_t;
    }
    unsafe { _svtssel_f32(op1, op2.as_signed()) }
}
#[doc = "Trigonometric select coefficient"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svtssel[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(ftssel))]
pub fn svtssel_f64(op1: svfloat64_t, op2: svuint64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.ftssel.x.nxv2f64"
        )]
        fn _svtssel_f64(op1: svfloat64_t, op2: svint64_t) -> svfloat64_t;
    }
    unsafe { _svtssel_f64(op1, op2.as_signed()) }
}
#[doc = "Create an uninitialized tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef2_f32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_f32() -> svfloat32x2_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef2_f64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_f64() -> svfloat64x2_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef2_s8)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_s8() -> svint8x2_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef2_s16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_s16() -> svint16x2_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef2_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_s32() -> svint32x2_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef2_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_s64() -> svint64x2_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef2_u8)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_u8() -> svuint8x2_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef2_u16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_u16() -> svuint16x2_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef2_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_u32() -> svuint32x2_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of two vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef2_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef2_u64() -> svuint64x2_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef3_f32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_f32() -> svfloat32x3_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef3_f64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_f64() -> svfloat64x3_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef3_s8)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_s8() -> svint8x3_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef3_s16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_s16() -> svint16x3_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef3_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_s32() -> svint32x3_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef3_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_s64() -> svint64x3_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef3_u8)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_u8() -> svuint8x3_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef3_u16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_u16() -> svuint16x3_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef3_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_u32() -> svuint32x3_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of three vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef3_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef3_u64() -> svuint64x3_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef4_f32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_f32() -> svfloat32x4_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef4_f64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_f64() -> svfloat64x4_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef4_s8)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_s8() -> svint8x4_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef4_s16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_s16() -> svint16x4_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef4_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_s32() -> svint32x4_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef4_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_s64() -> svint64x4_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef4_u8)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_u8() -> svuint8x4_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef4_u16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_u16() -> svuint16x4_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef4_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_u32() -> svuint32x4_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized tuple of four vectors"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef4_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef4_u64() -> svuint64x4_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef_f32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_f32() -> svfloat32_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef_f64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_f64() -> svfloat64_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef_s8)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_s8() -> svint8_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef_s16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_s16() -> svint16_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef_s32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_s32() -> svint32_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef_s64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_s64() -> svint64_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef_u8)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_u8() -> svuint8_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef_u16)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_u16() -> svuint16_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef_u32)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_u32() -> svuint32_t {
    simd_reinterpret(())
}
#[doc = "Create an uninitialized vector"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svundef_u64)"]
#[doc = ""]
#[doc = "## Safety"]
#[doc = "  * This creates an uninitialized value, and may be unsound (like [`core::mem::uninitialized`])."]
#[inline]
#[target_feature(enable = "sve")]
pub unsafe fn svundef_u64() -> svuint64_t {
    simd_reinterpret(())
}
#[doc = "Dot product (unsigned × signed)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svusdot_lane[_s32])"]
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(usdot, IMM_INDEX = 0))]
pub fn svusdot_lane_s32<const IMM_INDEX: i32>(
    op1: svint32_t,
    op2: svuint8_t,
    op3: svint8_t,
) -> svint32_t {
    static_assert_range!(IMM_INDEX, 0, 3);
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.usdot.lane.nxv4i32"
        )]
        fn _svusdot_lane_s32(
            op1: svint32_t,
            op2: svint8_t,
            op3: svint8_t,
            imm_index: i32,
        ) -> svint32_t;
    }
    unsafe { _svusdot_lane_s32(op1, op2.as_signed(), op3, IMM_INDEX) }
}
#[doc = "Dot product (unsigned × signed)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svusdot[_s32])"]
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(usdot))]
pub fn svusdot_s32(op1: svint32_t, op2: svuint8_t, op3: svint8_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.usdot.nxv4i32")]
        fn _svusdot_s32(op1: svint32_t, op2: svint8_t, op3: svint8_t) -> svint32_t;
    }
    unsafe { _svusdot_s32(op1, op2.as_signed(), op3) }
}
#[doc = "Dot product (unsigned × signed)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svusdot[_n_s32])"]
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(usdot))]
pub fn svusdot_n_s32(op1: svint32_t, op2: svuint8_t, op3: i8) -> svint32_t {
    svusdot_s32(op1, op2, svdup_n_s8(op3))
}
#[doc = "Matrix multiply-accumulate (unsigned × signed)"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svusmmla[_s32])"]
#[inline]
#[target_feature(enable = "sve,i8mm")]
#[cfg_attr(test, assert_instr(usmmla))]
pub fn svusmmla_s32(op1: svint32_t, op2: svuint8_t, op3: svint8_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.usmmla.nxv4i32")]
        fn _svusmmla_s32(op1: svint32_t, op2: svint8_t, op3: svint8_t) -> svint32_t;
    }
    unsafe { _svusmmla_s32(op1, op2.as_signed(), op3) }
}
#[doc = "Concatenate even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1_b8(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv16i1")]
        fn _svuzp1_b8(op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svuzp1_b8(op1, op2) }
}
#[doc = "Concatenate even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1_b16(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv8i1")]
        fn _svuzp1_b16(op1: svbool8_t, op2: svbool8_t) -> svbool8_t;
    }
    unsafe { _svuzp1_b16(op1.into(), op2.into()).into() }
}
#[doc = "Concatenate even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1_b32(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv4i1")]
        fn _svuzp1_b32(op1: svbool4_t, op2: svbool4_t) -> svbool4_t;
    }
    unsafe { _svuzp1_b32(op1.into(), op2.into()).into() }
}
#[doc = "Concatenate even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1_b64(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv2i1")]
        fn _svuzp1_b64(op1: svbool2_t, op2: svbool2_t) -> svbool2_t;
    }
    unsafe { _svuzp1_b64(op1.into(), op2.into()).into() }
}
#[doc = "Concatenate even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv4f32")]
        fn _svuzp1_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svuzp1_f32(op1, op2) }
}
#[doc = "Concatenate even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv2f64")]
        fn _svuzp1_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svuzp1_f64(op1, op2) }
}
#[doc = "Concatenate even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv16i8")]
        fn _svuzp1_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svuzp1_s8(op1, op2) }
}
#[doc = "Concatenate even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv8i16")]
        fn _svuzp1_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svuzp1_s16(op1, op2) }
}
#[doc = "Concatenate even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv4i32")]
        fn _svuzp1_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svuzp1_s32(op1, op2) }
}
#[doc = "Concatenate even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1.nxv2i64")]
        fn _svuzp1_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svuzp1_s64(op1, op2) }
}
#[doc = "Concatenate even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svuzp1_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Concatenate even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svuzp1_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Concatenate even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svuzp1_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Concatenate even elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svuzp1_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Concatenate even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1q[_f32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1q.nxv4f32")]
        fn _svuzp1q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svuzp1q_f32(op1, op2) }
}
#[doc = "Concatenate even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1q[_f64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1q.nxv2f64")]
        fn _svuzp1q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svuzp1q_f64(op1, op2) }
}
#[doc = "Concatenate even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1q[_s8])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1q.nxv16i8")]
        fn _svuzp1q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svuzp1q_s8(op1, op2) }
}
#[doc = "Concatenate even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1q[_s16])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1q.nxv8i16")]
        fn _svuzp1q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svuzp1q_s16(op1, op2) }
}
#[doc = "Concatenate even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1q[_s32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1q.nxv4i32")]
        fn _svuzp1q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svuzp1q_s32(op1, op2) }
}
#[doc = "Concatenate even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1q[_s64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp1q.nxv2i64")]
        fn _svuzp1q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svuzp1q_s64(op1, op2) }
}
#[doc = "Concatenate even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1q[_u8])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1q_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svuzp1q_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Concatenate even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1q[_u16])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1q_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svuzp1q_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Concatenate even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1q[_u32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1q_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svuzp1q_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Concatenate even quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp1q[_u64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp1))]
pub fn svuzp1q_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svuzp1q_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Concatenate odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2_b8(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv16i1")]
        fn _svuzp2_b8(op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svuzp2_b8(op1, op2) }
}
#[doc = "Concatenate odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2_b16(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv8i1")]
        fn _svuzp2_b16(op1: svbool8_t, op2: svbool8_t) -> svbool8_t;
    }
    unsafe { _svuzp2_b16(op1.into(), op2.into()).into() }
}
#[doc = "Concatenate odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2_b32(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv4i1")]
        fn _svuzp2_b32(op1: svbool4_t, op2: svbool4_t) -> svbool4_t;
    }
    unsafe { _svuzp2_b32(op1.into(), op2.into()).into() }
}
#[doc = "Concatenate odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2_b64(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv2i1")]
        fn _svuzp2_b64(op1: svbool2_t, op2: svbool2_t) -> svbool2_t;
    }
    unsafe { _svuzp2_b64(op1.into(), op2.into()).into() }
}
#[doc = "Concatenate odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv4f32")]
        fn _svuzp2_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svuzp2_f32(op1, op2) }
}
#[doc = "Concatenate odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv2f64")]
        fn _svuzp2_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svuzp2_f64(op1, op2) }
}
#[doc = "Concatenate odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv16i8")]
        fn _svuzp2_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svuzp2_s8(op1, op2) }
}
#[doc = "Concatenate odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv8i16")]
        fn _svuzp2_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svuzp2_s16(op1, op2) }
}
#[doc = "Concatenate odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv4i32")]
        fn _svuzp2_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svuzp2_s32(op1, op2) }
}
#[doc = "Concatenate odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2.nxv2i64")]
        fn _svuzp2_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svuzp2_s64(op1, op2) }
}
#[doc = "Concatenate odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svuzp2_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Concatenate odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svuzp2_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Concatenate odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svuzp2_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Concatenate odd elements from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svuzp2_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Concatenate odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2q[_f32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2q.nxv4f32")]
        fn _svuzp2q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svuzp2q_f32(op1, op2) }
}
#[doc = "Concatenate odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2q[_f64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2q.nxv2f64")]
        fn _svuzp2q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svuzp2q_f64(op1, op2) }
}
#[doc = "Concatenate odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2q[_s8])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2q.nxv16i8")]
        fn _svuzp2q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svuzp2q_s8(op1, op2) }
}
#[doc = "Concatenate odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2q[_s16])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2q.nxv8i16")]
        fn _svuzp2q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svuzp2q_s16(op1, op2) }
}
#[doc = "Concatenate odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2q[_s32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2q.nxv4i32")]
        fn _svuzp2q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svuzp2q_s32(op1, op2) }
}
#[doc = "Concatenate odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2q[_s64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.uzp2q.nxv2i64")]
        fn _svuzp2q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svuzp2q_s64(op1, op2) }
}
#[doc = "Concatenate odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2q[_u8])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2q_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svuzp2q_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Concatenate odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2q[_u16])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2q_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svuzp2q_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Concatenate odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2q[_u32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2q_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svuzp2q_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Concatenate odd quadwords from two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svuzp2q[_u64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(uzp2))]
pub fn svuzp2q_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svuzp2q_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "While incrementing scalar is less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilele_b8[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilele))]
pub fn svwhilele_b8_s32(op1: i32, op2: i32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilele.nxv16i1.i32"
        )]
        fn _svwhilele_b8_s32(op1: i32, op2: i32) -> svbool_t;
    }
    unsafe { _svwhilele_b8_s32(op1, op2) }
}
#[doc = "While incrementing scalar is less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilele_b16[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilele))]
pub fn svwhilele_b16_s32(op1: i32, op2: i32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilele.nxv8i1.i32"
        )]
        fn _svwhilele_b16_s32(op1: i32, op2: i32) -> svbool8_t;
    }
    unsafe { _svwhilele_b16_s32(op1, op2).into() }
}
#[doc = "While incrementing scalar is less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilele_b32[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilele))]
pub fn svwhilele_b32_s32(op1: i32, op2: i32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilele.nxv4i1.i32"
        )]
        fn _svwhilele_b32_s32(op1: i32, op2: i32) -> svbool4_t;
    }
    unsafe { _svwhilele_b32_s32(op1, op2).into() }
}
#[doc = "While incrementing scalar is less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilele_b64[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilele))]
pub fn svwhilele_b64_s32(op1: i32, op2: i32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilele.nxv2i1.i32"
        )]
        fn _svwhilele_b64_s32(op1: i32, op2: i32) -> svbool2_t;
    }
    unsafe { _svwhilele_b64_s32(op1, op2).into() }
}
#[doc = "While incrementing scalar is less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilele_b8[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilele))]
pub fn svwhilele_b8_s64(op1: i64, op2: i64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilele.nxv16i1.i64"
        )]
        fn _svwhilele_b8_s64(op1: i64, op2: i64) -> svbool_t;
    }
    unsafe { _svwhilele_b8_s64(op1, op2) }
}
#[doc = "While incrementing scalar is less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilele_b16[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilele))]
pub fn svwhilele_b16_s64(op1: i64, op2: i64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilele.nxv8i1.i64"
        )]
        fn _svwhilele_b16_s64(op1: i64, op2: i64) -> svbool8_t;
    }
    unsafe { _svwhilele_b16_s64(op1, op2).into() }
}
#[doc = "While incrementing scalar is less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilele_b32[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilele))]
pub fn svwhilele_b32_s64(op1: i64, op2: i64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilele.nxv4i1.i64"
        )]
        fn _svwhilele_b32_s64(op1: i64, op2: i64) -> svbool4_t;
    }
    unsafe { _svwhilele_b32_s64(op1, op2).into() }
}
#[doc = "While incrementing scalar is less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilele_b64[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilele))]
pub fn svwhilele_b64_s64(op1: i64, op2: i64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilele.nxv2i1.i64"
        )]
        fn _svwhilele_b64_s64(op1: i64, op2: i64) -> svbool2_t;
    }
    unsafe { _svwhilele_b64_s64(op1, op2).into() }
}
#[doc = "While incrementing scalar is less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilele_b8[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilels))]
pub fn svwhilele_b8_u32(op1: u32, op2: u32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilels.nxv16i1.i32"
        )]
        fn _svwhilele_b8_u32(op1: i32, op2: i32) -> svbool_t;
    }
    unsafe { _svwhilele_b8_u32(op1.as_signed(), op2.as_signed()) }
}
#[doc = "While incrementing scalar is less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilele_b16[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilels))]
pub fn svwhilele_b16_u32(op1: u32, op2: u32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilels.nxv8i1.i32"
        )]
        fn _svwhilele_b16_u32(op1: i32, op2: i32) -> svbool8_t;
    }
    unsafe { _svwhilele_b16_u32(op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "While incrementing scalar is less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilele_b32[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilels))]
pub fn svwhilele_b32_u32(op1: u32, op2: u32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilels.nxv4i1.i32"
        )]
        fn _svwhilele_b32_u32(op1: i32, op2: i32) -> svbool4_t;
    }
    unsafe { _svwhilele_b32_u32(op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "While incrementing scalar is less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilele_b64[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilels))]
pub fn svwhilele_b64_u32(op1: u32, op2: u32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilels.nxv2i1.i32"
        )]
        fn _svwhilele_b64_u32(op1: i32, op2: i32) -> svbool2_t;
    }
    unsafe { _svwhilele_b64_u32(op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "While incrementing scalar is less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilele_b8[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilels))]
pub fn svwhilele_b8_u64(op1: u64, op2: u64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilels.nxv16i1.i64"
        )]
        fn _svwhilele_b8_u64(op1: i64, op2: i64) -> svbool_t;
    }
    unsafe { _svwhilele_b8_u64(op1.as_signed(), op2.as_signed()) }
}
#[doc = "While incrementing scalar is less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilele_b16[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilels))]
pub fn svwhilele_b16_u64(op1: u64, op2: u64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilels.nxv8i1.i64"
        )]
        fn _svwhilele_b16_u64(op1: i64, op2: i64) -> svbool8_t;
    }
    unsafe { _svwhilele_b16_u64(op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "While incrementing scalar is less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilele_b32[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilels))]
pub fn svwhilele_b32_u64(op1: u64, op2: u64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilels.nxv4i1.i64"
        )]
        fn _svwhilele_b32_u64(op1: i64, op2: i64) -> svbool4_t;
    }
    unsafe { _svwhilele_b32_u64(op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "While incrementing scalar is less than or equal to"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilele_b64[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilels))]
pub fn svwhilele_b64_u64(op1: u64, op2: u64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilels.nxv2i1.i64"
        )]
        fn _svwhilele_b64_u64(op1: i64, op2: i64) -> svbool2_t;
    }
    unsafe { _svwhilele_b64_u64(op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "While incrementing scalar is less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilelt_b8[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelt))]
pub fn svwhilelt_b8_s32(op1: i32, op2: i32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelt.nxv16i1.i32"
        )]
        fn _svwhilelt_b8_s32(op1: i32, op2: i32) -> svbool_t;
    }
    unsafe { _svwhilelt_b8_s32(op1, op2) }
}
#[doc = "While incrementing scalar is less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilelt_b16[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelt))]
pub fn svwhilelt_b16_s32(op1: i32, op2: i32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelt.nxv8i1.i32"
        )]
        fn _svwhilelt_b16_s32(op1: i32, op2: i32) -> svbool8_t;
    }
    unsafe { _svwhilelt_b16_s32(op1, op2).into() }
}
#[doc = "While incrementing scalar is less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilelt_b32[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelt))]
pub fn svwhilelt_b32_s32(op1: i32, op2: i32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelt.nxv4i1.i32"
        )]
        fn _svwhilelt_b32_s32(op1: i32, op2: i32) -> svbool4_t;
    }
    unsafe { _svwhilelt_b32_s32(op1, op2).into() }
}
#[doc = "While incrementing scalar is less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilelt_b64[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelt))]
pub fn svwhilelt_b64_s32(op1: i32, op2: i32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelt.nxv2i1.i32"
        )]
        fn _svwhilelt_b64_s32(op1: i32, op2: i32) -> svbool2_t;
    }
    unsafe { _svwhilelt_b64_s32(op1, op2).into() }
}
#[doc = "While incrementing scalar is less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilelt_b8[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelt))]
pub fn svwhilelt_b8_s64(op1: i64, op2: i64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelt.nxv16i1.i64"
        )]
        fn _svwhilelt_b8_s64(op1: i64, op2: i64) -> svbool_t;
    }
    unsafe { _svwhilelt_b8_s64(op1, op2) }
}
#[doc = "While incrementing scalar is less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilelt_b16[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelt))]
pub fn svwhilelt_b16_s64(op1: i64, op2: i64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelt.nxv8i1.i64"
        )]
        fn _svwhilelt_b16_s64(op1: i64, op2: i64) -> svbool8_t;
    }
    unsafe { _svwhilelt_b16_s64(op1, op2).into() }
}
#[doc = "While incrementing scalar is less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilelt_b32[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelt))]
pub fn svwhilelt_b32_s64(op1: i64, op2: i64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelt.nxv4i1.i64"
        )]
        fn _svwhilelt_b32_s64(op1: i64, op2: i64) -> svbool4_t;
    }
    unsafe { _svwhilelt_b32_s64(op1, op2).into() }
}
#[doc = "While incrementing scalar is less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilelt_b64[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelt))]
pub fn svwhilelt_b64_s64(op1: i64, op2: i64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelt.nxv2i1.i64"
        )]
        fn _svwhilelt_b64_s64(op1: i64, op2: i64) -> svbool2_t;
    }
    unsafe { _svwhilelt_b64_s64(op1, op2).into() }
}
#[doc = "While incrementing scalar is less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilelt_b8[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelo))]
pub fn svwhilelt_b8_u32(op1: u32, op2: u32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelo.nxv16i1.i32"
        )]
        fn _svwhilelt_b8_u32(op1: i32, op2: i32) -> svbool_t;
    }
    unsafe { _svwhilelt_b8_u32(op1.as_signed(), op2.as_signed()) }
}
#[doc = "While incrementing scalar is less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilelt_b16[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelo))]
pub fn svwhilelt_b16_u32(op1: u32, op2: u32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelo.nxv8i1.i32"
        )]
        fn _svwhilelt_b16_u32(op1: i32, op2: i32) -> svbool8_t;
    }
    unsafe { _svwhilelt_b16_u32(op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "While incrementing scalar is less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilelt_b32[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelo))]
pub fn svwhilelt_b32_u32(op1: u32, op2: u32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelo.nxv4i1.i32"
        )]
        fn _svwhilelt_b32_u32(op1: i32, op2: i32) -> svbool4_t;
    }
    unsafe { _svwhilelt_b32_u32(op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "While incrementing scalar is less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilelt_b64[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelo))]
pub fn svwhilelt_b64_u32(op1: u32, op2: u32) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelo.nxv2i1.i32"
        )]
        fn _svwhilelt_b64_u32(op1: i32, op2: i32) -> svbool2_t;
    }
    unsafe { _svwhilelt_b64_u32(op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "While incrementing scalar is less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilelt_b8[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelo))]
pub fn svwhilelt_b8_u64(op1: u64, op2: u64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelo.nxv16i1.i64"
        )]
        fn _svwhilelt_b8_u64(op1: i64, op2: i64) -> svbool_t;
    }
    unsafe { _svwhilelt_b8_u64(op1.as_signed(), op2.as_signed()) }
}
#[doc = "While incrementing scalar is less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilelt_b16[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelo))]
pub fn svwhilelt_b16_u64(op1: u64, op2: u64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelo.nxv8i1.i64"
        )]
        fn _svwhilelt_b16_u64(op1: i64, op2: i64) -> svbool8_t;
    }
    unsafe { _svwhilelt_b16_u64(op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "While incrementing scalar is less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilelt_b32[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelo))]
pub fn svwhilelt_b32_u64(op1: u64, op2: u64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelo.nxv4i1.i64"
        )]
        fn _svwhilelt_b32_u64(op1: i64, op2: i64) -> svbool4_t;
    }
    unsafe { _svwhilelt_b32_u64(op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "While incrementing scalar is less than"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwhilelt_b64[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(whilelo))]
pub fn svwhilelt_b64_u64(op1: u64, op2: u64) -> svbool_t {
    extern "C" {
        #[cfg_attr(
            target_arch = "aarch64",
            link_name = "llvm.aarch64.sve.whilelo.nxv2i1.i64"
        )]
        fn _svwhilelt_b64_u64(op1: i64, op2: i64) -> svbool2_t;
    }
    unsafe { _svwhilelt_b64_u64(op1.as_signed(), op2.as_signed()).into() }
}
#[doc = "Write to the first-fault register"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svwrffr)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(wrffr))]
pub fn svwrffr(op: svbool_t) {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.wrffr")]
        fn _svwrffr(op: svbool_t);
    }
    unsafe { _svwrffr(op) }
}
#[doc = "Interleave elements from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1_b8(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv16i1")]
        fn _svzip1_b8(op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svzip1_b8(op1, op2) }
}
#[doc = "Interleave elements from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1_b16(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv8i1")]
        fn _svzip1_b16(op1: svbool8_t, op2: svbool8_t) -> svbool8_t;
    }
    unsafe { _svzip1_b16(op1.into(), op2.into()).into() }
}
#[doc = "Interleave elements from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1_b32(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv4i1")]
        fn _svzip1_b32(op1: svbool4_t, op2: svbool4_t) -> svbool4_t;
    }
    unsafe { _svzip1_b32(op1.into(), op2.into()).into() }
}
#[doc = "Interleave elements from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1_b64(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv2i1")]
        fn _svzip1_b64(op1: svbool2_t, op2: svbool2_t) -> svbool2_t;
    }
    unsafe { _svzip1_b64(op1.into(), op2.into()).into() }
}
#[doc = "Interleave elements from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv4f32")]
        fn _svzip1_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svzip1_f32(op1, op2) }
}
#[doc = "Interleave elements from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv2f64")]
        fn _svzip1_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svzip1_f64(op1, op2) }
}
#[doc = "Interleave elements from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv16i8")]
        fn _svzip1_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svzip1_s8(op1, op2) }
}
#[doc = "Interleave elements from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv8i16")]
        fn _svzip1_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svzip1_s16(op1, op2) }
}
#[doc = "Interleave elements from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv4i32")]
        fn _svzip1_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svzip1_s32(op1, op2) }
}
#[doc = "Interleave elements from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1.nxv2i64")]
        fn _svzip1_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svzip1_s64(op1, op2) }
}
#[doc = "Interleave elements from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svzip1_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave elements from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svzip1_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave elements from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svzip1_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave elements from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svzip1_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave quadwords from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1q[_f32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1q.nxv4f32")]
        fn _svzip1q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svzip1q_f32(op1, op2) }
}
#[doc = "Interleave quadwords from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1q[_f64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1q.nxv2f64")]
        fn _svzip1q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svzip1q_f64(op1, op2) }
}
#[doc = "Interleave quadwords from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1q[_s8])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1q.nxv16i8")]
        fn _svzip1q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svzip1q_s8(op1, op2) }
}
#[doc = "Interleave quadwords from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1q[_s16])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1q.nxv8i16")]
        fn _svzip1q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svzip1q_s16(op1, op2) }
}
#[doc = "Interleave quadwords from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1q[_s32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1q.nxv4i32")]
        fn _svzip1q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svzip1q_s32(op1, op2) }
}
#[doc = "Interleave quadwords from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1q[_s64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip1q.nxv2i64")]
        fn _svzip1q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svzip1q_s64(op1, op2) }
}
#[doc = "Interleave quadwords from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1q[_u8])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1q_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svzip1q_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave quadwords from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1q[_u16])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1q_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svzip1q_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave quadwords from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1q[_u32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1q_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svzip1q_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave quadwords from low halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip1q[_u64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip1))]
pub fn svzip1q_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svzip1q_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave elements from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2_b8)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2_b8(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv16i1")]
        fn _svzip2_b8(op1: svbool_t, op2: svbool_t) -> svbool_t;
    }
    unsafe { _svzip2_b8(op1, op2) }
}
#[doc = "Interleave elements from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2_b16)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2_b16(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv8i1")]
        fn _svzip2_b16(op1: svbool8_t, op2: svbool8_t) -> svbool8_t;
    }
    unsafe { _svzip2_b16(op1.into(), op2.into()).into() }
}
#[doc = "Interleave elements from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2_b32)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2_b32(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv4i1")]
        fn _svzip2_b32(op1: svbool4_t, op2: svbool4_t) -> svbool4_t;
    }
    unsafe { _svzip2_b32(op1.into(), op2.into()).into() }
}
#[doc = "Interleave elements from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2_b64)"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2_b64(op1: svbool_t, op2: svbool_t) -> svbool_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv2i1")]
        fn _svzip2_b64(op1: svbool2_t, op2: svbool2_t) -> svbool2_t;
    }
    unsafe { _svzip2_b64(op1.into(), op2.into()).into() }
}
#[doc = "Interleave elements from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2[_f32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv4f32")]
        fn _svzip2_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svzip2_f32(op1, op2) }
}
#[doc = "Interleave elements from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2[_f64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv2f64")]
        fn _svzip2_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svzip2_f64(op1, op2) }
}
#[doc = "Interleave elements from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2[_s8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv16i8")]
        fn _svzip2_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svzip2_s8(op1, op2) }
}
#[doc = "Interleave elements from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2[_s16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv8i16")]
        fn _svzip2_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svzip2_s16(op1, op2) }
}
#[doc = "Interleave elements from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2[_s32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv4i32")]
        fn _svzip2_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svzip2_s32(op1, op2) }
}
#[doc = "Interleave elements from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2[_s64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2.nxv2i64")]
        fn _svzip2_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svzip2_s64(op1, op2) }
}
#[doc = "Interleave elements from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2[_u8])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svzip2_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave elements from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2[_u16])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svzip2_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave elements from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2[_u32])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svzip2_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave elements from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2[_u64])"]
#[inline]
#[target_feature(enable = "sve")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svzip2_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave quadwords from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2q[_f32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2q.nxv4f32")]
        fn _svzip2q_f32(op1: svfloat32_t, op2: svfloat32_t) -> svfloat32_t;
    }
    unsafe { _svzip2q_f32(op1, op2) }
}
#[doc = "Interleave quadwords from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2q[_f64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2q.nxv2f64")]
        fn _svzip2q_f64(op1: svfloat64_t, op2: svfloat64_t) -> svfloat64_t;
    }
    unsafe { _svzip2q_f64(op1, op2) }
}
#[doc = "Interleave quadwords from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2q[_s8])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2q.nxv16i8")]
        fn _svzip2q_s8(op1: svint8_t, op2: svint8_t) -> svint8_t;
    }
    unsafe { _svzip2q_s8(op1, op2) }
}
#[doc = "Interleave quadwords from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2q[_s16])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2q.nxv8i16")]
        fn _svzip2q_s16(op1: svint16_t, op2: svint16_t) -> svint16_t;
    }
    unsafe { _svzip2q_s16(op1, op2) }
}
#[doc = "Interleave quadwords from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2q[_s32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2q.nxv4i32")]
        fn _svzip2q_s32(op1: svint32_t, op2: svint32_t) -> svint32_t;
    }
    unsafe { _svzip2q_s32(op1, op2) }
}
#[doc = "Interleave quadwords from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2q[_s64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t {
    extern "C" {
        #[cfg_attr(target_arch = "aarch64", link_name = "llvm.aarch64.sve.zip2q.nxv2i64")]
        fn _svzip2q_s64(op1: svint64_t, op2: svint64_t) -> svint64_t;
    }
    unsafe { _svzip2q_s64(op1, op2) }
}
#[doc = "Interleave quadwords from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2q[_u8])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2q_u8(op1: svuint8_t, op2: svuint8_t) -> svuint8_t {
    unsafe { svzip2q_s8(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave quadwords from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2q[_u16])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2q_u16(op1: svuint16_t, op2: svuint16_t) -> svuint16_t {
    unsafe { svzip2q_s16(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave quadwords from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2q[_u32])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2q_u32(op1: svuint32_t, op2: svuint32_t) -> svuint32_t {
    unsafe { svzip2q_s32(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
#[doc = "Interleave quadwords from high halves of two inputs"]
#[doc = ""]
#[doc = "[Arm's documentation](https://developer.arm.com/architectures/instruction-sets/intrinsics/svzip2q[_u64])"]
#[inline]
#[target_feature(enable = "sve,f64mm")]
#[cfg_attr(test, assert_instr(zip2))]
pub fn svzip2q_u64(op1: svuint64_t, op2: svuint64_t) -> svuint64_t {
    unsafe { svzip2q_s64(op1.as_signed(), op2.as_signed()).as_unsigned() }
}
